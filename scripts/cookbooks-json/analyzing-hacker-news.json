{
  "custompage": {
    "metadata": {
      "image": [],
      "title": "",
      "description": "",
      "keywords": ""
    },
    "algolia": {
      "recordCount": 11,
      "publishPending": false,
      "updatedAt": "2024-07-11T01:20:28.407Z"
    },
    "title": "Analyzing Hacker News with Six Language Understanding Methods",
    "slug": "analyzing-hacker-news",
    "body": "[block:html]\n{\n  \"html\": \"<div class=\\\"cookbook-nav-container\\\">\\n  <a href=\\\"/page/cookbooks\\\" class=\\\"back-button pt-10 group inline-block cursor-pointer font-medium \\\" rel=\\\"noreferrer\\\"\\n    target=\\\"_self\\\">\\n    <div class=\\\"pr-1 inline-block group-hover:no-underline\\\">\\n      <svg width=\\\"11.8\\\" height=\\\"11\\\" viewBox=\\\"0 0 14 13\\\" fill=\\\"none\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\">\\n        <path\\n          d=\\\"M1.1554 7.20808C1.35066 7.40335 1.66724 7.40335 1.8625 7.20808L7.18477 1.88582C7.38003 1.69055 7.38003 1.37397 7.18477 1.17871L6.83121 0.825157C6.63595 0.629895 6.31937 0.629896 6.12411 0.825157L0.801842 6.14742C0.60658 6.34269 0.60658 6.65927 0.801842 6.85453L1.1554 7.20808Z\\\"\\n          fill=\\\"currentColor\\\" />\\n        <path\\n          d=\\\"M1.1554 5.79226C1.35066 5.597 1.66724 5.597 1.8625 5.79226L7.18477 11.1145C7.38003 11.3098 7.38003 11.6264 7.18477 11.8216L6.83121 12.1752C6.63595 12.3705 6.31937 12.3705 6.12411 12.1752L0.801842 6.85292C0.60658 6.65766 0.60658 6.34108 0.801842 6.14582L1.1554 5.79226Z\\\"\\n          fill=\\\"currentColor\\\" />\\n        <path\\n          d=\\\"M2.52491 6.23674C2.52492 5.9606 2.74878 5.73675 3.02491 5.73675H6.28412C6.4513 5.73675 6.60742 5.8203 6.70015 5.95941L7.03347 6.45941C7.25499 6.79169 7.01679 7.23675 6.61745 7.23675H3.0249C2.74876 7.23675 2.5249 7.01289 2.5249 6.73674L2.52491 6.23674Z\\\"\\n          fill=\\\"currentColor\\\" />\\n        <path\\n          d=\\\"M13.5517 6.73676C13.5517 7.0129 13.3278 7.23675 13.0517 7.23675H8.79246C8.62528 7.23675 8.46916 7.1532 8.37643 7.0141L8.04311 6.5141C7.8216 6.18182 8.05979 5.73675 8.45914 5.73675H13.0517C13.3278 5.73675 13.5517 5.96062 13.5517 6.23676L13.5517 6.73676Z\\\"\\n          fill=\\\"currentColor\\\" />\\n      </svg>\\n    </div>\\n    Back to Cookbooks\\n  </a>\\n\\n  <a href=https://github.com/cohere-ai/cohere-developer-experience/blob/main/notebooks/guides/Analyzing_Hacker_News_with_Six_Language_Understanding_Methods.ipynb class=\\\"github-button pt-10 group inline-block cursor-pointer font-medium \\\" rel=\\\"noreferrer\\\"\\n    target=\\\"_blank\\\">\\n    Open in GitHub\\n    <div class=\\\"pl-1 inline-block group-hover:no-underline\\\">\\n      <svg width=\\\"14\\\" height=\\\"10\\\" viewBox=\\\"0 0 14 10\\\" fill=\\\"none\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\">\\n        <path\\n          d=\\\"M8.63218 0.366821C8.35604 0.366821 8.13218 0.590679 8.13218 0.866821V8.39364C8.13218 8.66978 8.35604 8.89364 8.63218 8.89364H9.13218C9.40832 8.89364 9.63218 8.66978 9.63218 8.39364V0.866821C9.63218 0.590678 9.40832 0.366821 9.13218 0.366821H8.63218Z\\\"\\n          fill=\\\"currentColor\\\" />\\n        <path\\n          d=\\\"M9.63332 1.36796C9.63332 1.6441 9.40946 1.86796 9.13332 1.86796H1.6065C1.33035 1.86796 1.1065 1.6441 1.1065 1.36796V0.867956C1.1065 0.591813 1.33035 0.367956 1.6065 0.367956H9.13332C9.40946 0.367956 9.63332 0.591813 9.63332 0.867956V1.36796Z\\\"\\n          fill=\\\"currentColor\\\" />\\n        <path\\n          d=\\\"M8.35063 2.02206C8.54588 2.21732 8.54588 2.5339 8.35062 2.72916L6.04601 5.03377C5.9278 5.15198 5.75833 5.20329 5.59439 5.1705L5.00515 5.05264C4.61356 4.97432 4.46728 4.49118 4.74966 4.2088L7.28997 1.66849C7.48523 1.47323 7.80182 1.47323 7.99708 1.6685L8.35063 2.02206Z\\\"\\n          fill=\\\"currentColor\\\" />\\n        <path\\n          d=\\\"M0.199967 9.46558C0.0047119 9.27032 0.0047151 8.95374 0.199974 8.75848L3.21169 5.74677C3.3299 5.62855 3.49938 5.57724 3.66331 5.61003L4.25256 5.72789C4.64414 5.80621 4.79042 6.28935 4.50804 6.57173L1.26063 9.81915C1.06536 10.0144 0.748774 10.0144 0.553513 9.81914L0.199967 9.46558Z\\\"\\n          fill=\\\"currentColor\\\" />\\n      </svg>\\n    </div>\\n  </a>\\n</div>\\n\\n<div>\\n  <h1>Analyzing Hacker News with Six Language Understanding Methods</h1>\\n</div>\\n\\n<style>\\n  .header {\\n    padding: 9px 0 17px 0;\\n    display: flex;\\n    flex-direction: column;\\n  }\\n\\n  a[href],\\n  .field-description a:not([href=\\\"\\\"]),\\n  .markdown-body a[href],\\n  .markdown-body a:not([href=\\\"\\\"]) {\\n    text-decoration: none;\\n  }\\n\\n  #content {\\n    padding: 0 32px;\\n  }\\n\\n  #content-head {\\n    display: none;\\n  }\\n\\n  .guide-page-title {\\n    font-size: 29px !important;\\n  }\\n\\n  .back-button .github-button {\\n    border-radius: 0 !important;\\n    border-width: 0 !important;\\n    background-color: inherit !important;\\n  }\\n\\n  .cookbook-nav-container {\\n    display: flex;\\n    flex-direction: row;\\n    justify-content: space-between;\\n    align-items: center;\\n  }\\n\\n  @media only screen and (min-width: 620px) {\\n    .guide-page-title {\\n      width: 70%;\\n    }\\n\\n    .header {\\n      display: flex;\\n      flex-direction: row;\\n      align-items: center;\\n      justify-content: space-between;\\n      padding: 9px 0 17px 0;\\n    }\\n\\n    .git--button {\\n      width: 145px !important;\\n      display: flex;\\n      flex-direction: row;\\n      justify-content: center;\\n      align-items: center;\\n      padding: 8px 16px;\\n\\n      width: 154px;\\n      height: 35px;\\n\\n      background: #D4D9D4;\\n      border: 1px solid #9DAAA4;\\n      border-radius: 6px;\\n    }\\n  }\\n\\n\\n  @media only screen and (min-width: 1024px) {\\n    .guide-page-title {\\n      font-size: 46px !important;\\n    }\\n\\n    .header {\\n      padding: 9px 0 32px 0;\\n    }\\n  }\\n</style>\"\n}\n[/block]\n\n\nLarge language models give machines a vastly improved representation and understanding of language. These abilities give developers more options for content recommendation, analysis, and filtering.\n\nIn this notebook we take thousands of the most popular posts from Hacker News and demonstrate some of these functionalities:\n\n1. Given an existing post title, retrieve the most similar posts (nearest neighbor search using embeddings)\n2. Given a query that we write, retrieve the most similar posts\n3. Plot the archive of articles by similarity (where similar posts are close together and different ones are far)\n4. Cluster the posts to identify the major common themes\n5. Extract major keywords from each cluster so we can identify what the clsuter is about\n6. (Experimental) Name clusters with a generative language model\n\n## Setup\n\nLet's start by installing the tools we'll need and then importing them.\n\n```python\n!pip install cohere umap-learn altair annoy bertopic\n```\n\n```\nRequirement already satisfied: cohere in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (5.1.5)\nRequirement already satisfied: umap-learn in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (0.5.5)\nRequirement already satisfied: altair in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (5.2.0)\nRequirement already satisfied: annoy in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (1.17.3)\nRequirement already satisfied: bertopic in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (0.16.0)\nRequirement already satisfied: httpx>=0.21.2 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from cohere) (0.27.0)\nRequirement already satisfied: pydantic>=1.9.2 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from cohere) (2.6.0)\nRequirement already satisfied: typing_extensions>=4.0.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from cohere) (4.10.0)\nRequirement already satisfied: numpy>=1.17 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from umap-learn) (1.24.3)\nRequirement already satisfied: scipy>=1.3.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from umap-learn) (1.11.1)\nRequirement already satisfied: scikit-learn>=0.22 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from umap-learn) (1.3.0)\nRequirement already satisfied: numba>=0.51.2 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from umap-learn) (0.57.0)\nRequirement already satisfied: pynndescent>=0.5 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from umap-learn) (0.5.12)\nRequirement already satisfied: tqdm in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from umap-learn) (4.65.0)\nRequirement already satisfied: jinja2 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from altair) (3.1.2)\nRequirement already satisfied: jsonschema>=3.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from altair) (4.17.3)\nRequirement already satisfied: packaging in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from altair) (23.2)\nRequirement already satisfied: pandas>=0.25 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from altair) (2.0.3)\nRequirement already satisfied: toolz in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from altair) (0.12.0)\nRequirement already satisfied: hdbscan>=0.8.29 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from bertopic) (0.8.33)\nRequirement already satisfied: sentence-transformers>=0.4.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from bertopic) (2.6.1)\nRequirement already satisfied: plotly>=4.7.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from bertopic) (5.9.0)\nRequirement already satisfied: cython<3,>=0.27 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from hdbscan>=0.8.29->bertopic) (0.29.37)\nRequirement already satisfied: joblib>=1.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from hdbscan>=0.8.29->bertopic) (1.2.0)\nRequirement already satisfied: anyio in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from httpx>=0.21.2->cohere) (3.5.0)\nRequirement already satisfied: certifi in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from httpx>=0.21.2->cohere) (2023.11.17)\nRequirement already satisfied: httpcore==1.* in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from httpx>=0.21.2->cohere) (1.0.2)\nRequirement already satisfied: idna in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from httpx>=0.21.2->cohere) (3.4)\nRequirement already satisfied: sniffio in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from httpx>=0.21.2->cohere) (1.2.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\nRequirement already satisfied: attrs>=17.4.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair) (22.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair) (0.18.0)\nRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from numba>=0.51.2->umap-learn) (0.40.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->altair) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->altair) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->altair) (2023.3)\nRequirement already satisfied: tenacity>=6.2.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from plotly>=4.7.0->bertopic) (8.2.2)\nRequirement already satisfied: annotated-types>=0.4.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from pydantic>=1.9.2->cohere) (0.6.0)\nRequirement already satisfied: pydantic-core==2.16.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from pydantic>=1.9.2->cohere) (2.16.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22->umap-learn) (2.2.0)\nRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.39.3)\nRequirement already satisfied: torch>=1.11.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.4.1->bertopic) (2.2.2)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.22.2)\nRequirement already satisfied: Pillow in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.4.1->bertopic) (10.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from jinja2->altair) (2.1.1)\nRequirement already satisfied: filelock in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.9.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.3.1)\nRequirement already satisfied: pyyaml>=5.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0)\nRequirement already satisfied: requests in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.31.0)\nRequirement already satisfied: six>=1.5 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.25->altair) (1.16.0)\nRequirement already satisfied: sympy in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.11.1)\nRequirement already satisfied: networkx in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1)\nRequirement already satisfied: regex!=2019.12.17 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (2022.7.9)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.4.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (1.26.18)\nRequirement already satisfied: mpmath>=0.19 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n```\n\n```python\nimport cohere\nimport numpy as np\nimport pandas as pd\nimport umap\nimport altair as alt\nfrom annoy import AnnoyIndex\nimport warnings\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom bertopic.vectorizers import ClassTfidfTransformer\n\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_colwidth', None)\n```\n\nFill in your Cohere API key in the next cell. To do this, begin by [signing up to Cohere](https://os.cohere.ai/) (for free!) if you haven't yet. Then get your API key [here](https://dashboard.cohere.com/api-keys).\n\n```python\nco = cohere.Client(\"COHERE_API_KEY\") # Insert your Cohere API key\n```\n\n## Dataset: Top 3,000 Ask HN posts\n\nWe will use the top 3,000 posts from the Ask HN section of Hacker News. We provide a CSV containing the posts.\n\n```python\ndf = pd.read_csv('https://storage.googleapis.com/cohere-assets/blog/text-clustering/data/askhn3k_df.csv', index_col=0)\n\nprint(f'Loaded a DataFrame with {len(df)} rows')\n```\n\n```\nLoaded a DataFrame with 3000 rows\n```\n\n```python\ndf.head()\n```\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n```\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n```\n\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>url</th>\n      <th>text</th>\n      <th>dead</th>\n      <th>by</th>\n      <th>score</th>\n      <th>time</th>\n      <th>timestamp</th>\n      <th>type</th>\n      <th>id</th>\n      <th>parent</th>\n      <th>descendants</th>\n      <th>ranking</th>\n      <th>deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I'm a software engineer going blind, how should I prepare?</td>\n      <td>NaN</td>\n      <td>I&amp;#x27;m a 24 y&amp;#x2F;o full stack engineer (I know some of you are rolling your eyes right now, just highlighting that I have experience on frontend apps as well as backend architecture). I&amp;#x27;ve been working professionally for ~7 years building mostly javascript projects but also some PHP. Two years ago I was diagnosed with a condition called &amp;quot;Usher&amp;#x27;s Syndrome&amp;quot; - characterized by hearing loss, balance issues, and progressive vision loss.&lt;p&gt;I know there are blind software engineers out there. My main questions are:&lt;p&gt;- Are there blind frontend engineers?&lt;p&gt;- What kinds of software engineering lend themselves to someone with limited vision? Backend only?&lt;p&gt;- Besides a screen reader, what are some of the best tools for building software with limited vision?&lt;p&gt;- Does your company employ blind engineers? How well does it work? What kind of engineer are they?&lt;p&gt;I&amp;#x27;m really trying to get ahead of this thing and prepare myself as my vision is degrading rather quickly. I&amp;#x27;m not sure what I can do if I can&amp;#x27;t do SE as I don&amp;#x27;t have any formal education in anything. I&amp;#x27;ve worked really hard to get to where I am and don&amp;#x27;t want it to go to waste.&lt;p&gt;Thank you for any input, and stay safe out there!&lt;p&gt;Edit:&lt;p&gt;Thank you all for your links, suggestions, and moral support, I really appreciate it. Since my diagnosis I&amp;#x27;ve slowly developed a crippling anxiety centered around a feeling that I need to figure out the rest of my life before it&amp;#x27;s too late. I know I shouldn&amp;#x27;t think this way but it is hard not to. I&amp;#x27;m very independent and I feel a pressure to &amp;quot;show up.&amp;quot; I will look into these opportunities mentioned and try to get in touch with some more members of the blind engineering community.</td>\n      <td>NaN</td>\n      <td>zachrip</td>\n      <td>3270</td>\n      <td>1587332026</td>\n      <td>2020-04-19 21:33:46+00:00</td>\n      <td>story</td>\n      <td>22918980</td>\n      <td>NaN</td>\n      <td>473.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Am I the longest-serving programmer – 57 years and counting?</td>\n      <td>NaN</td>\n      <td>In May of 1963, I started my first full-time job as a computer programmer for Mitchell Engineering Company, a supplier of steel buildings.  At Mitchell, I developed programs in Fortran II on an IBM 1620 mostly to improve the efficiency of order processing and fulfillment.  Since then, all my jobs for the past 57 years have involved computer programming.  I am now a data scientist developing cloud-based big data fraud detection algorithms using machine learning and other advanced analytical technologies.  Along the way, I earned a Master’s in Operations Research and a Master’s in Management Science, studied artificial intelligence for 3 years in a Ph.D. program for engineering, and just two years ago I received Graduate Certificates in Big Data Analytics from the schools of business and computer science at a local university (FAU).  In addition, I currently hold the designation of Certified Analytics Professional (CAP).  At 74, I still have no plans to retire or to stop programming.</td>\n      <td>NaN</td>\n      <td>genedangelo</td>\n      <td>2634</td>\n      <td>1590890024</td>\n      <td>2020-05-31 01:53:44+00:00</td>\n      <td>story</td>\n      <td>23366546</td>\n      <td>NaN</td>\n      <td>531.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Is S3 down?</td>\n      <td>NaN</td>\n      <td>I&amp;#x27;m getting&lt;p&gt;{\\n  &amp;quot;errorCode&amp;quot; : &amp;quot;InternalError&amp;quot;\\n}&lt;p&gt;When I attempt to use the AWS Console to view s3</td>\n      <td>NaN</td>\n      <td>iamdeedubs</td>\n      <td>2589</td>\n      <td>1488303958</td>\n      <td>2017-02-28 17:45:58+00:00</td>\n      <td>story</td>\n      <td>13755673</td>\n      <td>NaN</td>\n      <td>1055.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What tech job would let me get away with the least real work possible?</td>\n      <td>NaN</td>\n      <td>Hey HN,&lt;p&gt;I&amp;#x27;ll probably get a lot of flak for this. Sorry.&lt;p&gt;I&amp;#x27;m an average developer looking for ways to work as little as humanely possible.&lt;p&gt;The pandemic made me realize that I do not care about working anymore. The software I build is useless. Time flies real fast and I have to focus on my passions (which are not monetizable).&lt;p&gt;Unfortunately, I require shelter, calories and hobby materials. Thus the need for some kind of job.&lt;p&gt;Which leads me to ask my fellow tech workers, what kind of job (if any) do you think would fit the following requirements :&lt;p&gt;- No &amp;#x2F; very little involvement in the product itself (I do not care.)&lt;p&gt;- Fully remote (You can&amp;#x27;t do much when stuck in the office. Ideally being done in 2 hours in the morning then chilling would be perfect.)&lt;p&gt;- Low expectactions &amp;#x2F; vague job description.&lt;p&gt;- Salary can be on the lower side.&lt;p&gt;- No career advancement possibilities required. Only tech, I do not want to manage people.&lt;p&gt;- Can be about helping other developers, setting up infrastructure&amp;#x2F;deploy or pure data management since this is fun.&lt;p&gt;I think the only possible jobs would be some kind of backend-only dev or devops&amp;#x2F;sysadmin work. But I&amp;#x27;m not sure these exist anymore, it seems like you always end up having to think about the product itself. Web dev jobs always required some involvement in the frontend.&lt;p&gt;Thanks for any advice (or hate, which I can&amp;#x27;t really blame you for).</td>\n      <td>NaN</td>\n      <td>lmueongoqx</td>\n      <td>2022</td>\n      <td>1617784863</td>\n      <td>2021-04-07 08:41:03+00:00</td>\n      <td>story</td>\n      <td>26721951</td>\n      <td>NaN</td>\n      <td>1091.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What books changed the way you think about almost everything?</td>\n      <td>NaN</td>\n      <td>I was reflecting today about how often I think about Freakonomics. I don&amp;#x27;t study it religiously. I read it one time more than 10 years ago. I can only remember maybe a single specific anecdote from the book. And yet the simple idea that basically every action humans take can be traced back to an incentive has fundamentally changed the way I view the world. Can anyone recommend books that have had a similar impact on them?</td>\n      <td>NaN</td>\n      <td>anderspitman</td>\n      <td>2009</td>\n      <td>1549387905</td>\n      <td>2019-02-05 17:31:45+00:00</td>\n      <td>story</td>\n      <td>19087418</td>\n      <td>NaN</td>\n      <td>1165.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\nWe calculate the embeddings using Cohere's `embed-english-v3.0` model. The resulting embeddings matrix has 3,000 rows (one for each post) and 1024 columns (meaning each post title is represented with a 1024-dimensional embedding).\n\n```python\nbatch_size = 90\n\nembeds_list = []\nfor i in range(0, len(df), batch_size):\n    batch = df[i : min(i + batch_size, len(df))]\n    texts = list(batch[\"title\"])\n    embs_batch = co.embed(\n        texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n    ).embeddings\n    embeds_list.extend(embs_batch)\n\nembeds = np.array(embeds_list)\nembeds.shape\n```\n\n```\n(3000, 1024)\n```\n\n## Building a semantic search index\n\nFor nearest-neighbor search, we can use the open-source Annoy library. Let's create a semantic search index and feed it all the embeddings.\n\n```python\nsearch_index = AnnoyIndex(embeds.shape[1], 'angular')\nfor i in range(len(embeds)):\n    search_index.add_item(i, embeds[i])\n\nsearch_index.build(10) # 10 trees\nsearch_index.save('askhn.ann')\n```\n\n```\nTrue\n```\n\n## 1- Given an existing post title, retrieve the most similar posts (nearest neighbor search using embeddings)\n\nWe can query neighbors of a specific post using `get_nns_by_item`.\n\n```python\nexample_id = 50\n\nsimilar_item_ids = search_index.get_nns_by_item(example_id,\n                                                10, # Number of results to retrieve\n                                                include_distances=True)\nresults = pd.DataFrame(data={'post titles': df.iloc[similar_item_ids[0]]['title'],\n                             'distance': similar_item_ids[1]}).drop(example_id)\n\nprint(f\"Query post:'{df.iloc[example_id]['title']}'\\nNearest neighbors:\")\nresults\n```\n\n```\nQuery post:'Pick startups for YC to fund'\nNearest neighbors:\n```\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n```\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n```\n\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>post titles</th>\n      <th>distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2991</th>\n      <td>Best Bank for Startups?</td>\n      <td>0.883494</td>\n    </tr>\n    <tr>\n      <th>2910</th>\n      <td>Who's looking for a cofounder?</td>\n      <td>0.885087</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>What startup/technology is on your 'to watch' list?</td>\n      <td>0.887212</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>What startup/technology is on your 'to watch' list?</td>\n      <td>0.887212</td>\n    </tr>\n    <tr>\n      <th>2123</th>\n      <td>Who is seeking a cofounder?</td>\n      <td>0.889451</td>\n    </tr>\n    <tr>\n      <th>727</th>\n      <td>Agriculture startups doing interesting work?</td>\n      <td>0.899192</td>\n    </tr>\n    <tr>\n      <th>2972</th>\n      <td>How should I evaluate a startup as I job hunt?</td>\n      <td>0.901621</td>\n    </tr>\n    <tr>\n      <th>2589</th>\n      <td>What methods do you use to gain early customers for your startup?</td>\n      <td>0.903065</td>\n    </tr>\n    <tr>\n      <th>2708</th>\n      <td>Is there VC appetite for defense related startups?</td>\n      <td>0.904016</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n## 2- Given a query that we write, retrieve the most similar posts\n\nWe're not limited to searching using existing items. If we get a query, we can embed it and find its nearest neighbors from the dataset.\n\n```python\nquery = \"How can I improve my knowledge of calculus?\"\n\nquery_embed = co.embed(texts=[query],\n                       model=\"embed-english-v3.0\",\n                       truncate=\"RIGHT\",\n                       input_type=\"search_query\").embeddings\n\nsimilar_item_ids = search_index.get_nns_by_vector(query_embed[0], 10, include_distances=True)\n\nresults = pd.DataFrame(data={'texts': df.iloc[similar_item_ids[0]]['title'],\n                             'distance': similar_item_ids[1]})\nprint(f\"Query:'{query}'\\nNearest neighbors:\")\nresults\n```\n\n```\nQuery:'How can I improve my knowledge of calculus?'\nNearest neighbors:\n```\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n```\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n```\n\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>texts</th>\n      <th>distance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2457</th>\n      <td>How do I improve my command of mathematical language?</td>\n      <td>0.931286</td>\n    </tr>\n    <tr>\n      <th>1235</th>\n      <td>How to learn new things better?</td>\n      <td>1.024635</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>How to self-learn math?</td>\n      <td>1.044135</td>\n    </tr>\n    <tr>\n      <th>1317</th>\n      <td>How can I learn to read mathematical notation?</td>\n      <td>1.050976</td>\n    </tr>\n    <tr>\n      <th>910</th>\n      <td>How Do You Learn?</td>\n      <td>1.061253</td>\n    </tr>\n    <tr>\n      <th>2432</th>\n      <td>How did you learn math notation?</td>\n      <td>1.070800</td>\n    </tr>\n    <tr>\n      <th>1994</th>\n      <td>How do I become smarter?</td>\n      <td>1.083434</td>\n    </tr>\n    <tr>\n      <th>1529</th>\n      <td>How do you personally learn?</td>\n      <td>1.086088</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>How do you keep improving?</td>\n      <td>1.087251</td>\n    </tr>\n    <tr>\n      <th>1286</th>\n      <td>How do I learn drawing?</td>\n      <td>1.088468</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n## 3- Plot the archive of articles by similarity\n\nWhat if we want to browse the archive instead of only searching it? Let's plot all the questions in a 2D chart so you're able to visualize the posts in the archive and their similarities.\n\n```python\nreducer = umap.UMAP(n_neighbors=100)\numap_embeds = reducer.fit_transform(embeds)\n```\n\n```python\ndf['x'] = umap_embeds[:,0]\ndf['y'] = umap_embeds[:,1]\n\nchart = alt.Chart(df).mark_circle(size=60).encode(\n    x=#'x',\n    alt.X('x',\n        scale=alt.Scale(zero=False),\n        axis=alt.Axis(labels=False, ticks=False, domain=False)\n    ),\n    y=\n    alt.Y('y',\n        scale=alt.Scale(zero=False),\n        axis=alt.Axis(labels=False, ticks=False, domain=False)\n    ),\n    tooltip=['title']\n    ).configure(background=\"#FDF7F0\"\n    ).properties(\n        width=700,\n        height=400,\n        title='Ask HN: top 3,000 posts'\n        )\n\nchart.interactive()\n```\n\n<style>\n  #altair-viz-fbe8b85b27604922a130b864640c819c.vega-embed {\n    width: 100%;\n    display: flex;\n  }\n\n \n\n<br />\n\n  \\#altair-viz-fbe8b85b27604922a130b864640c819c.vega-embed details,  \n  #altair-viz-fbe8b85b27604922a130b864640c819c.vega-embed details summary {  \n    position: relative;  \n  }  \n</style>\n\n<div id=\"altair-viz-fbe8b85b27604922a130b864640c819c\"></div>\n\n## 4- Cluster the posts to identify the major common themes\n\nLet's proceed to cluster the embeddings using KMeans from scikit-learn.\n\n```python\nn_clusters = 8\n\nkmeans_model = KMeans(n_clusters=n_clusters, random_state=0)\nclasses = kmeans_model.fit_predict(embeds)\n```\n\n## 5- Extract major keywords from each cluster so we can identify what the cluster is about\n\n```python\ndocuments =  df['title']\ndocuments = pd.DataFrame({\"Document\": documents,\n                          \"ID\": range(len(documents)),\n                          \"Topic\": None})\ndocuments['Topic'] = classes\ndocuments_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})\ncount_vectorizer = CountVectorizer(stop_words=\"english\").fit(documents_per_topic.Document)\ncount = count_vectorizer.transform(documents_per_topic.Document)\nwords = count_vectorizer.get_feature_names_out()\n```\n\n```python\nctfidf = ClassTfidfTransformer().fit_transform(count).toarray()\nwords_per_class = {label: [words[index] for index in ctfidf[label].argsort()[-10:]] for label in documents_per_topic.Topic}\ndf['cluster'] = classes\ndf['keywords'] = df['cluster'].map(lambda topic_num: \", \".join(np.array(words_per_class[topic_num])[:]))\n```\n\n## Plot with clusters and keywords information\n\nWe can now plot the documents with their clusters and keywords\n\n```python\nselection = alt.selection_multi(fields=['keywords'], bind='legend')\n\nchart = alt.Chart(df).transform_calculate(\n    url='https://news.ycombinator.com/item?id=' + alt.datum.id\n).mark_circle(size=60, stroke='#666', strokeWidth=1, opacity=0.3).encode(\n    x=#'x',\n    alt.X('x',\n        scale=alt.Scale(zero=False),\n        axis=alt.Axis(labels=False, ticks=False, domain=False)\n    ),\n    y=\n    alt.Y('y',\n        scale=alt.Scale(zero=False),\n        axis=alt.Axis(labels=False, ticks=False, domain=False)\n    ),\n    href='url:N',\n    color=alt.Color('keywords:N',\n                    legend=alt.Legend(columns=1, symbolLimit=0, labelFontSize=14)\n                   ),\n    opacity=alt.condition(selection, alt.value(1), alt.value(0.2)),\n    tooltip=['title', 'keywords', 'cluster', 'score', 'descendants']\n).properties(\n    width=800,\n    height=500\n).add_selection(\n    selection\n).configure_legend(labelLimit= 0).configure_view(\n    strokeWidth=0\n).configure(background=\"#FDF7F0\").properties(\n    title='Ask HN: Top 3,000 Posts'\n)\nchart.interactive()\n```\n\n<style>\n  #altair-viz-a5dcb59584cf4c7d810203872ec4e0ac.vega-embed {\n    width: 100%;\n    display: flex;\n  }\n\n \n\n<br />\n\n  \\#altair-viz-a5dcb59584cf4c7d810203872ec4e0ac.vega-embed details,  \n  #altair-viz-a5dcb59584cf4c7d810203872ec4e0ac.vega-embed details summary {  \n    position: relative;  \n  }  \n</style>\n\n<div id=\"altair-viz-a5dcb59584cf4c7d810203872ec4e0ac\"></div>\n\n## 6- (Experimental) Naming clusters with a generative language model\n\nWhile the extracted keywords do add a lot of information to help us identify the clusters at a glance, we should be able to have a generative model look at these keywords and suggest a name. So far I have reasonable results from a prompt that looks like this:\n\n```\nThe common theme of the following words: books, book, read, the, you, are, what, best, in, your\nis that they all relate to favorite books to read.\n---\nThe common theme of the following words: startup, company, yc, failed\nis that they all relate to startup companies and their failures.\n---\nThe common theme of the following words: freelancer, wants, hired, be, who, seeking, to, 2014, 2020, april\nis that they all relate to hiring for a freelancer to join the team of a startup.\n---\nThe common theme of the following words: <insert keywords here>\nis that they all relate to\n```\n\nThere's a lot of room for improvement though. I'm really excited by this use case because it adds so much information. Imagine if the in the following tree of topics, you assigned each cluster an intelligible name. Then imagine if you assigned each _branching_ a name as well\n\n[block:html]\n{\n  \"html\": \"<img src=\\\"https://raw.githubusercontent.com/cohere-ai/cohere-developer-experience/main/notebooks/images/kmeans-centroid-dendrogram.png\\\" alt=\\\"\\\"/>\"\n}\n[/block]\n\n\nWe can’t wait to see what you start building! Share your projects or find support on our [Discord server](https://discord.com/invite/co-mmunity).",
    "html": "",
    "htmlmode": false,
    "fullscreen": false,
    "hidden": true,
    "revision": 6,
    "_id": "664def02d64f73003c851b6b",
    "__v": 0,
    "createdAt": "2024-05-22T13:11:30.964Z",
    "lastUpdatedHash": "4c5f8f1c9d160290fed465d7f91d998127188c16",
    "project": "62cde2919aafea009aefb289",
    "updatedAt": "2024-07-11T01:20:28.407Z",
    "user": "63fcfa48e37787000ae6fbdd"
  },
  "meta": {
    "user": {
      "allowedProjects": ["cohere-ai", "cohere-enterprise"],
      "apiKey": "",
      "email": "andrewjiang@hey.com",
      "name": "Andrew Jiang",
      "version": 1,
      "Name": "Andrew Jiang",
      "Email": "andrewjiang@hey.com",
      "APIKey": "",
      "AllowedProjects": ["cohere-ai", "cohere-enterprise"]
    },
    "baseUrl": "/",
    "hidden": true,
    "title": "Analyzing Hacker News with Six Language Understanding Methods",
    "metaTitle": "Analyzing Hacker News with Six Language Understanding Methods",
    "keywords": "",
    "description": "",
    "image": [],
    "slug": "analyzing-hacker-news",
    "type": "custompage",
    "full": false
  }
}

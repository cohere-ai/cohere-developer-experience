{
  "custompage": {
    "metadata": {
      "image": [],
      "title": "",
      "description": "",
      "keywords": ""
    },
    "algolia": {
      "recordCount": 7,
      "publishPending": false,
      "updatedAt": "2024-07-11T01:20:20.489Z"
    },
    "title": "Article Recommender with Text Embedding Classification Extraction",
    "slug": "article-recommender-with-text-embeddings",
    "body": "[block:html]\n{\n  \"html\": \"<div class=\\\"cookbook-nav-container\\\">\\n  <a href=\\\"/page/cookbooks\\\" class=\\\"back-button pt-10 group inline-block cursor-pointer font-medium \\\" rel=\\\"noreferrer\\\"\\n    target=\\\"_self\\\">\\n    <div class=\\\"pr-1 inline-block group-hover:no-underline\\\">\\n      <svg width=\\\"11.8\\\" height=\\\"11\\\" viewBox=\\\"0 0 14 13\\\" fill=\\\"none\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\">\\n        <path\\n          d=\\\"M1.1554 7.20808C1.35066 7.40335 1.66724 7.40335 1.8625 7.20808L7.18477 1.88582C7.38003 1.69055 7.38003 1.37397 7.18477 1.17871L6.83121 0.825157C6.63595 0.629895 6.31937 0.629896 6.12411 0.825157L0.801842 6.14742C0.60658 6.34269 0.60658 6.65927 0.801842 6.85453L1.1554 7.20808Z\\\"\\n          fill=\\\"currentColor\\\" />\\n        <path\\n          d=\\\"M1.1554 5.79226C1.35066 5.597 1.66724 5.597 1.8625 5.79226L7.18477 11.1145C7.38003 11.3098 7.38003 11.6264 7.18477 11.8216L6.83121 12.1752C6.63595 12.3705 6.31937 12.3705 6.12411 12.1752L0.801842 6.85292C0.60658 6.65766 0.60658 6.34108 0.801842 6.14582L1.1554 5.79226Z\\\"\\n          fill=\\\"currentColor\\\" />\\n        <path\\n          d=\\\"M2.52491 6.23674C2.52492 5.9606 2.74878 5.73675 3.02491 5.73675H6.28412C6.4513 5.73675 6.60742 5.8203 6.70015 5.95941L7.03347 6.45941C7.25499 6.79169 7.01679 7.23675 6.61745 7.23675H3.0249C2.74876 7.23675 2.5249 7.01289 2.5249 6.73674L2.52491 6.23674Z\\\"\\n          fill=\\\"currentColor\\\" />\\n        <path\\n          d=\\\"M13.5517 6.73676C13.5517 7.0129 13.3278 7.23675 13.0517 7.23675H8.79246C8.62528 7.23675 8.46916 7.1532 8.37643 7.0141L8.04311 6.5141C7.8216 6.18182 8.05979 5.73675 8.45914 5.73675H13.0517C13.3278 5.73675 13.5517 5.96062 13.5517 6.23676L13.5517 6.73676Z\\\"\\n          fill=\\\"currentColor\\\" />\\n      </svg>\\n    </div>\\n    Back to Cookbooks\\n  </a>\\n\\n  <a href=https://github.com/cohere-ai/cohere-developer-experience/blob/main/notebooks/guides/Article_Recommender_with_Text_Embedding_Classification_Extraction.ipynb class=\\\"github-button pt-10 group inline-block cursor-pointer font-medium \\\" rel=\\\"noreferrer\\\"\\n    target=\\\"_blank\\\">\\n    Open in GitHub\\n    <div class=\\\"pl-1 inline-block group-hover:no-underline\\\">\\n      <svg width=\\\"14\\\" height=\\\"10\\\" viewBox=\\\"0 0 14 10\\\" fill=\\\"none\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\">\\n        <path\\n          d=\\\"M8.63218 0.366821C8.35604 0.366821 8.13218 0.590679 8.13218 0.866821V8.39364C8.13218 8.66978 8.35604 8.89364 8.63218 8.89364H9.13218C9.40832 8.89364 9.63218 8.66978 9.63218 8.39364V0.866821C9.63218 0.590678 9.40832 0.366821 9.13218 0.366821H8.63218Z\\\"\\n          fill=\\\"currentColor\\\" />\\n        <path\\n          d=\\\"M9.63332 1.36796C9.63332 1.6441 9.40946 1.86796 9.13332 1.86796H1.6065C1.33035 1.86796 1.1065 1.6441 1.1065 1.36796V0.867956C1.1065 0.591813 1.33035 0.367956 1.6065 0.367956H9.13332C9.40946 0.367956 9.63332 0.591813 9.63332 0.867956V1.36796Z\\\"\\n          fill=\\\"currentColor\\\" />\\n        <path\\n          d=\\\"M8.35063 2.02206C8.54588 2.21732 8.54588 2.5339 8.35062 2.72916L6.04601 5.03377C5.9278 5.15198 5.75833 5.20329 5.59439 5.1705L5.00515 5.05264C4.61356 4.97432 4.46728 4.49118 4.74966 4.2088L7.28997 1.66849C7.48523 1.47323 7.80182 1.47323 7.99708 1.6685L8.35063 2.02206Z\\\"\\n          fill=\\\"currentColor\\\" />\\n        <path\\n          d=\\\"M0.199967 9.46558C0.0047119 9.27032 0.0047151 8.95374 0.199974 8.75848L3.21169 5.74677C3.3299 5.62855 3.49938 5.57724 3.66331 5.61003L4.25256 5.72789C4.64414 5.80621 4.79042 6.28935 4.50804 6.57173L1.26063 9.81915C1.06536 10.0144 0.748774 10.0144 0.553513 9.81914L0.199967 9.46558Z\\\"\\n          fill=\\\"currentColor\\\" />\\n      </svg>\\n    </div>\\n  </a>\\n</div>\\n\\n<div>\\n  <h1>Article Recommender with Text Embedding Classification Extraction</h1>\\n</div>\\n\\n<style>\\n  .header {\\n    padding: 9px 0 17px 0;\\n    display: flex;\\n    flex-direction: column;\\n  }\\n\\n  a[href],\\n  .field-description a:not([href=\\\"\\\"]),\\n  .markdown-body a[href],\\n  .markdown-body a:not([href=\\\"\\\"]) {\\n    text-decoration: none;\\n  }\\n\\n  #content {\\n    padding: 0 32px;\\n  }\\n\\n  #content-head {\\n    display: none;\\n  }\\n\\n  .guide-page-title {\\n    font-size: 29px !important;\\n  }\\n\\n  .back-button .github-button {\\n    border-radius: 0 !important;\\n    border-width: 0 !important;\\n    background-color: inherit !important;\\n  }\\n\\n  .cookbook-nav-container {\\n    display: flex;\\n    flex-direction: row;\\n    justify-content: space-between;\\n    align-items: center;\\n  }\\n\\n  @media only screen and (min-width: 620px) {\\n    .guide-page-title {\\n      width: 70%;\\n    }\\n\\n    .header {\\n      display: flex;\\n      flex-direction: row;\\n      align-items: center;\\n      justify-content: space-between;\\n      padding: 9px 0 17px 0;\\n    }\\n\\n    .git--button {\\n      width: 145px !important;\\n      display: flex;\\n      flex-direction: row;\\n      justify-content: center;\\n      align-items: center;\\n      padding: 8px 16px;\\n\\n      width: 154px;\\n      height: 35px;\\n\\n      background: #D4D9D4;\\n      border: 1px solid #9DAAA4;\\n      border-radius: 6px;\\n    }\\n  }\\n\\n\\n  @media only screen and (min-width: 1024px) {\\n    .guide-page-title {\\n      font-size: 46px !important;\\n    }\\n\\n    .header {\\n      padding: 9px 0 32px 0;\\n    }\\n  }\\n</style>\"\n}\n[/block]\n\n\n## Article Recommender with Text Embedding, Classification, and Extraction\n\nThis is a simple demonstration of how we can stack multiple NLP models together  \nto get an output much closer to our desired outcome.\n\nEmbeddings can capture the meaning of a piece of text beyond keyword-matching. In this article, we will build a simple news article recommender system that computes the embeddings of all available articles and recommend the most relevant articles based on embeddings similarity. \n\nWe will also make the recommendation tighter by using text classification to recommend only articles within the same category. We will then extract a list of tags from each recommended article, which can further help readers discover new articles. \n\nAll this will be done via three Cohere API endpoints stacked together: Embed, Classify, and Chat.\n\n[block:html]\n{\n  \"html\": \"<img src=\\\"https://github.com/cohere-ai/cohere-developer-experience/raw/main/notebooks/images/article-recommender/article-rec-1.png\\\" alt=\\\"Article recommender with Embed, Classify, and Chat\\\"/>\"\n}\n[/block]\n\n\nWe will implement the following steps:\n\n**1: Find the most similar articles to the one currently reading using embeddings.**\n\n**2: Keep only articles of the same category using text classification.**\n\n**3: Extract tags from these articles.**\n\n**4: Show the top 5 recommended articles.**\n\n```python\n! pip install cohere\n```\n\n```\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting cohere\n  Downloading cohere-1.3.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n\u001b[K     |████████████████████████████████| 18.0 MB 135 kB/s \n\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from cohere) (2.23.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (1.24.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (2022.6.15)\nRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (2.10)\nRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (3.0.4)\nInstalling collected packages: cohere\nSuccessfully installed cohere-1.3.10\n```\n\n```python\nimport numpy as np\nimport pandas as pd\nimport re\nimport cohere\n\nco = cohere.Client(\"COHERE_API_KEY\") # Get your API key: https://dashboard.cohere.com/api-keys\n\n```\n\n[block:html]\n{\n  \"html\": \"<img src=\\\"https://github.com/cohere-ai/cohere-developer-experience/raw/main/notebooks/images/article-recommender/article-rec-2.png\\\" alt=\\\"Step 1 - Embed\\\"/>\"\n}\n[/block]\n\n\n## 1.1: Get articles\n\nThroughout this article, we'll use the [BBC news article dataset](https://www.kaggle.com/competitions/learn-ai-bbc/data?select=BBC+News+Train.csv) as an example [\\[Source\\]](http://mlg.ucd.ie/datasets/bbc.html). This dataset consists of articles from a few categories: business, politics, tech, entertainment, and sport.\n\nWe'll extract a subset of the data and in Step 1, use the first 100 data points.\n\n```python\ndf = pd.read_csv('https://raw.githubusercontent.com/cohere-ai/cohere-developer-experience/main/notebooks/data/bbc_news_subset.csv', delimiter=',')\n\nINP_START = 0\nINP_END = 100\ndf_inputs = df.iloc[INP_START:INP_END]\ndf_inputs = df_inputs.copy()\n\ndf_inputs.drop(['ArticleId','Category'],axis=1,inplace=True)\n\ndf_inputs.head()\n```\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n```\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n```\n\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>worldcom ex-boss launches defence lawyers defe...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>german business confidence slides german busin...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bbc poll indicates economic gloom citizens in ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lifestyle  governs mobile choice  faster  bett...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>enron bosses in $168m payout eighteen former e...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n## 1.2: Turn articles into embeddings\n\nNext we turn each article text into embeddings. An [embedding](https://docs.cohere.ai/embedding-wiki) is a list of numbers that our models use to represent a piece of text, capturing its context and meaning.\n\nWe do this by calling Cohere's [Embed endpoint](https://docs.cohere.ai/embed-reference), which takes in text as input and returns embeddings as output.\n\n```python\narticles = df_inputs['Text'].tolist()\n\noutput = co.embed(\n            model ='embed-english-v3.0',\n            input_type='search_document',\n            texts = articles)\nembeds = output.embeddings\n\nprint('Number of articles:', len(embeds))\n```\n\n```\nNumber of articles: 100\n```\n\n## 1.3: Pick one article and find the most similar articles\n\nNext, we pick any one article to be the one the reader is currently reading (let's call this the target) and find other articles with the most similar embeddings (let's call these candidates) using cosine similarity.\n\n[Cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) is a metric that measures how similar sequences of numbers are (embeddings in our case), and we compute it for each target-candidate pair. \n\n```python\nprint(f'Choose one article ID between {INP_START} and {INP_END-1} below...')\n```\n\n```\nChoose one article ID between 0 and 99 below...\n```\n\n```python\nREADING_IDX = 70\n\nreading = embeds[READING_IDX]\n```\n\n```python\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef get_similarity(target,candidates):\n  # Turn list into array\n  candidates = np.array(candidates)\n  target = np.expand_dims(np.array(target),axis=0)\n\n  # Calculate cosine similarity\n  similarity_scores = cosine_similarity(target,candidates)\n  similarity_scores = np.squeeze(similarity_scores).tolist()\n\n  # Sort by descending order in similarity\n  similarity_scores = list(enumerate(similarity_scores))\n  similarity_scores = sorted(similarity_scores, key=lambda x:x[1], reverse=True)\n\n  # Return similarity scores\n  return similarity_scores\n```\n\n```python\nsimilarity = get_similarity(reading,embeds)\n\nprint('Target:')\nprint(f'[ID {READING_IDX}]',df_inputs['Text'][READING_IDX][:100],'...','\\n')\n\nprint('Candidates:')\nfor i in similarity[1:6]: # Exclude the target article\n  print(f'[ID {i[0]}]',df_inputs['Text'][i[0]][:100],'...')\n```\n\n```\nTarget:\n[ID 70] aragones angered by racism fine spain coach luis aragones is furious after being fined by the spanis ... \n\nCandidates:\n[ID 23] ferguson urges henry punishment sir alex ferguson has called on the football association to punish a ...\n[ID 51] mourinho defiant on chelsea form chelsea boss jose mourinho has insisted that sir alex ferguson and  ...\n[ID 73] balco case trial date pushed back the trial date for the bay area laboratory cooperative (balco) ste ...\n[ID 41] mcleish ready for criticism rangers manager alex mcleish accepts he is going to be criticised after  ...\n[ID 42] premier league planning cole date the premier league is attempting to find a mutually convenient dat ...\n```\n\n[block:html]\n{\n  \"html\": \"<img src=\\\"https://github.com/cohere-ai/cohere-developer-experience/raw/main/notebooks/images/article-recommender/article-rec-3.png\\\" alt=\\\"Step 2 - Classify\\\"/>\"\n}\n[/block]\n\n\nTwo articles may be similar but they may not necessarily belong to the same category. For example, an article about a sports team manager facing a fine may be similar to another about a business entity facing a fine, but they are not of the same category.\n\nPerhaps we can make the system better by only recommending articles of the same category. For this, let's build a news category classifier.\n\n## 2.1: Build a classifier\n\nWe use Cohere's [Classify endpoint](https://docs.cohere.ai/classify-reference) to build a news category classifier, classifying articles into five categories: Business, Politics, Tech, Entertainment, and Sport. \n\nA typical text classification model requires hundreds/thousands of data points to train, but with this endpoint, we can build a classifier with a few as five examples per class.\n\nTo build the classifier, we need a set of examples consisting of text (news text) and labels (news category). The BBC News dataset happens to have both (columns 'Text' and 'Category'), so this time we’ll use the categories for building our examples. For this, we will set aside another portion of dataset.\n\n```python\nEX_START = 100\nEX_END = 200\ndf_examples = df.iloc[EX_START:EX_END]\ndf_examples = df_examples.copy()\n\ndf_examples.drop(['ArticleId'],axis=1,inplace=True)\n\ndf_examples.head()\n```\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n```\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n```\n\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>100</th>\n      <td>honda wins china copyright ruling japan s hond...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>ukip could sue veritas defectors the uk indepe...</td>\n      <td>politics</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>security warning over  fbi virus  the us feder...</td>\n      <td>tech</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>europe backs digital tv lifestyle how people r...</td>\n      <td>tech</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>celebrities get to stay in jungle all four con...</td>\n      <td>entertainment</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\nWith the Classify endpoint, there is a limit of 512 tokens per input. This means full articles won't be able to fit in the examples, so we will approximate and limit each article to its first 300 characters.\n\n```python\nMAX_CHARS = 300\n\ndef shorten_text(text):\n  return text[:MAX_CHARS]\n\ndf_examples['Text'] = df_examples['Text'].apply(shorten_text)\n```\n\nThe Classify endpoint needs a minimum of 2 examples for each category. We'll have 5 examples each, sampled randomly from the dataset. We have 5 categories, so we will have a total of 25 examples.\n\n```python\nEX_PER_CAT = 5 \n\ncategories = df_examples['Category'].unique().tolist()\n\nex_texts = []\nex_labels = []\nfor category in categories:\n  df_category = df_examples[df_examples['Category'] == category]\n  samples = df_category.sample(n=EX_PER_CAT, random_state=42)\n  ex_texts += samples['Text'].tolist()\n  ex_labels += samples['Category'].tolist()\n\nprint(f'Number of examples per category: {EX_PER_CAT}')\nprint(f'List of categories: {categories}')\nprint(f'Number of categories: {len(categories)}')\nprint(f'Total number of examples: {len(ex_texts)}')\n```\n\n```\nNumber of examples per category: 5\nList of categories: ['business', 'politics', 'tech', 'entertainment', 'sport']\nNumber of categories: 5\nTotal number of examples: 25\n```\n\nOnce the examples are ready, we can now get the classifications. Here is a function that returns the classification given an input.\n\n```python\n\nfrom cohere import ClassifyExample\n\nexamples = []\nfor txt, lbl in zip(ex_texts,ex_labels):\n  examples.append(ClassifyExample(text=txt, label=lbl))\n\ndef classify_text(texts, examples):\n    classifications = co.classify(\n        inputs=texts,\n        examples=examples\n    )\n\n    return [c.prediction for c in classifications.classifications]\n```\n\n## 2.2: Measure its performance\n\nBefore actually using the classifier, let's first test its performance. Here we take another 100 data points as the test dataset and the classifier will predict its class i.e. news category.\n\n```python\nTEST_START = 200\nTEST_END = 300\ndf_test = df.iloc[TEST_START:TEST_END]\ndf_test = df_test.copy()\n\ndf_test.drop(['ArticleId'],axis=1,inplace=True)\n\ndf_test['Text'] = df_test['Text'].apply(shorten_text)\n\ndf_test.head()\n```\n\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n```\n.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}\n```\n\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>200</th>\n      <td>sa return to mauritius top seeds south africa ...</td>\n      <td>sport</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>snow patrol feted at irish awards snow patrol ...</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>clyde 0-5 celtic celtic brushed aside clyde to...</td>\n      <td>sport</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>bad weather hits nestle sales a combination of...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>204</th>\n      <td>net fingerprints combat attacks eighty large n...</td>\n      <td>tech</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n\n```python\npredictions = []\nBATCH_SIZE = 90 # The API accepts a maximum of 96 inputs\nfor i in range(0, len(df_test['Text']), BATCH_SIZE):\n    batch_texts = df_test['Text'][i:i+BATCH_SIZE].tolist()\n    predictions.extend(classify_text(batch_texts, examples))    \n    \nactual = df_test['Category'].tolist()\n```\n\n```python\nfrom sklearn.metrics import accuracy_score\n\naccuracy = accuracy_score(actual, predictions)\nprint(f'Accuracy: {accuracy*100}')\n```\n\n```\nAccuracy: 89.0\n```\n\nWe get a good accuracy score of 91%, so the classifier is ready to be  \nimplemented in our recommender system.\n\n[block:html]\n{\n  \"html\": \"<img src=\\\"https://github.com/cohere-ai/cohere-developer-experience/raw/main/notebooks/images/article-recommender/article-rec-4.png\\\" alt=\\\"Step 3 - Extract\\\"/>\"\n}\n[/block]\n\n\nWe now proceed to the tags extraction step. Compared to the previous two steps, this step is not about sorting or filtering articles, but rather enriching them with more information. \n\nWe do this with the Chat endpoint.\n\nWe call the endpoint by specifying a few settings, and it will generate the corresponding extractions.\n\n```python\ndef extract_tags(article):\n  prompt = f\"\"\"Given an article, extract a list of tags containing keywords of that article.\n\nArticle: japanese banking battle at an end japan s sumitomo mitsui \\\nfinancial has withdrawn its takeover offer for rival bank ufj holdings enabling the \\\nlatter to merge with mitsubishi tokyo.  sumitomo bosses told counterparts at ufj of its \\\ndecision on friday  clearing the way for it to conclude a 3 trillion\n\nTags: sumitomo mitsui financial, ufj holdings, mitsubishi tokyo, japanese banking\n\nArticle:france starts digital terrestrial france has become the last big european country to \\\nlaunch a digital terrestrial tv (dtt) service.  initially  more than a third of the \\\npopulation will be able to receive 14 free-to-air channels. despite the long wait for a \\\nfrench dtt roll-out  the new platform s bac\n\nTags: france, digital terrestrial\n\nArticle: apple laptop is  greatest gadget  the apple powerbook 100 has been chosen as the greatest \\\ngadget of all time  by us magazine mobile pc.  the 1991 laptop was chosen because it was \\\none of the first  lightweight  portable computers and helped define the layout of all future \\\nnotebook pcs. the magazine h\n\nTags: apple, apple powerbook 100, laptop\n\n\nArticle:{article}\n\nTags:\"\"\"\n  \n  \n  response = co.chat(\n    model='command-r',\n    message=prompt,\n    preamble=\"\")\n\n  return response.text\n```\n\n[block:html]\n{\n  \"html\": \"<img src=\\\"https://github.com/cohere-ai/cohere-developer-experience/raw/main/notebooks/images/article-recommender/article-rec-5.png\\\" alt=\\\"Complete all steps\\\"/>\"\n}\n[/block]\n\n\nLet's now put everything together for our article recommender system.\n\nFirst, we select the target article and compute the similarity scores against the candidate articles.\n\n```python\nprint(f'Choose one article ID between {INP_START} and {INP_END-1} below...')\n```\n\n```\nChoose one article ID between 0 and 99 below...\n```\n\n```python\nREADING_IDX = 70\n\nreading = embeds[READING_IDX]\n\nsimilarity = get_similarity(reading,embeds)\n```\n\nNext, we filter the articles via classification. Finally, we extract the keywords from each article and show the recommendations.\n\n```python\nSHOW_TOP = 5\n\ndf_inputs = df_inputs.copy()\ndf_inputs['Text'] = df_inputs['Text'].apply(shorten_text)\n\ndef get_recommendations(reading_idx,similarity,show_top):\n\n  # Show the current article\n  print('------  You are reading...  ------')\n  print(f'[ID {READING_IDX}] Article:',df_inputs['Text'][reading_idx][:MAX_CHARS]+'...\\n')\n\n  # Show the recommended articles\n  print('------  You might also like...  ------')\n\n  # Classify the target article\n  target_class = classify_text([df_inputs['Text'][reading_idx]],examples)\n  print(target_class)\n\n  count = 0\n  for idx,score in similarity:\n\n    # Classify each candidate article\n    candidate_class = classify_text([df_inputs['Text'][idx]],examples)\n    \n    # Show recommendations\n    if target_class == candidate_class and idx != reading_idx:\n      selection = df_inputs['Text'][idx][:MAX_CHARS]\n      print(f'[ID {idx}] Article:',selection+'...')\n\n      # Extract and show tags\n      tags = extract_tags(selection)\n      if tags:\n          print(f'Tags: {tags.strip()}\\n')\n      else:\n          print(f'Tags: none\\n')      \n\n      # Increment the article count\n      count += 1\n\n      # Stop once articles reach the SHOW_TOP number\n      if count == show_top:\n        break\n```\n\n```python\nget_recommendations(READING_IDX,similarity,SHOW_TOP)\n```\n\n```\n------  You are reading...  ------\n[ID 70] Article: aragones angered by racism fine spain coach luis aragones is furious after being fined by the spanish football federation for his comments about thierry henry.  the 66-year-old criticised his 3000 euros (£2 060) punishment even though it was far below the maximum penalty.  i am not guilty  nor do i ...\n\n------  You might also like...  ------\n[ID 23] Article: ferguson urges henry punishment sir alex ferguson has called on the football association to punish arsenal s thierry henry for an incident involving gabriel heinze.  ferguson believes henry deliberately caught heinze on the head with his knee during united s controversial win. the united boss said i...\nTags: football, sir alex ferguson, thierry henry, arsenal, manchester united\n\n[ID 51] Article: mourinho defiant on chelsea form chelsea boss jose mourinho has insisted that sir alex ferguson and arsene wenger would swap places with him.  mourinho s side were knocked out of the fa cup by newcastle last sunday before seeing barcelona secure a 2-1 champions league first-leg lead in the nou camp....\nTags: chelsea, jose mourinho, sir alex ferguson, arsene wenger, fa cup, newcastle, barcelona, champions league\n\n[ID 41] Article: mcleish ready for criticism rangers manager alex mcleish accepts he is going to be criticised after their disastrous uefa cup exit at the hands of auxerre at ibrox on wednesday.  mcleish told bbc radio five live:  we were in pole position to get through to the next stage but we blew it  we absolutel...\nTags: rangers, alex mcleish, auxerre, uefa cup, ibrox\n\n[ID 42] Article: premier league planning cole date the premier league is attempting to find a mutually convenient date to investigate allegations chelsea made an illegal approach for ashley cole.  both chelsea and arsenal will be asked to give evidence to a premier league commission  but no deadline has been put on ...\nTags: premier league, chelsea, arsenal, ashley cole\n\n[ID 14] Article: ireland 21-19 argentina an injury-time dropped goal by ronan o gara stole victory for ireland from underneath the noses of argentina at lansdowne road on saturday.  o gara kicked all of ireland s points  with two dropped goals and five penalties  to give the home side a 100% record in their autumn i...\nTags: rugby, ireland, argentina, ronan o gara\n```\n\nKeeping to the Section 1.3 example, here we see how the classification and extraction steps have improved our recommendation outcome.\n\nFirst, now the article with ID 73 (non sport) doesn't get recommended anymore. And now we have the tags related to each article being generated. \n\nLet's try a couple of other articles in business and tech and see the output...\n\nBusiness article (returning recommendations around German economy and economic growth/slump):\n\n```python\n\nREADING_IDX = 1\n\nreading = embeds[READING_IDX]\n\nsimilarity = get_similarity(reading,embeds)\n\nget_recommendations(READING_IDX,similarity,SHOW_TOP)\n```\n\n```\n------  You are reading...  ------\n[ID 1] Article: german business confidence slides german business confidence fell in february knocking hopes of a speedy recovery in europe s largest economy.  munich-based research institute ifo said that its confidence index fell to 95.5 in february from 97.5 in january  its first decline in three months. the stu...\n\n------  You might also like...  ------\n[ID 56] Article: borussia dortmund near bust german football club and former european champion borussia dortmund has warned it will go bankrupt if rescue talks with creditors fail.  the company s shares tumbled after it said it has  entered a life-threatening profitability and financial situation . borussia dortmund...\nTags: borussia dortmund, german football, bankruptcy\n\n[ID 2] Article: bbc poll indicates economic gloom citizens in a majority of nations surveyed in a bbc world service poll believe the world economy is worsening.  most respondents also said their national economy was getting worse. but when asked about their own family s financial outlook  a majority in 14 countries...\nTags: bbc, economy, financial outlook\n\n[ID 8] Article: car giant hit by mercedes slump a slump in profitability at luxury car maker mercedes has prompted a big drop in profits at parent daimlerchrysler.  the german-us carmaker saw fourth quarter operating profits fall to 785m euros ($1bn) from 2.4bn euros in 2003. mercedes-benz s woes - its profits slid...\nTags: daimlerchrysler, mercedes, luxury car, profitability\n\n[ID 32] Article: china continues rapid growth china s economy has expanded by a breakneck 9.5% during 2004  faster than predicted and well above 2003 s 9.1%.  the news may mean more limits on investment and lending as beijing tries to take the economy off the boil. china has sucked in raw materials and energy to fee...\nTags: china, economy, beijing\n\n[ID 96] Article: bmw to recall faulty diesel cars bmw is to recall all cars equipped with a faulty diesel fuel-injection pump supplied by parts maker robert bosch.  the faulty part does not represent a safety risk and the recall only affects pumps made in december and january. bmw said that it was too early to say h...\nTags: bmw, diesel cars, robert bosch, fuel injection pump\n```\n\nTech article (returning recommendations around consumer devices):\n\n```python\n\nREADING_IDX = 71\n\nreading = embeds[READING_IDX]\n\nsimilarity = get_similarity(reading,embeds)\n\nget_recommendations(READING_IDX,similarity,SHOW_TOP)\n```\n\n```\n------  You are reading...  ------\n[ID 71] Article: camera phones are  must-haves  four times more mobiles with cameras in them will be sold in europe by the end of 2004 than last year  says a report from analysts gartner.  globally  the number sold will reach 159 million  an increase of 104%. the report predicts that nearly 70% of all mobile phones ...\n\n------  You might also like...  ------\n[ID 3] Article: lifestyle  governs mobile choice  faster  better or funkier hardware alone is not going to help phone firms sell more handsets  research suggests.  instead  phone firms keen to get more out of their customers should not just be pushing the technology for its own sake. consumers are far more interest...\nTags: mobile, lifestyle, phone firms, handsets\n\n[ID 69] Article: gates opens biggest gadget fair bill gates has opened the consumer electronics show (ces) in las vegas  saying that gadgets are working together more to help people manage multimedia content around the home and on the move.  mr gates made no announcement about the next generation xbox games console ...\nTags: bill gates, consumer electronics show, gadgets, xbox\n\n[ID 46] Article: china  ripe  for media explosion asia is set to drive global media growth to 2008 and beyond  with china and india filling the two top spots  analysts have predicted.  japan  south korea and singapore will also be strong players  but china s demographics give it the edge  a media conference in londo...\nTags: china, india, japan, south korea, singapore, global media growth\n\n[ID 19] Article: moving mobile improves golf swing a mobile phone that recognises and responds to movements has been launched in japan.  the motion-sensitive phone - officially titled the v603sh - was developed by sharp and launched by vodafone s japanese division. devised mainly for mobile gaming  users can also ac...\nTags: mobile phone, japan, sharp, vodafone, golf swing\n\n[ID 63] Article: what high-definition will do to dvds first it was the humble home video  then it was the dvd  and now hollywood is preparing for the next revolution in home entertainment - high-definition.  high-definition gives incredible  3d-like pictures and surround sound. the dvd disks and the gear to play the...\nTags: high-definition, dvd, hollywood, home entertainment\n```\n\nIn conclusion, this demonstrates an example of how we can stack multiple NLP endpoints together to get an output much closer to our desired outcome.\n\nIn practice, hosting and maintaining multiple models can turn quickly into a complex activity. But by leveraging Cohere endpoints, this task is reduced to a simple API call.",
    "html": "",
    "htmlmode": false,
    "fullscreen": false,
    "hidden": true,
    "revision": 7,
    "_id": "664cbbc8bfcd8c0019287c49",
    "__v": 0,
    "createdAt": "2024-05-21T15:20:40.461Z",
    "lastUpdatedHash": "caad8b160c1620625b525dd49612345afd6f115c",
    "project": "62cde2919aafea009aefb289",
    "updatedAt": "2024-07-11T01:20:20.489Z",
    "user": "63fcfa48e37787000ae6fbdd"
  },
  "meta": {
    "user": {
      "allowedProjects": ["cohere-ai", "cohere-enterprise"],
      "apiKey": "",
      "email": "andrewjiang@hey.com",
      "name": "Andrew Jiang",
      "version": 1,
      "Name": "Andrew Jiang",
      "Email": "andrewjiang@hey.com",
      "APIKey": "",
      "AllowedProjects": ["cohere-ai", "cohere-enterprise"]
    },
    "baseUrl": "/",
    "hidden": true,
    "title": "Article Recommender with Text Embedding Classification Extraction",
    "metaTitle": "Article Recommender with Text Embedding Classification Extraction",
    "keywords": "",
    "description": "",
    "image": [],
    "slug": "article-recommender-with-text-embeddings",
    "type": "custompage",
    "full": false
  }
}

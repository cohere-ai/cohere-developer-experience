---
title: "Command R: Retrieval-Augmented Generation at Production Scale"
slug: "changelog/command-r-retrieval-augmented-generation-at-production-scale"
type: ""
createdAt: "Sun Mar 24 2024 18:44:00 GMT+0000 (Coordinated Universal Time)"
hidden: false
description: "Command R: Retrieval Augmented Generation at scale."
image: "../../assets/images/eede06c-cohere_meta_image.jpg"   
---
Today, we are introducing Command R, a new LLM aimed at large-scale production workloads. Command R targets the emerging “scalable” category of models that balance high efficiency with strong accuracy, enabling companies to move beyond proof of concept, and into production.

Command R is a generative model optimized for long context tasks such as retrieval-augmented generation (RAG) and using external APIs and tools. It is designed to work in concert with our industry-leading Embed and Rerank models to provide best-in-class integration for RAG applications and excel at enterprise use cases. As a model built for companies to implement at scale, Command R boasts:

- Strong accuracy on RAG and Tool Use
- Low latency, and high throughput
- Longer 128k context and lower pricing
- Strong capabilities across 10 key languages
- Model weights available on HuggingFace for research and evaluation

For more information, check out the [official blog post](https://cohere.com/blog/command-r/) or the [Command R documentation](/docs/command-r).

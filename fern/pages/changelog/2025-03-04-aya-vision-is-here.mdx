---
title: "Our Groundbreaking Multimodal Model, Aya Vision, is Here!"
slug: "changelog/aya-vision-announcement"
createdAt: "Wed Feb 26 2025 00:00:00 (MST)"
hidden: false
description: >-
  Release announcement for the new multimodal Aya Vision model 
---

Today, Cohere Labs, Cohereâ€™s research arm, is proud to announce [Aya Vision](https://cohere.com/blog/aya-vision), a state-of-the-art multimodal large language model excelling across multiple languages and modalities. Aya Vision outperforms the leading open-weight models in critical benchmarks for language, text, and image capabilities. 

built as a foundation for multilingual and multimodal communication, this groundbreaking AI model supports tasks such as image captioning, visual question answering, text generation, and translations from both texts and images into coherent text.

Find more information about Aya Vision [here](/docs/aya-multimodal).

---
title: 'Release Notes January 22, 2024'
slug: changelog/release-notes-january-x-2024
type: ''
createdAt: 'Tue Jan 02 2024 19:15:05 GMT+0000 (Coordinated Universal Time)'
hidden: false
description: >-
  Discover new AI capabilities with Cohere's latest features, including improved
  fine-tuning, Embed Jobs API, and multi-language SDK support.
---
## Apply Cohere's AI with Connectors!

One of the most exciting applications of generative AI is known as ["retrieval augmented generation"](/docs/retrieval-augmented-generation-rag) (RAG). This refers to the practice of _grounding_ the outputs of a large language model (LLM) by offering it resources -- like your internal technical documentation, chat logs, etc. -- from which to draw as it formulates its replies. 

Cohere has made it much easier to utilize RAG in bespoke applications via [Connectors](/docs/overview-rag-connectors). As the name implies, Connectors allow you to _connect_ Cohere's generative AI platform up to whatever resources you'd like it to ground on, facilitating the creation of a wide variety of applications -- customer service chatbots, internal tutors, or whatever else you want to build.

Our docs cover how to [create and deploy connectors](/docs/creating-and-deploying-a-connector), [how to manage your connectors ](/docs/managing-your-connector), [how to handle authentication](/docs/connector-authentication), and [more](/docs/connector-faqs)!

## Expanded Fine-tuning Functionality

Cohere's ready-to-use LLMs, such as Command, are very good at producing responses to natural language prompts. However, there are many cases in which getting the best model performance requires performing an additional round of training on custom user data. This is process known as fine-tuning, and we've dramatically revamped our [fine-tuning documentation](/docs/fine-tuning). 

The new docs are organized according to the major endpoints, and we support fine-tuning for [Generate](/docs/generate-fine-tuning), [Classify](/docs/classify-fine-tuning), [Rerank](/docs/rerank-fine-tuning), and [Chat](/docs/chat-fine-tuning).

But wait, there's more: many developers work with generative AI through popular cloud-compute platforms like Amazon Web Services (AWS), and we support [fine-tuning on AWS Bedrock](/docs/fine-tuning-cohere-models-on-amazon-bedrock). We also support fine-tuning with Sagemaker, and the relevant documentation will be published in the coming weeks.  

## A new Embed Jobs API Endpoint Has Been Released

The [Embed Jobs API](/docs/embed-jobs-api) was designed for users who want to leverage the power of retrieval over large corpuses of information. Encoding a large volume of documents with an API can be tedious and difficult, but the Embed Jobs API makes it a breeze to handle encoding workflows involving 100,000 documents, or more! 

The API works in conjunction with `co.embed()`. For more information, [consult the docs](/docs/embed-jobs-api). 

## Our SDK now Supports More Languages

Throughout our documentation you'll find code-snippets for performing common tasks with Python. Recently, we made the decision to expand these code snippets to include Typescript and Go, and are working to include several other popular languages as well.

---
title: Toxicity Detection
slug: docs/toxicity-detection
subtitle: >-
  This endpoint classifies text into one of several classes. It uses a few
  examples to create a classifier from a generative model. In the background, it
  constructs a few-shot classification prompt and uses it classify the `input`
  texts you pass to it.
hidden: false
description: >-
  Learn how to automatically flag toxic online user comments and classify them
  as either toxic or non-toxic.
image: ../../../assets/images/68e785a-meta_docs_image_cohere.jpg
createdAt: 'Thu Sep 08 2022 23:27:58 GMT+0000 (Coordinated Universal Time)'
updatedAt: 'Fri Mar 15 2024 04:33:37 GMT+0000 (Coordinated Universal Time)'
---
<Note title="This is an interactive tutorial!">  
 To run this tutorial, click on **Examples** and select one of the options.
</Note>

The internet is dominated by user-generated content. While it provides an avenue for online platforms to grow, it is a bane for content moderators managing them. It is impossible for humans to manually moderate all the user content that is created. This is why an automated solution is needed, such as in flagging for toxic content.

Here we look at an example of classifying online user comments for toxicity by classifying them in `Toxic` or `Not Toxic`.

## Set up

Install the SDK.

---
title: "Module 7: Retrieval-Augmented Generation (RAG)"
slug: "docs/module-8-chat-and-retrieval-augmented-generation-rag"

hidden: false
createdAt: "Mon Nov 20 2023 02:16:44 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Wed Jun 05 2024 02:41:57 GMT+0000 (Coordinated Universal Time)"
---
Welcome to the Retrieval-Augmented Generation (RAG) module!

RAG is an approach that significantly reduces the hallucination issue common in LLMs. RAG enables the model to access and utilize supplementary information from external data sources, thereby improving the accuracy of its responses.

By the end of this module, you will be able to build RAG-powered applications by leveraging various Cohere endpoints – Chat, Embed, and Rerank. You will also learn how to use quickstart connectors, which are pre-built implementations to connect a RAG application to over 80 enterprise datastores.

Here is what you'll learn in this module:

- **[Getting Started With RAG](https://cohere.com/llmu/rag-start/)**: Learn the basics of RAG and how to get started with RAG with the Chat endpoint.
- **[RAG With Chat, Embed, and Rerank](https://cohere.com/llmu/rag-chatbot/)**: Learn how to build a RAG-powered chatbot using the Chat, Embed, and Rerank endpoints.
- **[RAG With Connectors](https://cohere.com/llmu/rag-connectors/)**: Learn about connectors and how to build RAG applications using the web search connector.
- **[RAG With Quickstart Connectors](https://cohere.com/llmu/rag-quickstart-connectors/)**: Learn how to connect RAG applications to datastores by leveraging Cohere’s pre-built quickstart connectors.
- **[RAG Over Large-Scale Data](https://cohere.com/llmu/rag-large-scale-data/)**: Learn how to build RAG applications over multiple datastores and long documents.

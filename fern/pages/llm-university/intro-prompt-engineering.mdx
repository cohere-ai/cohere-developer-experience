---
title: "Module 6: Prompt Engineering"
slug: "docs/intro-prompt-engineering"

hidden: false
createdAt: "Sun Oct 01 2023 04:05:48 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Tue Apr 16 2024 18:40:24 GMT+0000 (Coordinated Universal Time)"
---
<img src='../../assets/images/012a6bc-image.png' alt='Amer' />


Welcome to the Prompt Engineering module! I'm Meor Amer, your instructor.

By the end of this module, you will be able to apply various prompting techniques using the Command model.

To gain the most value out of this module, we highly recommend that you first take the [Text Generation](/docs/intro-text-generation) module, which teaches the basics of using the Command model and the fundamentals of prompt engineering. This module builds on that and goes deeper into the various prompt engineering techniques. In this module, you'll also learn about how to perform validation and evaluation on the outputs generated by a model.

Here is what you'll learn in this module:

- **[Constructing Prompts](/docs/constructing-prompts)**: Learn about different techniques for constructing prompts for the Command model.
- **[Use Case Patterns](/docs/use-case-patterns)**: Learn about common use case patterns in text generation, with example prompts.
- **[Chaining Prompts](/docs/chaining-prompts-2)**: Explore prompt-chaining patterns and their example applications.
- **[Validating Outputs](/docs/validating-outputs)**: Implement validation on LLM outputs.
- **[Evaluating Outputs](/docs/evaluating-outputs)**: Explore different options for evaluating LLM outputs.
- **[Conclusion - Prompt Engineering](/docs/conclusion-prompt-engineering)**: Summarize what you have learned.

For further reading, we also have documentation on [prompt engineering for Command models](/docs/prompt-engineering-and-preambles) .

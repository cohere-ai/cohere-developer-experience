---
title: "Preparing the Chat Fine-tuning Data"
slug: "docs/chat-preparing-the-data"

hidden: false
description: "This document provides guidelines on preparing data in `jsonl` format for fine-tuning a chat model, including ensuring proper roles, message lengths, and encoding in UTF-8. It also explains how to create datasets using the Python SDK and best practices for chat customization."
image: "../../../assets/images/6b90ef9-cohere_meta_image.jpg"  
keywords: "fine-tuning, fine-tuning language models"

createdAt: "Thu Nov 16 2023 02:53:26 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Tue May 07 2024 19:35:14 GMT+0000 (Coordinated Universal Time)"
---
In this section, we will walk through how you can prepare your data for fine-tuning a one of the Command family of models for Chat.

### Data format

First, ensure your data is in `jsonl` format. It should have the following structure: 

- `messages`: This contains a list of messages of the conversation

A message consist of the following parts:

- `role`: The current speaker. You can pick from `System`, `User`, or `Chatbot`.
- `content`: This contains the content of the message.

Here is a chat example that trains a chat bot to answer questions. Notice that, for the sake of readability, the document spans over multiple lines. For your dataset, make sure that each line contains one whole example.

```json JSON
{
  "messages": [
    {
      "role": "System",
      "content": "You are a large language model trained by Cohere."
    },
    {
      "role": "User",
      "content": "Hi! What were Time magazines top 10 cover stories in the last 10 years?"
    },
    {
      "role": "Chatbot",
      "content": "Time magazines top 10 cover stories in the last 10 years were:\\n\\n1. Volodymyr Zelenskyy\\n2. Elon Musk\\n3. Martin Luther King Jr.\\n4. How Earth Survived\\n5. Her Lasting Impact\\n6. Nothing to See Here\\n7. Meltdown\\n8. Deal With It\\n9. The Top of America\\n10. Bitter Pill"
    },
    {
      "role": "User",
      "content": "Who is Volodymyr Zelenskyy?"
    },
    {
      "role": "Chatbot",
      "content": "Volodymyr Zelenskyy is a Ukrainian politician who was elected President of Ukraine in 2019. He previously served as the Minister of Internal Affairs in the government of Prime Minister Volodymyr Groysman."
    },
    {
      "role": "User",
      "content": "Thank you!"
    }
  ]
}
```

### Data Requirements

To pass the validation tests Cohere performs on uploaded data, ensure that: 

- You have the proper roles. There are only three acceptable values for the `role` field: `System`, `Chatbot` or `User`. There should be at least one instance of `Chatbot` and `User` in each conversation. If your dataset includes other roles, an error will be thrown.
- A preamble should be uploaded as the first message in the conversation, with `role: System`. All other messages with `role: System` will be treated as speakers in the conversation.
- The "System" preamble message is not longer than 4096 tokens, which is half the maximum training sequence length.
- Each turn in the conversation should be within the training context length of 8192 tokens to avoid being dropped from the dataset. We explain a turn in the "Chat Customization Best Practices" section below.
- Your data is encoded in UTF-8.

### Evaluation Datasets

Evaluation data is utilized to calculate metrics that depict the performance of your fine-tuned model. You have the option of generating a validation dataset yourself, or you can opt instead to allow us to divide your training file into separate train and evaluation datasets.

### Create a Dataset with the Python SDK

If you intend to fine-tune through our UI you can skip to the next chapter. Otherwise continue reading to learn how to create datasets for fine-tuning via our Python SDK. Before you start, we recommend that you read about [datasets](/docs/datasets). Please also see the 'Data Formatting and Requirements' in 'Using the Python SDK' in the next chapter for a full table of expected validation errors. Below you will find some code samples on how create datasets via the SDK:

```python PYTHON
import cohere

# instantiate the Cohere client
co = cohere.Client("YOUR_API_KEY")  

chat_dataset = co.datasets.create(name="chat-dataset",
                                   data=open("path/to/train.jsonl", "rb"),
                                   type="chat-finetune-input")
print(co.wait(chat_dataset))
                                   
chat_dataset_with_eval = co.datasets.create(name="chat-dataset-with-eval",
                                           data=open("path/to/train.jsonl, "rb"),
                                           eval_data=open("path/to/eval.jsonl, "rb"),
                                           type="chat-finetune-input")
print(co.wait(chat_dataset_with_eval))
```

### Chat Customization Best Practices

A turn includes all messages up to the Chatbot speaker. The following conversation has two turns:

```json JSON
{
  "messages": [
    {
      "role": "System",
      "content": "You are a chatbot trained to answer to my every question."
    },
    {
      "role": "User",
      "content": "Hello"
    },
    {
      "role": "Chatbot",
      "content": "Greetings! How can I help you?"
    },
    {
      "role": "User",
      "content": "What makes a good running route?"
    },
    {
      "role": "Chatbot",
      "content": "A sidewalk-lined road is ideal so that youâ€™re up and off the road away from vehicular traffic."
    }
  ]
}
```

A few things to bear in mind:

- The preamble is always kept within the context window. This means that the preamble and _all turns within the context window_ should be within 8192 tokens.
- To check how many tokens your data is, you can use the [co.tokenize() api](/reference/tokenize).
- If any turns are above the context length of 8192 tokens, we will drop them from the training data.
- If an evaluation file is not uploaded, we will make our best effort to automatically split your uploaded conversations into an 80/20 split. In other words, if you upload a training dataset containing only the minimum of two conversations, we'll randomly put one of them in the training set, and the other in the evaluation set.

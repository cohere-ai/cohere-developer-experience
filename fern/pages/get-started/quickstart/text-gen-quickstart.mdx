---
title: Text Generation
slug: /docs/text-gen-quickstart

description: "A quickstart guide for performing text generation with Cohere's Command models (v1 API)."
image: "../../../assets/images/f1cc130-cohere_meta_image.jpg"  
keywords: "Cohere, text generation, chatbot, command models"
---

You can use Cohere's Command models via the Chat endpoint. This endpoint enables you to build generative AI applications and facilitates a conversational interface for building chatbots.

In this quickstart, learn how to perform text generation with the Chat endpoint.

<Steps>
### Setup
First, install the Cohere Python SDK with the following command.

```bash
pip install -U cohere
```

Next, import the library and create a client.

<Tabs>
<Tab title="Cohere Platform">

```python PYTHON
import cohere

co = cohere.Client("COHERE_API_KEY") # Get your free API key here: https://dashboard.cohere.com/api-keys
```

</Tab>
<Tab title="Private Deployment">

```python PYTHON
import cohere

co = cohere.Client(api_key="", # Leave this blank
                   base_url="<YOUR_DEPLOYMENT_URL>")
```

</Tab>

<Tab title="Bedrock">

```python PYTHON
import cohere

co = cohere.BedrockClient(
    aws_region="AWS_REGION",
    aws_access_key="AWS_ACCESS_KEY_ID",
    aws_secret_key="AWS_SECRET_ACCESS_KEY",
    aws_session_token="AWS_SESSION_TOKEN",
)

# Get the model name: https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
```
</Tab>

<Tab title="SageMaker">

```python PYTHON
import cohere

co = cohere.SagemakerClient(
    aws_region="AWS_REGION",
    aws_access_key="AWS_ACCESS_KEY_ID",
    aws_secret_key="AWS_SECRET_ACCESS_KEY",
    aws_session_token="AWS_SESSION_TOKEN",
)
```
</Tab>

<Tab title="Azure AI">

```python PYTHON
import cohere

co = cohere.Client(
    api_key="AZURE_API_KEY",
    base_url="AZURE_ENDPOINT",
)
```
</Tab>

</Tabs>


### Basic Text Generation
To perform a basic text generation, call the Chat endpoint by passing the `message` parameter containing the user message.

<Tabs>
<Tab title="Cohere Platform">
```python PYTHON
response = co.chat(
    model="command-r-plus-08-2024",
    message="I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates?"
)

print(response.text)
```
</Tab>

<Tab title="Private Deployment">
```python PYTHON
response = co.chat(
    message="I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates?"
)

print(response.text)
```
</Tab>

<Tab title="Bedrock">
```python PYTHON
response = co.chat(
    model="YOUR_MODEL_NAME",
    message="I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates?"
)

print(response.text)
```
</Tab>

<Tab title="SageMaker">
```python PYTHON
response = co.chat(
    model="YOUR_ENDPOINT_NAME",
    message="I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates?"
)

print(response.text)
```
</Tab>

<Tab title="Azure AI">
```python PYTHON
response = co.chat(
    message="I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates?"
)

print(response.text)
```
</Tab>
</Tabs>

```mdx wordWrap
"Excited to be part of the Co1t team, I'm [Your Name], a [Your Role], passionate about [Your Area of Expertise] and looking forward to contributing to the company's success."
```

### State Management
To maintain the state of a conversation, such as for building chatbots, append a sequence of `user` and `chatbot` messages to the `chat_history` list. You can also include a `preamble` parameter, which will act as a system message to set the context of the conversation.

<Tabs>
  <Tab title="Cohere Platform">
    ```python PYTHON
    response = co.chat(
        model="command-r-plus-08-2024",
        preamble="You respond in concise sentences.",
        chat_history=[
            {
                "role": "user",
                "message": "Hello"
            },
            {
                "role": "chatbot",
                "message": "Hi, how can I help you today?"
            }
        ],
        message="I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates?"
    )
    
    print(response.text)
    ```
  </Tab>

  <Tab title="Private Deployment">
    ```python PYTHON
    response = co.chat(
        preamble="You respond in concise sentences.",
        chat_history=[
            {
                "role": "user",
                "message": "Hello"
            },
            {
                "role": "chatbot",
                "message": "Hi, how can I help you today?"
            }
        ],
        message="I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates?"
    )
    
    print(response.text)
    ```
  </Tab>

  <Tab title="Bedrock">
    ```python PYTHON
    response = co.chat(
        model="YOUR_MODEL_NAME",
        preamble="You respond in concise sentences.",
        chat_history=[
            {
                "role": "user",
                "message": "Hello"
            },
            {
                "role": "chatbot",
                "message": "Hi, how can I help you today?"
            }
        ],
        message="I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates?"
    )
    
    print(response.text)
    ```
  </Tab>

  <Tab title="SageMaker">
    ```python PYTHON
    response = co.chat(
        model="YOUR_ENDPOINT_NAME",
        preamble="You respond in concise sentences.",
        chat_history=[
            {
                "role": "user",
                "message": "Hello"
            },
            {
                "role": "chatbot",
                "message": "Hi, how can I help you today?"
            }
        ],
        message="I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates?"
    )
    
    print(response.text)
    ```
  </Tab>

  <Tab title="Azure AI">
    ```python PYTHON
    response = co.chat(
        preamble="You respond in concise sentences.",
        chat_history=[
            {
                "role": "user",
                "message": "Hello"
            },
            {
                "role": "chatbot",
                "message": "Hi, how can I help you today?"
            }
        ],
        message="I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates?"
    )
    
    print(response.text)
    ```
  </Tab>
</Tabs>
```mdx wordWrap
"Excited to join the team at Co1t, looking forward to contributing my skills and collaborating with everyone!"
```

### Streaming

To stream the generated text, call the Chat endpoint using `chat_stream` instead of `chat`. This returns a generator that yields `chunk` objects, which you can access the generated text from.

<Tabs>
<Tab title="Cohere Platform">
```python PYTHON
message = "I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates."

response = co.chat_stream(
    model="command-r-plus-08-2024", 
    message=message
)

for chunk in response:
    if chunk.event_type == "text-generation":
        print(chunk.text, end="")
```
</Tab>

<Tab title="Private Deployment">
```python PYTHON
message = "I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates."

response = co.chat_stream(
    message=message
)

for chunk in response:
    if chunk.event_type == "text-generation":
        print(chunk.text, end="")
```
</Tab>

<Tab title="Bedrock">
```python PYTHON
message = "I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates."

response = co.chat_stream(
    model="YOUR_MODEL_NAME", 
    message=message
)

for chunk in response:
    if chunk.event_type == "text-generation":
        print(chunk.text, end="")
```
</Tab>

<Tab title="SageMaker">
```python PYTHON
message = "I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates."

response = co.chat_stream(
    model="YOUR_ENDPOINT_NAME", 
    message=message
)

for chunk in response:
    if chunk.event_type == "text-generation":
        print(chunk.text, end="")
```
</Tab>

<Tab title="Azure AI">
```python PYTHON
message = "I'm joining a new startup called Co1t today. Could you help me write a one-sentence introduction message to my teammates."

response = co.chat_stream(
    message=message
)

for chunk in response:
    if chunk.event_type == "text-generation":
        print(chunk.text, end="")
```
</Tab>
</Tabs>
```mdx wordWrap
"Excited to be part of the Co1t team, I'm [Your Name], a [Your Role/Position], looking forward to contributing my skills and collaborating with this talented group to drive innovation and success."
```


</Steps>

## Further Resources
- [Chat endpoint API reference](https://docs.cohere.com/v1/reference/chat)
- [Documentation on text generation](https://docs.cohere.com/v1/docs/introduction-to-text-generation-at-cohere)
- [LLM University module on text generation](https://cohere.com/llmu#text-generation)
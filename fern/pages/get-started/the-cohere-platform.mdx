---
title: An Overview of The Cohere Platform
slug: docs/the-cohere-platform
hidden: false
description: >-
  Cohere offers world-class Large Language Models (LLMs) like Command, Rerank, and Embed.
  These help developers and enterprises build LLM-powered applications.
image: ../../assets/images/e2602c8-meta_docs_image_cohere.jpg
keywords: 'natural language processing, generative AI, fine-tuning models'
createdAt: 'Thu Oct 13 2022 21:30:34 GMT+0000 (Coordinated Universal Time)'
updatedAt: 'Mon Jun 24 2024 09:16:55 GMT+0000 (Coordinated Universal Time)'
---


## Large Language Models (LLMs)

Language is important. It’s how we learn about the world (e.g. news, searching the web or Wikipedia), and also how we shape it (e.g. agreements, laws, or messages). Language is also how we connect and communicate — as people, and as groups and companies.

Despite the rapid evolution of software, computers remain limited in their ability to deal with language. Software is great at searching for exact matches in text, but often fails at more advanced uses of language — ones that humans employ on a daily basis.

There’s a clear need for more intelligent tools that better understand language.


A recent breakthrough in artificial intelligence (AI) is the introduction of language processing technologies that enable us to build more intelligent systems with a richer understanding of language than ever before. Large pre-trained Transformer language models, or simply large language models, vastly extend the capabilities of what systems are able to do with text.

<img src='../../assets/images/edb518d-IntroToLLM_Visual_1.png' alt='systems.' />


Consider this: adding language models to empower Google Search was <a href="https://blog.google/products/search/search-language-understanding-bert/" target="_blank">noted</a> as “representing the biggest leap forward in the past five years, and one of the biggest leaps forward in the history of Search“. Microsoft also <a href="https://azure.microsoft.com/en-us/blog/bing-delivers-its-largest-improvement-in-search-experience-using-azure-gpus/" target="_blank">uses</a> such models for every query in the Bing search engine.

Despite the utility of these models, training and deploying them effectively is resource intensive, requiring a large investment of data, compute, and engineering resources.

## Cohere's LLMs

Cohere allows developers and enterprises to build LLM-powered applications. We do that by creating world-class models, along with the supporting platform required to deploy them securely and privately.


The Command family of models includes [Command A](https://docs.cohere.com/docs/command-a), [Command R7B](https://docs.cohere.com/docs/command-r7b), [Command R+](/docs/command-r-plus), and [Command R](/docs/command-r). Together, they are the text-generation LLMs powering conversational agents, summarization, copywriting, and similar use cases. They work through the [Chat](/reference/chat) endpoint, which can be used with or without [retrieval augmented generation](/docs/retrieval-augmented-generation-rag) RAG.

[Rerank](https://cohere.com/blog/rerank/) is the fastest way to inject the intelligence of a language model into an existing search system. It can be accessed via the [Rerank](/reference/rerank-1) endpoint.

[Embed](https://cohere.com/models/embed) improves the accuracy of search, classification, clustering, and RAG results. It also powers the [Embed](/reference/embed) and [Classify](/reference/classify) endpoints.


<img src="../../assets/images//b483350-Visual_1.png" />

[Click here](/docs/foundation-models) to learn more about Cohere foundation models.

## Example Applications

Try [the Chat UI](https://coral.cohere.com) to see what an LLM-powered conversational agent can look like. It is able to converse, summarize text, and write emails and articles.

<img src="../../assets/images//ebb82f9-Screenshot_2024-07-10_at_9.27.11_AM.png" />

Our goal, however, is to enable you to build your own LLM-powered applications. The [Chat endpoint](/docs/chat-api), for example, can be used to build a conversational agent powered by the Command family of models. 

<img src="../../assets/images//f4a351b-Visual_3.png" alt="A diagram of a conversational agent." />

### Retrieval-Augmented Generation (RAG)

“Grounding” refers to the practice of allowing an LLM to access external data sources – like the internet or a company’s internal technical documentation – which leads to better, more factual generations. 

Chat is being used with grounding enabled in the screenshot below, and you can see how accurate and information-dense its reply is.

<img src="../../assets/images//04315e6-Screenshot_2024-07-10_at_9.29.25_AM.png" />


What’s more, advanced RAG capabilities allow you to see what underlying query the model generates when completing its tasks, and its output includes [citations](/docs/documents-and-citations) pointing you to where it found the information it uses. Both the query and the citations can be leveraged alongside the Cohere Embed and Rerank models to build a remarkably powerful RAG system, such as the one found in [this guide](https://cohere.com/llmu/rag-chatbot).

<img src="../../assets/images//545e35e-Visual_5.png" />

[Click here](/docs/serving-platform) to learn more about the Cohere serving platform.

### Advanced Search & Retrieval

Embeddings enable you to search based on what a phrase _means_ rather than simply what keywords it _contains_, leading to search systems that incorporate context and user intent better than anything that has come before.

<img src="../../assets/images//04fe094-Visual_6.png" alt="How a query returns results." />

Learn more about semantic search [here](https://cohere.com/llmu/what-is-semantic-search).

## Fine-Tuning

To [create a fine-tuned model](/docs/fine-tuning), simply upload a dataset and hold on while we train a custom model and then deploy it for you. Fine-tuning can be done with [generative models](/docs/generate-fine-tuning), [multi-label classification models](/docs/classify-fine-tuning), [rerank models](/docs/rerank-fine-tuning), and [chat models](/docs/chat-fine-tuning).

<img src="../../assets/images//980660f-Visual_7.png" alt="A diagram of fine-tuning." />

## Accessing Cohere Models

Depending on your privacy/security requirements there are a number of ways to access Cohere:

- [Cohere API](/reference/about): this is the easiest option, simply grab an API key from [the dashboard](https://dashboard.cohere.com/) and start using the models hosted by Cohere.
- Cloud AI platforms: this option offers a balance of ease-of-use and security. you can access Cohere on various cloud AI platforms such as [Oracle's GenAI Service](https://www.oracle.com/uk/artificial-intelligence/generative-ai/large-language-models/), AWS' [Bedrock](https://aws.amazon.com/bedrock/cohere-command-embed/) and [Sagemaker](https://aws.amazon.com/blogs/machine-learning/cohere-brings-language-ai-to-amazon-sagemaker/) platforms, [Google Cloud](https://console.cloud.google.com/marketplace/product/cohere-id-public/cohere-public?ref=txt.cohere.com), and [Azure's AML service](https://cohere.com/blog/coheres-enterprise-ai-models-coming-soon-to-microsoft-azure-ai-as-a-managed-service/).
- Private cloud deploy deployments: Cohere's models can be deployed privately in most virtual private cloud (VPC) environments, offering enhanced security and highest degree of customization. Please [contact sales](emailto:team@cohere.com) for information.

<img src="../../assets/images//2ce36b1-Visual_8.png" alt="The major cloud providers." />


### On-Premise and Air Gapped Solutions

- On-premise: if your organization deals with sensitive data that cannot live on a cloud we also offer the option for fully-private deployment on your own infrastructure. Please [contact sales](emailto:team@cohere.com) for information.

## Let us Know What You’re Making

We hope this overview has whetted your appetite for building with our generative AI models. Reach out to us on [Discord](https://discord.com/invite/co-mmunity) with any questions or to showcase your projects – we love hearing from the Cohere community!

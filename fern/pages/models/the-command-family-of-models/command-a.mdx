---
title: Command A
subtitle: Cohere's Command A model
slug: docs/command-a
hidden: false
description: >-
    Command A is [TODO, fill in] model in our R family of enterprise-focused large language models. It excels at [TODO, fill in].
image: ../../../assets/images/edb3e49-cohere_meta_image.jpg
keywords: 'generative AI, Cohere, large language models'
createdAt: 'Thu Mar 13 2025'
updatedAt: ''
---

Command A is Cohere's most performant model to date, excelling at real world enterprise tasks including tool use, retrieval augmented generation (RAG), agents, and multilingual use cases. At 111B parameters, Command A has a context length of 256K and only requires 2 GPUs (A100s / H100s) to run, while being significantly more efficient at inference time with 150% higher throughput compared to its predecessor, Command R+ 08-2024.




## Model Details
| Model Name               | Description                                                                                                                                                                                                                                                                                                                                                      | Modality          | Context Length | Maximum Output Tokens | Endpoints                                                                                  |
|--------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------|----------------|-----------------------|-------------------------------------------------------------------------------------------|
| `command-a-03-2025`      | Command A is our most performant model to date, excelling at tool use, agents, retrieval augmented generation (RAG), and multilingual use cases. Command A has a context length of 256K, only requires two GPUs to run, and has 150% higher throughput compared to Command R+ 08-2024.                                                                           | Text              | 256k           | 4k                    | [Chat](/reference/chat)|

## What Can Command A Be Used For?
Command A is excellent for:

- Tool use
- Agents 
- Retrieval augmented generation
- Multilingual use cases

### Command A is Chatty
By default, the model is interactive and optimized for conversation, meaning it is verbose and uses markdown to highlight code. To override this behavior, developers should use a preamble which asks the model to simply provide the answer and to not use markdown or code block markers. To learn more, consult our documentation on [system messages](https://docs.cohere.com/docs/preambles).

### Reasoning 
---
title: "Command and Command Light"
slug: "v2/docs/command-beta"

hidden: false
description: "Cohere's generative model Command is available in two sizes, with the `command` model showing better performance. Nightly versions are released weekly to improve performance, and users can provide feedback via email or Discord."
image: "../../../../assets/images/b02d668-cohere_docs_preview_image_1200x630_copy.jpg"  
keywords: "Cohere's command model, generative AI"

createdAt: "Mon Nov 07 2022 16:26:44 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Tue Jun 04 2024 18:34:22 GMT+0000 (Coordinated Universal Time)"
---
<Info title="Note">  
 For most use cases we recommend our latest model [Command R](/v2/docs/command-r) instead.
</Info>



| Latest Model              | Description                                                                                                                                                                                                                                                                                                                                                                 | Context Length | Maximum Output Tokens | Endpoints                                                                                  |
|---------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------|-----------------------|-------------------------------------------------------------------------------------------|
| `command`                 | An instruction-following conversational model that performs language tasks with high quality, more reliably and with a longer context than our base generative models.                                                                                                                                                                                                      | 4k             | 4k                    | [Chat](/reference/chat),  <br/>[Summarize](/reference/summarize)                                                       |
| `command-light`           | A smaller, faster version of `command`. Almost as capable, but a lot faster.                                                                                                                                                                                                                                                                                                 | 4k             | 4k                    | [Chat](/reference/chat),  <br/>[Summarize](/reference/summarize-2)                                                    |
| `command-nightly`         | To reduce the time between major releases, we put out nightly versions of command models. For `command`, that is `command-nightly`.  <br/><br/>Be advised that `command-nightly` is the latest, most experimental, and (possibly) unstable version of its default counterpart. Nightly releases are updated regularly, without warning, and are not recommended for production use. | 128K           | 4k                  | [Chat](/reference/chat)                                                                                                                      |
| `command-light-nightly`   | To reduce the time between major releases, we put out nightly versions of command models. For `command-light`, that is `command-light-nightly`.  <br/><br/>Be advised that `command-light-nightly` is the latest, most experimental, and (possibly) unstable version of its default counterpart. Nightly releases are updated regularly, without warning, and are not recommended for production use. | 4k             | 4k                    | [Chat](/reference/chat)                                                                                                                      |



The Command family of models responds well with instruction-like prompts, and are available in two variants: `command-light` and `command`. The `command` model demonstrates better performance, while `command-light` is a great option for applications that require fast responses.

To reduce the turnaround time for releases, we have nightly versions of Command available. This means that every week, you can expect the performance of `command-nightly` and `command-light-nightly` to improve.

## Example Prompts

<img src='../../../../assets/images/aae9450-prod_desc.png' />


<img src='../../../../assets/images/97a8c22-leetcode.png' />


<img src='../../../../assets/images/4bb18de-vendor.png' />


## Get Started

### Set up

Install the SDK, if you haven't already.

`pip install cohere`

Then, set up the Cohere client.

```python PYTHON
import cohere  
co = cohere.ClientV2(api_key="<YOUR API KEY>")
```

### Create prompt

```python PYTHON
message = "Write an introductory paragraph for a blog post about language models."
```

### Generate text

```python PYTHON
response = co.chat(model="command",
                   messages=[{"role" : "user", "content" : message}]
)

intro_paragraph = response.message.content[0].text
```

## FAQ

### Can users train Command?

Users cannot train Command in OS at this time. However, our team can handle this on a case-by-case basis. Please email [team@cohere.com](mailto:team@cohere.com) if you’re interested in training this model.

### Where can I leave feedback about Cohere generative models?

Please leave feedback on [Discord](https://discord.com/invite/co-mmunity).

### What's the context length on the command models?

A model's "context length" refers to the number of tokens it's capable of processing at one time. In the table above, you can find the context length (and a few other relevant parameters) for the different versions of the command models.
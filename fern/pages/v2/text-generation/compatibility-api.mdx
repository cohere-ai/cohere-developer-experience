---
title: "Using Cohere models via the OpenAI SDK"
slug: "v2/docs/compatibility-api"

hidden: true 
description: "The document serves as a guide for Cohere's Compatibility API, which allows developers to seamlessly use Cohere's models using OpenAI's SDK."
image: "../../../assets/images/b3c8253-cohere_meta_image.jpg"  
keywords: "Cohere, text generation, LLMs, generative AI"

createdAt: "Thu Feb 29 2024 18:13:25 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Thu May 23 2024 04:32:10 GMT+0000 (Coordinated Universal Time)"
---
The Compatibility API allows developers to use Cohere’s models through OpenAI’s SDK. 
It makes it easy to switch existing OpenAI-based applications to use Cohere’s models while still maintaining the use of OpenAI SDK — no big refactors needed.

The following endpoints are supported via the Compatibility API:

- GET `/models`
- GET `/models/{model}`
- POST `/embeddings`
- POST `/chat/completions`

## Supported parameters

The following is the list supported parameters in the Compatibility API, including those that are not explicitly demonstrated in the examples above:

### Chat completions

- `model`
- `messages`
- `stream`
- `reasoning_effort` (Only "none" and "high" are currently supported.)
- `response_format`
- `tools`
- `temperature`
- `max_tokens`
- `stop`
- `seed`
- `top_p`
- `frequency_penalty`
- `presence_penalty`

<Warning title="Note">  
Currently, only **`none`** and **`high`** are supported for `reasoning_effort`.  
These correspond to enabling or disabling `thinking` in the Cohere Chat API.  
Passing **`medium`** or **`low`** is **not supported** at this time.
</Warning>

### Embeddings

- `input`
- `model`
- `encoding_format`

## Unsupported parameters

The following parameters are not supported in the Compatibility API:

### Chat completions

- `store`
- `metadata`
- `logit_bias`
- `top_logprobs`
- `n`
- `modalities`
- `prediction`
- `audio`
- `service_tier`
- `parallel_tool_calls`

### Embeddings

- `dimensions`
- `user`

### Cohere-specific parameters

Parameters that are uniquely available on the Cohere API but not on the OpenAI SDK are not supported.

Chat endpoint:

- `connectors`
- `documents`
- `citation_options`
- ...[more here](https://docs.cohere.com/reference/chat)

Embed endpoint:
- `input_type`
- `images`
- `truncate`
- ...[more here](https://docs.cohere.com/reference/embed)

This is a quickstart guide to help you get started with the Compatibility API.

## Installation

First, install the OpenAI SDK and import the package.

Then, create a client and configure it with the compatibility API base URL and your Cohere API key.

<Tabs>
<Tab title="Python">
    
```bash
pip install openai
```

```python PYTHON
from openai import OpenAI

client = OpenAI(
    base_url="https://api.cohere.ai/compatibility/v1",
    api_key="COHERE_API_KEY",
)
```

</Tab>

<Tab title="TypeScript">

```bash
npm install openai
```

```typescript TYPESCRIPT

import OpenAI from "openai";

const openai = new OpenAI({
    baseURL: "https://api.cohere.ai/compatibility/v1",
    apiKey: "COHERE_API_KEY",
});
```
</Tab>
</Tabs>
    

## Chat Completions

Here’s a basic example of using the Chat Completions API.

<Tabs>
<Tab title="Python">
    
```python PYTHON
from openai import OpenAI

client = OpenAI(
    base_url="https://api.cohere.ai/compatibility/v1",
    api_key="COHERE_API_KEY",
)

completion = client.chat.completions.create(
    model="command-a-03-2025",
    messages=[
        {
            "role": "user",
            "content": "Write a haiku about recursion in programming.",
        },
    ],
)

print(completion.choices[0].message)
```

</Tab>

<Tab title="TypeScript">

```typescript TYPESCRIPT
import OpenAI from "openai";

const openai = new OpenAI({
    baseURL: "https://api.cohere.ai/compatibility/v1",
    apiKey: "COHERE_API_KEY",
    });

const completion = await openai.chat.completions.create({
    model: "command-a-03-2025",
    messages: [
        {
            role: "user",
            content: "Write a haiku about recursion in programming.",
        },
    ]
});

console.log(completion.choices[0].message);
```

</Tab>

<Tab title="cURL">

```bash
curl --request POST \
    --url https://api.cohere.ai/compatibility/v1/chat/completions \
    --header 'Authorization: Bearer COHERE_API_KEY' \
    --header 'Content-Type: application/json' \
    --data '{
    "model": "command-a-03-2025",
    "messages": [
    {
        "role": "user", 
        "content": "Write a haiku about recursion in programming."
    }
    ]
}'
```

</Tab>

</Tabs>
    

Example response (via the Python SDK):

```mdx
ChatCompletionMessage(content="Recursive loops,\nUnraveling code's depths,\nEndless, yet complete.", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)
```

## Embeddings

You can generate text embeddings with the Embeddings API by passing a list of strings as the `input` parameter. You can also specify in `encoding_format` the format of embeddings to be generated. Can be either `float` or `base64`.

<Tabs>
<Tab title="Python">
    
```python PYTHON
from openai import OpenAI

client = OpenAI(
    base_url="https://api.cohere.ai/compatibility/v1",
    api_key=COHERE_API_KEY,
)

response = client.embeddings.create(
    input=["Hello world!"],
    model="embed-v4.0",
    encoding_format="float",
)

print(
    response.data[0].embedding[:5]
)  # Display the first 5 dimensions
```

</Tab>

<Tab title="TypeScript">

```typescript TYPESCRIPT
import OpenAI from "openai";

const openai = new OpenAI({
    baseURL: "https://api.cohere.ai/compatibility/v1",
    apiKey: "COHERE_API_KEY",
    });

const response = await openai.embeddings.create({
    input: ["Hello world!"],
    model: "embed-v4.0",
    encoding_format: "float"
});

console.log(response.data[0].embedding.slice(0, 5)); // Display the first 5 dimensions
```

</Tab>

<Tab title="cURL">

```bash
curl --request POST \
    --url https://api.cohere.ai/compatibility/v1/embeddings \
    --header 'Authorization: Bearer COHERE_API_KEY' \
    --header 'Content-Type: application/json' \
    --data '{
    "model": "embed-v4.0",
    "input": ["Hello world!"],
    "encoding_format": "float"
}'

```

</Tab>

</Tabs>

Example response (via the Python SDK):

```mdx
[0.0045051575, 0.046905518, 0.025543213, 0.009651184, -0.024993896]
```

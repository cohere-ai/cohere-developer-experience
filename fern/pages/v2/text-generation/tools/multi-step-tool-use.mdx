---
title: "Multi-step Tool Use (Agents)"
slug: "docs/multi-step-tool-use"
hidden: false 
description: "Tool use allows developers to connect Cohere's models to external tools for various actions, while multi-step tool use extends this to allow the model to call multiple tools in a sequence of steps. This process enables the model to reason, perform dynamic actions, and adapt quickly based on external information."
image: "../../../../assets/images/21a3b59-cohere_meta_image.jpg"
createdAt: "Wed Mar 27 2024 19:22:07 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Mon Jun 17 2024 19:41:53 GMT+0000 (Coordinated Universal Time)"
---
Tool use is a technique which allows Cohere's models to invoke external tools: search engines, APIs, functions, databases, and so on.

Multi-step tool use happens when the output of one tool calling step is needed as the input to the another. In other words, tool-calling needs to happen in a sequence.

For example, given the `web-search` tool, the model can start answering complex questions that require performing internet searches.

![](../../../../assets/images/00e8907-image.png)
Notice that the model learned information from the first search, which it then used to perform a second web search. This behavior is called multi-step because the model tackles the task step by step.

Also, note that multi-step is enabled in the Chat API by default.

## Multi-step Tool Use With the Chat API

### Step 1: Define the tools

```python PYTHON
# define the `web_search` tool.

def web_search(query: str) -> list[dict]:
  # your code for performing a web search goes here
  # return [{
  #		"url": "https://en.wikipedia.org/wiki/Ontario",
  #		"text": "The capital of Ontario is Toronto, ..."
  #	}]

web_search_tool = {
    "type": "function",
    "function": {
        "name": "web_search",
        "description": "performs a web search with the specified query",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "str",
                    "description": "the query to look up"
                }
            },
            "required": ["query"]
        }
    }
}
```

### Step 2: Run the tool use workflow

```python PYTHON
import cohere
co = cohere.ClientV2(api_key="<YOUR API KEY>")

# 1 - Add the user message
message = "Who is the mayor of the capital of Ontario?"
messages = [{'role': 'user', 'content': message}]

# 2 - Model generates tool calls, if any
model = "command-r-plus"
res = co.chat(model=model,
              messages=messages,
              tools=[web_search_tool])

# As long as the model sends back tool_calls,
# keep invoking tools and sending the results back to the model
while res.message.tool_calls:
    print("\nTool plan:")
    print(res.message.tool_plan) # This will be an observation and a plan with next steps
    
    print("\nTool calls:")
    for tc in res.message.tool_calls:
        print(f"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}")
    
    messages.append({'role': 'assistant',
                      'tool_calls': res.message.tool_calls,
                      'tool_plan': res.message.tool_plan})
    
    # 3 - Execute tools based on the tool calls generated by the model
    print("\nTool results:")
    for tc in res.message.tool_calls:
        tool_result = web_search(**json.loads(tc.function.arguments))
        print(tool_result)
        tool_content = [cohere.ToolContent(output=tool_result)]
        messages.append({'role': 'tool',
                         'tool_call_id': tc.id,
                         'tool_content': tool_content}) 

    # 4 - Model either generates more tool calls or returns a response
    res = co.chat(model=model,
                messages=messages,
                tools=[web_search_tool])

print("\nResponse:")
print(res.message.content[0].text)

if res.message.citations:
    print("\nCitations:")
    for citation in res.message.citations:
        print(citation, "\n")
```
```
# EXAMPLE RESPONSE

Tool plan:
First I will search for the capital of Ontario, then I will search for the mayor of that city.

Tool calls:
Tool name: web_search | Parameters: {"query":"capital of Ontario"}

Tool results:
{'documents': [{'title': 'Ontario', 'snippet': "It is home to the nation's capital, Ottawa, and its most populous city, Toronto, which is Ontario's provincial capital. Ontario. Province · A red flag ...", 'url': 'https://en.wikipedia.org/wiki/Ontario'}]}

Tool plan:
I now know that Toronto is the capital of Ontario. I need to search for the mayor of Toronto.

Tool calls:
Tool name: web_search | Parameters: {"query":"mayor of toronto"}

Tool results:
{'documents': [{'title': 'Mayor of Toronto', 'snippet': 'Olivia Chow has served as the 66th and current mayor of Toronto since July 12, 2023, after winning the 2023 by-election.', 'url': 'https://en.wikipedia.org/wiki/Mayor_of_Toronto'}]}

Response:
Toronto is the capital of Ontario, and Olivia Chow is the current mayor.

Citations:
start=0 end=7 text='Toronto' sources=[Source_Tool(id='web_search_vzj0at1aj4h6:0', tool_output={'documents': '[{"snippet":"It is home to the nation\'s capital, Ottawa, and its most populous city, Toronto, which is Ontario\'s provincial capital. Ontario. Province · A red flag ...","title":"Ontario","url":"https://en.wikipedia.org/wiki/Ontario"}]'}, type='tool')] 

start=39 end=50 text='Olivia Chow' sources=[Source_Tool(id='web_search_nk68kpe77jq8:0', tool_output={'documents': '[{"snippet":"Olivia Chow has served as the 66th and current mayor of Toronto since July 12, 2023, after winning the 2023 by-election.","title":"Mayor of Toronto","url":"https://en.wikipedia.org/wiki/Mayor_of_Toronto"}]'}, type='tool')] 

```

## How Does Multi-step Tool Use Work?

<Frame caption={<a href="https://python.langchain.com/docs/use_cases/tool_use">Source</a>}>
<img src="../../../../assets/images/1e500e0-tool_use_1.svg" />
</Frame>

Here’s an outline of the basic steps involved in multi-step tool use:

- Given a user request, the model comes up with a plan to solve the problem which answers questions such as "Which tools should be used," and "In what order should they be used."
- The model then carries out the plan by repeatedly executing actions (using whatever tools are appropriate), reasoning over the results, and re-evaluating the plan.
- After each Action -> Observation ->Reflection cycle, the model reflects about what to do next. This reflection involves analyzing what has been figured out so far, determining whether any changes need to be made to the plan, and what to do next. The model can take as many steps as it deems necessary.
- Once the model decides it knows how to answer the user question, it proceeds to generating the final response.

#### What is the difference between tool use and Retrieval Augmented Generation (RAG)?

Tool use is a natural extension of retrieval augmented generation (RAG). RAG is about enabling the model to interact with an information retrieval system (like a vector database). Our models are trained to be excellent at RAG use cases.

Tool use pushes this further, allowing Cohere models to go far beyond information retrieval, interact with search engines, APIs, functions, databases, and many other tools.

## A Further Example With Multiple Tools

This section provides another example of multi-step tool use, this time with multiple tools. The notebook for this example can be [found here](<todo>).

This example demonstrates an agent that performs analysis on a Spotify tracks dataset (via a Python interpreter tool) while also having access to another tool: web search tool.

### Step 1: Define the tools

Here, we define the web search tool, which uses the Tavily Python client to perform web searches.

```python PYTHON
# ! pip install tavily-python --q --disable-pip-version-check

from tavily import TavilyClient

tavily_client = TavilyClient(api_key="TAVILY_API_KEY")

# here's a web search engine
def web_search(query: str) -> list[dict]:
  response = tavily_client.search(query, max_results=3)['results']
  return {"results": response}


# the LLM is equipped with a description of the web search engine
web_search_tool = {
    "type": "function",
    "function": {
        "name": "web_search",
        "description": "Returns a list of relevant document snippets for a textual query retrieved from the internet",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "Query to search the internet with"
                }
            },
            "required": ["query"]
        }
    }
}
```
Here, we define the Python interpreter tool, which uses the `exec` function to execute Python code.

```python PYTHON
import io, contextlib

def python_interpreter(code: str) -> list[dict]:
    output = io.StringIO()
    try:
        # Redirect stdout to capture print statements
        with contextlib.redirect_stdout(output):
            exec(code, globals())
    except Exception as e:
        return {
            "error": str(e),
            "executed_code": code
        }
    # Get stdout
    return {
  		"console_output": output.getvalue(),
        "executed_code": code
  	}

# the LLM is equipped with a description of a python console
python_interpreter_tool = {
    "type": "function",
    "function": {
        "name": "python_interpreter",
        "description": "Executes python code and returns the result. The code runs in a static sandbox without internet access and without interactive mode, so print output or save output to a file.",
        "parameters": {
            "type": "object",
            "properties": {
                "code": {
                    "type": "string",
                    "description": "Python code to execute"
                }
            },
            "required": ["code"]
        }
    }
}

functions_map = {
    "web_search": web_search,
    "python_interpreter": python_interpreter,
}
```

We'll also need the `spotify_data` dataset, which contains information about Spotify tracks such as the track information, release information, popularity metrics, and musical characteristics. You can find the dataset [here](<todo>).

Here is the task that the agent needs to perform:

```python PYTHON
message = """What's the age and citizenship of the artists who had the top 3 most streamed songs on Spotify in 2023?

You have access to a dataset with information about Spotify songs from the past 10 years, located at ./spotify_dataset.csv.
You also have access to the internet to search for information not available in the dataset.
You must use the dataset when you can, and if stuck you can use the internet.
Remember to inspect the dataset and get a list of its columnsto understand its structure before trying to query it. Take it step by step.
"""
```

### Step 2: Run the tool use workflow

Next, we run the tool use workflow involving for steps:
- Get the user message
- Model generates tool calls, if any
- Execute tools based on the tool calls generated by the model
- Model either generates more tool calls or returns a response with citations

```python PYTHON
model = "command-r-plus"
tools = [web_search_tool,python_interpreter_tool]

# Step 1: get user message
print(f"USER MESSAGE:\n{message}")
print("="*50)

messages = [{'role': 'user','content': message}]

# 2 - Model generates tool calls, if any
res = co.chat(model=model,
        messages=messages,
        tools=tools,
        temperature=0)

# Keep invoking tools as long as the model generates tool calls
while res.message.tool_calls:
    # Tool plan and tool calls
    print("\nTOOL PLAN:")
    print(res.message.tool_plan)

    print("\nTOOL CALLS:")
    for tc in res.message.tool_calls:
        if tc.function.name == "python_interpreter":
            print(f"Tool name: {tc.function.name}")
            tool_call_prettified = print("\n".join(f"  {line}" for line_num, line in enumerate(json.loads(tc.function.arguments)["code"].splitlines())))
            print(tool_call_prettified)
        else:
            print(f"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}")

    messages.append({'role': 'assistant',
                    'tool_calls': res.message.tool_calls,
                    'tool_plan': res.message.tool_plan})

    # 3 - Execute tools based on the tool calls generated by the model
    print("\nTOOL RESULTS:")
    for tc in res.message.tool_calls:
        tool_result = functions_map[tc.function.name](**json.loads(tc.function.arguments))
        tool_content = [cohere.ToolContent(output=tool_result)]
        print(tool_result, "\n")
        
        messages.append({'role': 'tool',
                        'tool_call_id': tc.id,
                        'tool_content': tool_content}) 

    # 4 - Model either generates more tool calls or returns a response
    res = co.chat(model=model,
                messages=messages,
                tools=tools,
                temperature=0)
    
messages.append({"role": "assistant", "content": res.message.content[0].text})

print("\nRESPONSE:")
print(res.message.content[0].text)

if res.message.citations:
    print("\nCITATIONS:")
    for citation in res.message.citations:
        print(f"Start: {citation.start} | End: {citation.end} | Text: '{citation.text}'")
        print("Sources:")
        if citation.sources:
            for source in citation.sources:
                print(source.id)
        print("-"*50)
```
And here is an example output. In summary, the agent performs the task in a sequence of 3 steps:

1. Inspect the dataset and get a list of its columns.
2. Write and execute Python code to find the top 3 most streamed songs on Spotify in 2023 and their respective artists.
3. Search for the age and citizenship of each artist on the internet.

```
USER MESSAGE:
What's the age and citizenship of the artists who had the top 3 most streamed songs on Spotify in 2023?

You have access to a dataset with information about Spotify songs from the past 10 years, located at ./spotify_dataset.csv.
You also have access to the internet to search for information not available in the dataset.
You must use the dataset when you can, and if stuck you can use the internet.
Remember to inspect the dataset and get a list of its columnsto understand its structure before trying to query it. Take it step by step.

==================================================

TOOL PLAN:
I will first inspect the dataset to understand its structure and the columns it contains. Then, I will write and execute Python code to find the top 3 most streamed songs on Spotify in 2023 and their respective artists. Finally, I will search for the age and citizenship of each artist online.

TOOL CALLS:
Tool name: python_interpreter
  import pandas as pd
  
  df = pd.read_csv('spotify_dataset.csv')
  
  print(df.columns)

TOOL RESULTS:
{'console_output': "Index(['track_name', 'artist(s)_name', 'artist_count', 'released_year',\n       'released_month', 'released_day', 'in_spotify_playlists',\n       'in_spotify_charts', 'streams', 'in_apple_playlists', 'in_apple_charts',\n       'in_deezer_playlists', 'in_deezer_charts', 'in_shazam_charts', 'bpm',\n       'key', 'mode', 'danceability', 'valence', 'energy', 'acousticness',\n       'instrumentalness', 'liveness', 'speechiness', 'release_date'],\n      dtype='object')\n", 'executed_code': "import pandas as pd\n\ndf = pd.read_csv('spotify_dataset.csv')\n\nprint(df.columns)"} 


TOOL PLAN:
I now know the column names of the dataset. I will now find the top 3 most streamed songs on Spotify in 2023 and then find the age and citizenship of the artists of those songs.

TOOL CALLS:
Tool name: python_interpreter
  import pandas as pd
  
  df = pd.read_csv('spotify_dataset.csv')
  
  # Filter for songs released in 2023
  df_2023 = df[df['released_year'] == 2023]
  
  # Sort by streams in descending order
  df_2023 = df_2023.sort_values(by='streams', ascending=False)
  
  # Get the top 3 most streamed songs
  top_3_songs = df_2023[['track_name', 'artist(s)_name']].head(3)
  print("Top 3 most streamed songs on Spotify in 2023:", top_3_songs)
  
  # Get the artists' names
  artists = top_3_songs['artist(s)_name'].tolist()
  print("Artists:", artists)

TOOL RESULTS:
{'console_output': "Top 3 most streamed songs on Spotify in 2023:                                 track_name              artist(s)_name\n12                                 Flowers                 Miley Cyrus\n6                          Ella Baila Sola  Eslabon Armado, Peso Pluma\n133  Shakira: Bzrp Music Sessions, Vol. 53           Shakira, Bizarrap\nArtists: ['Miley Cyrus', 'Eslabon Armado, Peso Pluma', 'Shakira, Bizarrap']\n", 'executed_code': 'import pandas as pd\n\ndf = pd.read_csv(\'spotify_dataset.csv\')\n\n# Filter for songs released in 2023\ndf_2023 = df[df[\'released_year\'] == 2023]\n\n# Sort by streams in descending order\ndf_2023 = df_2023.sort_values(by=\'streams\', ascending=False)\n\n# Get the top 3 most streamed songs\ntop_3_songs = df_2023[[\'track_name\', \'artist(s)_name\']].head(3)\nprint("Top 3 most streamed songs on Spotify in 2023:", top_3_songs)\n\n# Get the artists\' names\nartists = top_3_songs[\'artist(s)_name\'].tolist()\nprint("Artists:", artists)'} 


RESPONSE:
The top 3 most streamed songs on Spotify in 2023 were:
1. *Flowers* by Miley Cyrus
2. *Ella Baila Sola* by Eslabon Armado, Peso Pluma
3. *Shakira: Bzrp Music Sessions, Vol. 53* by Shakira, Bizarrap

The artists' ages and citizenships are as follows:
1. Miley Cyrus: 30 years old (American)
2. Eslabon Armado: Unknown age (Mexican)
3. Peso Pluma: 28 years old (Mexican)
4. Shakira: 46 years old (Colombian-Spanish)
5. Bizarrap: 24 years old (Argentinian)

CITATIONS:
Start: 59 | End: 66 | Text: 'Flowers'
Sources:
python_interpreter_53ea36x4atay:0
--------------------------------------------------
Start: 71 | End: 82 | Text: 'Miley Cyrus'
Sources:
python_interpreter_53ea36x4atay:0
--------------------------------------------------
Start: 87 | End: 102 | Text: 'Ella Baila Sola'
Sources:
python_interpreter_53ea36x4atay:0
--------------------------------------------------
Start: 107 ...

...

```
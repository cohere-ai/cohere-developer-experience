---
title: "Private Deployment Usage"
slug: "v2/docs/private-deployment-usage"

hidden: false

description: "This page describes how to use Cohere's SDK to access privately deployed Cohere models."
image: "../../../assets/images/f1cc130-cohere_meta_image.jpg"  
keywords: "generative AI, large language models, private deployment"

createdAt: "Mon Apr 08 2024 14:53:59 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Wed May 01 2024 16:11:36 GMT+0000 (Coordinated Universal Time)"
---

You can use Cohere's SDK to access privately deployed Cohere models.

## Installation

To install the Cohere SDK, choose from the following 4 languages:

[[todo - from snippets library--]]

## Getting Started

The only difference between using Cohere's models on private deployments and the Cohere platform is how you set up the client. With private deployments, you need to pass the following parameters:
- `api_key` - Pass a blank value
- `base_url` - Pass the URL of your private deployment

[[todo - client setup - from snippets library - all 4 languages--]]

To get started with example use cases, refer to the following quickstart examples:
- [Text Generation (Command model)](https://docs.cohere.com/docs/text-gen-quickstart)
- [RAG (Command model)](https://docs.cohere.com/docs/rag-quickstart)
- [Tool Use (Command model)](https://docs.cohere.com/docs/tool-use-quickstart)
- [Semantic Search (Embed model)](https://docs.cohere.com/docs/sem-search-quickstart)
- [Reranking (Rerank model)](https://docs.cohere.com/docs/reranking-quickstart)

## Integrations

You can use the LangChain library with privately deployed Cohere models. Refer to the [LangChain section](https://docs.cohere.com/docs/chat-on-langchain#using-langchain-on-private-deployments) for more information on setting up LangChain for private deployments.
---
title: "Private Deployment â€“ Setting Up"
slug: "v2/docs/private-deployment-setup"

hidden: false

description: "This page describes the setup required for private deployments of Cohere's models."
image: "../../../../assets/images/f1cc130-cohere_meta_image.jpg"  
keywords: "generative AI, large language models, private deployment"

createdAt: "Mon Apr 08 2024 14:53:59 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Wed May 01 2024 16:11:36 GMT+0000 (Coordinated Universal Time)"
---

## Getting Access
When you [sign up for private deployment](https://cohere.com/contact-sales), you will receive two key pieces of information:
1. A license key for authenticating and pulling model containers
2. A list of artifacts (docker containers) that you can pull using the license key

You can then use the license to pull and run the images, as described in the [provisioning guide](https://docs.cohere.com/docs/single-container-on-private-clouds).

## Infrastructure Requirements
Different models require different hardware requirements, depending on the model types (for example, Command, Embed, and Rerank) and their different versions.

During the engagement, you will be provided with the specific requirements, which will include:
- GPU model, count, and interconnect requirements
- System requirements
- Software and driver versions

## Available Models
Visit the [Models Reference]([[todo - link to reference page]]) page to see the models available for private deployments.

Cohere has a monthly cadence for model releases and updates.

Cohere also support model customization through fine-tuning.

<Info>[Contact sales](https://cohere.com/contact-sales) to learn more about private deployments.</Info>
---
title: "Deployment Options - Overview"
slug: "v2/docs/deployment-options-overview"

hidden: false

description: "This page provides an overview of the available options for deploying Cohere's models."
image: "../../../assets/images/f1cc130-cohere_meta_image.jpg"  
keywords: "generative AI, large language models, private deployment"

createdAt: "Mon Apr 08 2024 14:53:59 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Wed May 01 2024 16:11:36 GMT+0000 (Coordinated Universal Time)"
---
The most common way to access Cohere’s large language models (LLMs) is through the Cohere platform, which is fully managed by Cohere and accessible through an API.

But that’s not the only way to access Cohere’s models. In an enterprise setting, organizations might require more control over where and how the models are hosted.

Specifically, Cohere offers four types of deployment options.
1. **Cohere Platform**
2. **Cloud AI Services**
3. **Private Deployments - Cloud**
4. **Private Deployments - On-Premises**

## Cohere platform

This is the fastest and easiest way to start using Cohere’s models. The models are hosted on Cohere infrastructure and available on our public SaaS platform (which provides an API data opt-out), which is fully managed by Cohere.

## Cloud AI services

These managed services enable enterprises to access Cohere’s models on cloud AI services. In this scenario, Cohere’s models are hosted on the cloud provider’s infrastructure. Cohere is cloud-agnostic, meaning you can deploy our models through any cloud provider.

### AWS

Developers can access a range of Cohere’s language models in a private environment via Amazon’s AWS Cloud platform. Cohere’s models are supported on two Amazon services: **Amazon Bedrock** and **Amazon SageMaker**.

#### Amazon Bedrock

Amazon Bedrock is a fully managed service where foundational models from Cohere are made available through a single, serverless API. [Read about Bedrock here](http://docs.aws.amazon.com/bedrock).

[View Cohere’s models on Amazon Bedrock](https://aws.amazon.com/bedrock/cohere/).

#### Amazon SageMaker

Amazon SageMaker is a service that allows customers to prepare data and build, train, and deploy machine learning (ML) models for any use case with fully managed infrastructure, tools, and workflows. [Read about SageMaker here.](https://aws.amazon.com/pm/sagemaker/)

Cohere offers a comprehensive suite of generative and embedding models through SageMaker on a range of hardware options, many of which support finetuning for deeper customization and performance.

[View Cohere's model listing on the AWS Marketplace](https://aws.amazon.com/marketplace/seller-profile?id=87af0c85-6cf9-4ed8-bee0-b40ce65167e0).

### Azure AI Foundry

Azure AI Foundry is a platform that is designed for developers to build generative AI applications on an enterprise-grade platform. Developers can explore a wide range of models, services, and capabilities to build AI applications that meet their specific goals.

[View Cohere’s models on Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/deploy-models-cohere-command).

### OCI Generative AI Service

Oracle Cloud Infrastructure Generative AI is a fully managed service that enables you to use Cohere's [generative](https://docs.oracle.com/en-us/iaas/Content/generative-ai/generate-models.htm) and [embedding models](https://docs.oracle.com/en-us/iaas/Content/generative-ai/embed-models.htm) through an API.

## Private deployments

### Cloud (VPC)

Private deployments (cloud) allow enterprises to deploy the Cohere stack privately on cloud platforms. With AWS, Cohere’s models can be deployed in an enterprise’s AWS Cloud environment via their own VPC (EC2, EKS). Compared to managed cloud services, VPC deployments provide tighter control and compliance. No egress is another common reason for going with VPCs. Overall, the VPC option has a higher management burden but offers more flexibility.

### On-premises

Private deployments on-premises (on-prem) allow enterprises to deploy the Cohere stack privately on their own compute. This includes air-gapped environments where systems are physically isolated from unsecured networks, providing maximum security for sensitive workloads.
---
title: Semantic search - quickstart
slug: v2/docs/sem-search-quickstart

description: "A quickstart guide for performing text semantic search with Cohere's Embed models (v2 API)."
image: "../../../../assets/images/f1cc130-cohere_meta_image.jpg"  
keywords: "Cohere, semantic search, text embeddings, embed models"
---
Cohere's embedding models are available via the Embed endpoint. This endpoint enables you to embed text documents (multilingual) and images into a vector space.

Semantic search, powered by embeddings, enables applications to perform information retrieval based on the context or meaning of a document.

This quickstart guide shows you how to perform semantic search with the Embed endpoint.

<Steps>
### Setup
First, install the Cohere Python SDK with the following command.

```bash
pip install -U cohere
```

Next, import the library and create a client.

<Tabs>
<Tab title="Cohere Platform">

```python PYTHON
import cohere

co = cohere.ClientV2(
    "COHERE_API_KEY"
)  # Get your free API key here: https://dashboard.cohere.com/api-keys
```

</Tab>
<Tab title="Private Deployment">

```python PYTHON
import cohere

co = cohere.ClientV2(
    api_key="",  # Leave this blank
    base_url="<YOUR_DEPLOYMENT_URL>",
)
```

</Tab>

<Tab title="Bedrock">

```python PYTHON
import cohere

co = cohere.BedrockClientV2(
    aws_region="AWS_REGION",
    aws_access_key="AWS_ACCESS_KEY_ID",
    aws_secret_key="AWS_SECRET_ACCESS_KEY",
    aws_session_token="AWS_SESSION_TOKEN",
)

# Get the model name: https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html
```
</Tab>

<Tab title="SageMaker">

```python PYTHON
import cohere

co = cohere.SagemakerClientV2(
    aws_region="AWS_REGION",
    aws_access_key="AWS_ACCESS_KEY_ID",
    aws_secret_key="AWS_SECRET_ACCESS_KEY",
    aws_session_token="AWS_SESSION_TOKEN",
)
```
</Tab>

<Tab title="Azure AI">

```python PYTHON
import cohere

co = cohere.ClientV2(
    api_key="AZURE_API_KEY",
    base_url="AZURE_ENDPOINT",
)
```
</Tab>

</Tabs>

### Document Embeddings
First, embed the list of available documents using the Embed endpoint by specifying the `input_type` as `search_document`.

<Tabs>
<Tab title="Cohere Platform">
```python PYTHON
# Define the documents
documents = [
    "Joining Slack Channels: Be sure to join relevant channels to stay informed and engaged.",
    "Finding Coffee Spots: For your caffeine fix, cross the street to the café for artisan coffee.",
    "Working Hours Flexibility: While our core hours are 9 AM to 5 PM, we offer flexibility to adjust as needed.",
]

# Embed the documents
doc_emb = co.embed(
    model="embed-v4.0",
    input_type="search_document",
    texts=documents,
    max_tokens=8000,
    output_dimension=1024,
    embedding_types=["float"],
).embeddings.float
```
</Tab>

<Tab title="Private Deployment">
```python PYTHON
# Define the documents
documents = [
    "Joining Slack Channels: Be sure to join relevant channels to stay informed and engaged.",
    "Finding Coffee Spots: For your caffeine fix, cross the street to the café for artisan coffee.",
    "Working Hours Flexibility: While our core hours are 9 AM to 5 PM, we offer flexibility to adjust as needed.",
]

# Embed the documents
doc_emb = co.embed(
    model="embed-v4.0",
    input_type="search_document",
    texts=documents,
    max_tokens=8000,
    output_dimension=1024,
    embedding_types=["float"],
).embeddings.float
```
</Tab>

<Tab title="Bedrock">
```python PYTHON
# Define the documents
documents = [
    "Joining Slack Channels: Be sure to join relevant channels to stay informed and engaged.",
    "Finding Coffee Spots: For your caffeine fix, cross the street to the café for artisan coffee.",
    "Working Hours Flexibility: While our core hours are 9 AM to 5 PM, we offer flexibility to adjust as needed.",
]

# Embed the documents
doc_emb = co.embed(
    model="YOUR_MODEL_NAME",
    input_type="search_document",
    texts=documents,
    embedding_types=["float"],
).embeddings.float
```
</Tab>

<Tab title="SageMaker">
```python PYTHON
# Define the documents
documents = [
    "Joining Slack Channels: Be sure to join relevant channels to stay informed and engaged.",
    "Finding Coffee Spots: For your caffeine fix, cross the street to the café for artisan coffee.",
    "Working Hours Flexibility: While our core hours are 9 AM to 5 PM, we offer flexibility to adjust as needed.",
]

# Embed the documents
doc_emb = co.embed(
    model="YOUR_ENDPOINT_NAME",
    input_type="search_document",
    texts=documents,
    embedding_types=["float"],
).embeddings.float
```
</Tab>

<Tab title="Azure AI">
```python PYTHON
# Define the documents
documents = [
    "Joining Slack Channels: Be sure to join relevant channels to stay informed and engaged.",
    "Finding Coffee Spots: For your caffeine fix, cross the street to the café for artisan coffee.",
    "Working Hours Flexibility: While our core hours are 9 AM to 5 PM, we offer flexibility to adjust as needed.",
]

# Embed the documents
doc_emb = co.embed(
    input_type="search_document",
    texts=documents,
    embedding_types=["float"],
).embeddings.float
```
</Tab>
</Tabs>

### Query Embedding
Next, embed the user query using the Embed endpoint by specifying the `input_type` as `search_query`.

<Tabs>
<Tab title="Cohere Platform">
```python PYTHON
# Add the user query
query = "Ways to connect with my teammates"

# Embed the query
query_emb = co.embed(
    model="embed-v4.0",
    input_type="search_query",
    texts=[query],
    max_tokens=8000,
    output_dimension=1024,
    embedding_types=["float"],
).embeddings.float
```
</Tab>

<Tab title="Private Deployment">
```python PYTHON
# Add the user query
query = "Ways to connect with my teammates"

# Embed the query
query_emb = co.embed(
    model="embed-v4.0",
    input_type="search_query",
    texts=[query],
    max_tokens=8000,
    output_dimension=1024,
    embedding_types=["float"],
).embeddings.float
```
</Tab>

<Tab title="Bedrock">
```python PYTHON
# Add the user query
query = "Ways to connect with my teammates"

# Embed the query
query_emb = co.embed(
    model="YOUR_MODEL_NAME",
    input_type="search_query",
    texts=[query],
    embedding_types=["float"],
).embeddings.float
```
</Tab>

<Tab title="SageMaker">
```python PYTHON
# Add the user query
query = "Ways to connect with my teammates"

query_emb = co.embed(
    model="embed-v4.0",
    input_type="search_query",
    texts=[query],
    max_tokens=8000,
    output_dimension=1024,
    embedding_types=["float"],
).embeddings.float
```
</Tab>

<Tab title="Azure AI">
```python PYTHON
# Add the user query
query = "Ways to connect with my teammates"

query_emb = co.embed(
    model="embed-v4.0",
    input_type="search_query",
    texts=[query],
    max_tokens=8000,
    output_dimension=1024,
    embedding_types=["float"],
).embeddings.float
```
</Tab>
</Tabs>

### Semantic Search

Then, perform semantic search by computing the similarity between the query embedding and the document embeddings, and then returning the most similar documents.

```python PYTHON
import numpy as np


# Compute dot product similarity and display results
def return_results(query_emb, doc_emb, documents):
    n = 2  # customize your top N results
    scores = np.dot(query_emb, np.transpose(doc_emb))[0]
    max_idx = np.argsort(-scores)[:n]

    for rank, idx in enumerate(max_idx):
        print(f"Rank: {rank+1}")
        print(f"Score: {scores[idx]}")
        print(f"Document: {documents[idx]}\n")


return_results(query_emb, doc_emb, documents)
```

```mdx wordWrap
Rank: 1
Score: 0.262197161387274
Document: Joining Slack Channels: Be sure to join relevant channels to stay informed and engaged.

Rank: 2
Score: 0.1266074257723145
Document: Working Hours Flexibility: While our core hours are 9 AM to 5 PM, we offer flexibility to adjust as needed.
```
</Steps>

## Further Resources
- [Embed endpoint API reference](https://docs.cohere.com/reference/embed)
- [Documentation on embeddings](https://docs.cohere.com/docs/embeddings)
- [LLM University module on semantic search](https://cohere.com/llmu#semantic-search)
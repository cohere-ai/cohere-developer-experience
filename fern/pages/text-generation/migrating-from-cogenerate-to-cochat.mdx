---
title: "Migrating from the Generate API to the Chat API"
slug: "docs/migrating-from-cogenerate-to-cochat"

hidden: false 
description: "The document outlines the migration from the Generate endpoint to the Chat endpoint for Cohere's generative functionality, advising users to use the Chat endpoint for improved model output quality and providing steps for a smooth transition. The Generate endpoint will still be available but will no longer receive new features."
image: "../../assets/images/c64f7d8-cohere_meta_image.jpg"  
keywords: "text generation, chat API, large language models"

createdAt: "Mon Feb 12 2024 17:29:36 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Thu May 30 2024 15:54:19 GMT+0000 (Coordinated Universal Time)"
---
<Info> 
Users of [Amazon Sagemaker](https://aws.amazon.com/marketplace/pp/prodview-n44fbeuycwldi), [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-cohere-command.html), and [Oracle Cloud Infrastructure (OCI)](https://www.oracle.com/artificial-intelligence/generative-ai/large-language-models/) don't need to migrate. Please refer to platform-specific documentation for recommended usage of Cohere Command models.
</Info>

With our newest planned updates, Generate will be relegated to legacy status. It will still be available for use, but will no longer be updated with new features.

In order to use Cohere generative functionality, we recommend using the [Chat endpoint](/reference/chat). This guide outlines how to migrate from Generate to Chat in order to get improved performance and to eliminate any potential interruptions. 

## Overview

The difference between Chat and Generate is that the Chat endpoint adds a default preamble to the user prompt that improves the quality of the modelâ€™s output. 

Here's an example:

```python PYTHON
# BEFORE
co.generate(prompt="Write me three bullet points for my resume")

# AFTER
co.chat(message="Write me three bullet points for my resume")
```

### Unsupported Parameters

The following parameters were previously available in Generate but are _not supported_ by Chat. 

- `num_generations`: To achieve the same outcome as `num_generations=n`  in Chat, please call `co.chat()`  `n`  times.
- `stop_sequences` and `end_sequences`: Going forward, we ask users to trim model outputs on their side instead of setting a stop sequence.
- `return_likelihoods`: This is not supported in the Chat endpoint.
- `logit_bias`: This is not supported in the Chat endpoint.
- `truncate`: This is not supported in the Chat endpoint.
- `preset`: This is not supported in the Chat endpoint. Please create and store presets on your end instead of storing them via our endpoints.

### Example for Migrating from Generate to Chat

Here are some steps you can take to ensure that your migration goes smoothly:

- Ensure that you're using the `message` parameter instead of the  `prompt` parameter. The primary way of communicating with the Chat API is via  `message`. Going forward, send the contents of your prompt through  `message` and _not_ through `prompt`. 
- No changes have been made to `k`, `p`, `frequency_penalty`, `presence_penalty`, `max_tokens`, `stream`, or `temperature`, so those should behave as expected.

### Fine-tuned Models

Models that were fine-tuned to use the Generate API will work with the Chat API. Remember not to use the `chat_history` parameter, as this parameter is only supported for models fine-tuned for Chat. 

We will not delete or disable the Generate endpoint, but we suggest fine-tuning models for use with the Chat endpoint in the future.

## FAQs About Migration

**When will the generate endpoint stop being supported?**

At this time, we will still support requests to Generate but we will not be making feature updates. For this reason, the Generate is being marked as a _legacy_ API endpoint.

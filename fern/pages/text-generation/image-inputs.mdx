---
title: Using Cohere's Models to Work with Image Inputs
slug: /docs/image-inputs

description: "This page describes how a Cohere large language model works with image inputs. It covers passing images with the API, limitations, and best practices."
image: "../../assets/images/f1cc130-cohere_meta_image.jpg"  
keywords: "Cohere, large language models, vision models"
---

[NOTES from MICHAEL 06/09/2025]
- ~This is possible~
- Simplest possible example
- ~Image detail~
  - Discuss tradeoffs, when does each make scenes
  - Talk about the default ('auto')
    - Chooses for you, based on image dimension 
  - 'high' means image is split into tiles (up to `n`, whatever the max is), each tile is 256*something 
    - Provide an example, i.e., 1000x1000, you'll have 1000/256x1000/256, plus the preview tile, this will result in `n` tokens.
  - Token counting
- passing an Image
  - Base 64 and HTTP URLs 
    - Base64 can be used anywhere
    - HTTP means you don't have to re-upload the image on every request.
      - With the ChatAPI, you have to append messages, which would be prohibitive if you're sending massive images. But with an HTTP URL, multi-turn is leaner. This is much lower latency.
- Image specs  
  - formats 
    - PNG, JPEG, GIF 
  - How many can you send at once? 
  - How big can an image be? 
  - Works will in JSON mode (THINK ABOUT WHERE TO PUT THIS.)



## Introduction 
Multimodality has become an important part of the modern generative AI landscape, as there's real demand for models able to understand and interpret visual data, map relationships between text and visual inputs, and handle use cases like image captioning, visual question-answering, and object identification. 

[PULL FROM ANTHROPIC COOKBOOK]
[THIS IS DUPLICATIVE OF THE 'USE CASES' SECTION BELOW, I'LL HAVE TO FIND A WAY TO CONSOLIDATE]
Excellent in enterprise use cases that benefit from processing images and documents' visual components, such as:

- Chart, graph, diagram, table understanding, and analysis
- Document OCR and Q&A
- Real-world natural image processing, including translation of text found in images.
- more… (cookbook)

[Work with Meor to get a very simple example]

This document outlines how to work with Cohere's Vision models.



## Image Detail

- Supported image resolution (e.g. file size/pixels/ratios/etc)

Cohere's API will allow users to control the level of image “detail” sent to the model. This property is specified for each image and can be set to `“low”`, `“high”` or `“auto”` (the default). This works exactly the same way as OpenAI's image models. 

```python PYTHON 
co.chat(
  model="command-vision",
  messages=[
	{ "role": "user", "content": [
            {"type": "text",
              "text": "what's in this image?"
              },
            {"type": "image_url",
            "image_url": {
              "url": "https://cohere.com/favicon-32x32.png",
              "detail": "high"
          }
        },
      ]
    }
  ]
)
```

When detail is set to `“low”`:
- If the image is larger than 512x512 pixels it will be resized to fit into these dimensions while attempting to approximate the aspect ratio.
- Each `“low”` detail image takes up 256 tokens that count towards the model’s context length.

When detail is set to `“high”`:
- If the image is larger than 1536x2048 pixels it will be resized to fit into these dimensions without changing the aspect ratio, so that it can be cached.
- Under the hood, the model will divide the image into one or more tiles of 512x512 pixels plus one 512x512 pixel preview tile; each of these tiles takes up 256 tokens that count towards the model’s context length. 
[Per Cassie's comment, add a bit of the details on how we exactly calculate the numbers of 512 X 512 tiles? And I believe we have a max limit of the number being 9?]
[Per Cassie's comment: We can also discuss this calculation logic in the pricing section like OpenAI's page https://platform.openai.com/docs/guides/images-vision?api-mode=chat]

[TODO]
Discuss tradeoffs, when does each make scenes
  - Talk about the default ('auto')
    - Chooses for you, based on image dimension 
  - 'high' means image is split into tiles (up to `n`, whatever the max is), each tile is 256*something 
    - Provide an example, i.e., 1000x1000, you'll have 1000/256x1000/256, plus the preview tile, this will result in `n` tokens.
  - Token counting

## Passing in an Image

As with Cohere's [Aya models](https://docs.cohere.com/docs/aya-vision), users will be able to send in images as base64 data url strings (e.g., `“data:image/png;base64,...”`) by setting content type to `“image_url”`:

```python PYTHON
co.chat(
    model="command-vision",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "what's in this image?"},
                {
                    "type": "image_url",
                    "image_url": {"url": "data:image..."},
                },
            ],
        }
    ],
)
```

In addition to specifying images as base64 data urls the API will support HTTP and HTTPS URLs (eg “https://cohere.com/favicon-32x32.png”). This is useful for two reasons:

- First, it makes the API easy to try out in postman, as data URLs are long and hard to deal with.
- Second, including long data URLs in the request increases the request size and increases network latency. For use cases like chatbots, where the old images accumulate in the chat history, we recommend you use image URLs, since the request size will be smaller, and with server-side caching will result in faster response times.

```python PYTHON
co.chat(
    model="command-vision",
    messages=[
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "what's in this image?"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://cohere.com/favicon-32x32.png"
                    },
                },
            ],
        }
    ],
)
```

## Image Preparation

### Image Formats

- HTTP URL - faster, but you need to upload your image somewhere, and not available outside platform (not in Azure, Bedrock)
- Base64 - how to encode, API structure
- URL - how to format, API structure

[TODO] Comparison - pros and cons of both

### Image Counts 

- You can pass in a maximum of 20 images per request, or 20 megabytes (mb) in total data, whichever comes first.
- API structure

### Rate Limits

TODO

### Understanding Costs 

- How image tokens are estimated (e.g., (width_px * height_px) / xyz)
- Impact of image size and number on cost
- Example cost calculations

### Limitations of working with the Image API

- Image input limits (e.g. max file size, max num of images per call, resolution, etc)
- Accuracy Considerations (Low-quality images, complex scenes)
- Specific Task Limitations (e.g., precise counting, spatial reasoning, identifying people, detecting AI-generated images)
Non-Latin Alphabets: Performance may vary when processing images containing text in non-Latin scripts, like Japanese or Korean characters.
Text Size: To enhance accuracy, consider enlarging small text in images while ensuring no crucial visual information is lost.
Potential Errors: In some cases, the model might produce inaccurate descriptions or captions.

### Total number of images

For Command Vision, you can pass in a maximum of 20 images per request, or 20 megabytes (mb) in total data, whichever comes first.

### Max size of a single image

For Command Vision:
- Low-resolution: 512px x 512px
- High-resolution: 1536px (short side) x 2048px (long side)
  - Walter says "high-resolution can be up to 512px*12 total pixels but maybe that's harder to communicate," but I'm not sure what he means.

### File types

- PNG (`.png`)
- JPEG (`.jpeg` and `.jpg`)
- WEBP (`.webp`)
- Non-animated GIF (`.gif`)

## Prompt Engineering for Image Models

- How to create effective prompts (system prompt/user prompt)
- Image/text ordering
- [MAYBE LEAVE THIS OUT, Cassie says "We don't support interleaved image and text"] Referencing Images (e.g., "Image 1:", "Image 2:")
- Multi-turn prompting (e.g. In multi-turn chat, does the API hold context/tokens of the images in the previous turns?)

## Example Use Cases

Excellent in enterprise use cases that benefit from processing images and documents' visual components, such as:

- Chart, graph, diagram, table understanding, and analysis
- Document OCR and Q&A
- Real-world natural image processing
- more… (cookbook)

## Guidelines 

- No real-time content blocking will take place in the API
- Images cached in GCS will go through CSAM checks
- Cohere Tokens
- Put'Inappropriate Use' in the guidelines section (IF I decide to include one).
- Safety and Responsible AI (Prohibited content, biased interpretations)
- Should work with Safety team to ensure we document this properly

## Best Practices

- Handling common errors
- Recommended image size/resolution
- Resizing Large Images (Benefits: latency, cost, performance; recommended dimensions)
- Impact of image Quality (Clarity, blurriness, legibility of text)
- Getting best results out of the model
- Official languages: English, Portuguese, Italian, French, German, and Spanish.



## FAQs

TODO

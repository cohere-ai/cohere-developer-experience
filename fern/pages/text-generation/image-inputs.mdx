---
title: Using Cohere's Models to Work with Image Inputs
slug: /docs/image-inputs

description: "This page describes how a Cohere large language model works with image inputs. It covers passing images with the API, limitations, and best practices."
image: "../../assets/images/f1cc130-cohere_meta_image.jpg"  
keywords: "Cohere, large language models, vision models"
---

## Introduction 
Vision Language Models (VLMs) are AI systems that combine computer vision and natural language processing (NLP) to understand and interpret visual data, such as images. VLMs map relationships between text and visual inputs, enabling tasks like image captioning, visual question-answering, and object identification. 

Command Vision deliveres a robust VLM capable of accurate, versatile, and reliable performance across diverse applications. It excels in tasks like detailed image description, complex query answering, and real-world integration, setting a new standard for vision-language AI.

This document outlines how to work with Command Vision.

## Getting Started
[Work with Meor to do this]

## Image Preparation

## Image Formats

- Base64 - how to encode, API structure
- URL - how to format, API structure

[TODO] Comparison - pros and cons of both

### Passing in an Image

As with Cohere's [Aya models](link), users will be able to send in images as base64 data url strings (e.g., `“data:image/png;base64,...”`) by setting content type to `“image_url”`:

```python PYTHON
co.chat(
  model="command-vision",
  messages=[
	{ "role": "user", "content": [
        {"type": "text",
        "text": "what's in this image?"},
        {"type": "image_url",
        "image_url": {"url": "data:image..."}
        }
      ]
    }
  ]
)
```

In addition to specifying images as base64 data urls the api will support HTTP and HTTPS URLs (eg “https://cohere.com/favicon-32x32.png”). This is useful for two reasons:

- First, it makes the API easy to try out in postman, as data URLs are long and hard to deal with.
- Second, including long data URLs in the request increases the request size and increases network latency. For use cases such as chatbots, where the old images accumulate in the chat history, it is recommended to use image URLs, since the request size will be smaller, and with server-side caching will result in faster response times.

```python PYTHON
co.chat(
  model="command-vision",
  messages=[
	{ "role": "user", "content": [
            {"type": "text", "text": "what's in this image?"},
            {"type": "image_url", "image_url": {
            "url": "https://cohere.com/favicon-32x32.png"
        }},
    ]}
  ]
)
```

## Image Counts 

- Single images, multiple images, etc
- API structure

## Image Resolution

- Supported image resolution (e.g. file size/pixels/ratios/etc)

Cohere's API will allow users to control the level of image “detail” sent to the model. This property is specified for each image and can be set to `“low”`, `“high”` or `“auto”`, defaulting to `“auto”` if not specified. This works exactly the same way as OpenAI's image models. 

```python PYTHON 
co.chat(
  model="command-vision",
  messages=[
	{ "role": "user", "content": [
            {"type": "text",
              "text": "what's in this image?"
              },
            {"type": "image_url",
            "image_url": {
              "url": "https://cohere.com/favicon-32x32.png",
              "detail": "high"
          }
        },
      ]
    }
  ]
)
```

When detail is set to `“low”`:
- If the image is larger than 512x512 pixels it will be resized to fit into these dimensions without changing the aspect ratio, so that it can be cached.
- Each `“low”` detail image takes up 256 tokens that count towards the model’s context length.

When detail is set to `“high”`:
- If the image is larger than 1536x2048 pixels it will be resized to fit into these dimensions without changing the aspect ratio, so that it can be cached.
- Under the hood, the model will divide the image into one or more tiles of 512x512 pixels plus one 512x512 pixel preview tile; each of these tiles takes up 256 tokens that count towards the model’s context length. 

## Prompt Engineering for Image Models

- How to create effective prompts (system prompt/user prompt)
- Image/text ordering
- Referencing Images (e.g., "Image 1:", "Image 2:")
- Multi-turn prompting (e.g. In multi-turn chat, does the API hold context/tokens of the images in the previous turns?)

### Raw Prompting

Currently there is no Raw Prompting API with support for images. This is because in addition to the prompt, raw image bytes get sent to the model. To allow modelling teams to try various raw prompts on the hosted models, we can implement the following options.

[TODO: SHOULD THIS EVEN BE IN HERE?] #### Option 1: Expose “images” internal-only param in Generate API

This is the true “raw prompting” solution. The user is expected to handle image resizing and to invoke the Image Tiler logic when building the prompt. Image Tiler is available as a python library in the datatools repo.

#### Option 2: Use `skip_preamble` parameter in Chat along with `detail=”unprocessed”`

This is the “raw turns” approach, leaves turn formatting and image tiling logic to the API, while allowing the developer to experiment with various system and user instructions. Setting the `detail` level for each image to “unprocessed” will skip all API-level image processing (the model will do the image resizing).

Request (no images)

```python PYTHON 
{
  model="command-vision"
  skip_preamble=True,
  messages=[
	{ "role": "system", "content": "custom system message" },
	{ "role": "user", "content": "custom user message" },
    { "role": "system", "content": "custom system message" }
  ]
}
```

**Prompt**
```bash
<BOS_TOKEN><|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>custom system message<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|USER_TOKEN|>custom user message<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>custom system message<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>"
```

**Request** 

```python PYTHON
{
  model="command-vision"
  skip_preamble=True,
  messages=[
	{
        "role": "system",
        "content": "custom system message"
    },
    {
        "role": "user", 
        "content": [{ "type": "image_url", "image_url": {
            "url": "..",
            "detail": "unprocessed"
        }}]
    },
  ]
}
```

**Prompt** 

```txt 
<BOS_TOKEN><|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>custom system message<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|ofUSER_TOKEN|><|START_OF_IMG|>GLOBAL_TILE<|IMG_PATCH|><|IMG_PATCH|><|IMG_PATCH|>...<|IMG_PATCH|><|END_OF_IMG|><|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>
```

**Note:** there are currently some limitations in the API around interweaving text and images in the same message object. Specifically, if **the same message (aka turn)** object contains both images and text, the images will always make it after the text **of that message (aka turn)** in the prompt.

Example:

turn message: <image1> how is the image above different from the image below? <image2>

turn in the prompt: <|START_TURN|>how is the image above different from the image below? <image1> <image2><|END_TURN|>

This was a requirement for the current set of multi-modal models, but the API will support mix-and-matching content within the same turn soon after launch.

## Example Use Cases

- Question answering
- Data extraction with structured outputs
- Multilingual multimodal
- Multimodal RAG
- more… (cookbook)

## Best Practices

- Handling common errors
- Recommended image size/resolution
- Resizing Large Images (Benefits: latency, cost, performance; recommended dimensions)
- Impact of image Quality (Clarity, blurriness, legibility of text)
- Getting best results out of

## Limitations of working with the Image API

- Image input limits (e.g. max file size, max num of images per call, resolution, etc)
- Accuracy Considerations (Low-quality images, complex scenes)
- Specific Task Limitations (e.g., precise counting, spatial reasoning, identifying people, detecting AI-generated images)
- Safety and Responsible AI (Prohibited content, biased interpretations)

### Total number of images

TODO.

### Max size of a single image

TODO.


### File types

- PNG (`.png`)
- JPEG (`.jpeg` and `.jpg`)
- WEBP (`.webp`)
- Non-animated GIF (`.gif`)

### File Content Moderation

- No real-time content blocking will take place in the API
- Images cached in GCS will go through CSAM checks
- Should work with Safety team to ensure we document this properly

### Rate Limits

TODO

## Understanding Costs 

- How image tokens are estimated (e.g., (width_px * height_px) / xyz)
- Impact of image size and number on cost
- Example cost calculations

## FAQs

TODO

---
title: Introduction to Embeddings at Cohere
slug: docs/embeddings
hidden: false
description: >-
  Embeddings transform text into numerical data, enabling language-agnostic
  similarity searches and efficient storage with compression.
image: ../../assets/images/fa074c3-cohere_docs_preview_image_1200x630_copy.jpg
keywords: 'vector embeddings, embeddings, natural language processing'
createdAt: 'Thu Sep 01 2022 14:50:09 GMT+0000 (Coordinated Universal Time)'
updatedAt: 'Tue May 28 2024 19:14:00 GMT+0000 (Coordinated Universal Time)'
---
<img src='../../assets/images/e8ea586-Embeddings_Visual_1_1.png' alt='embeddings.' />


Embeddings are a way to represent the **meaning** of text as a list of numbers. Using a simple comparison function, we can then calculate a similarity score for two embeddings to figure out whether two texts are talking about similar things. Common use-cases for embeddings include semantic search, clustering, and classification.

In the example below we use the `embed-v4.0` model to generate embeddings for 3 phrases and compare them using a similarity function. The two similar phrases have a high similarity score, and the embeddings for two unrelated phrases have a low similarity score:

```python PYTHON
import cohere
import numpy as np

co = cohere.Client(api_key="YOUR_API_KEY")

# get the embeddings
phrases = ["i love soup", "soup is my favorite", "london is far away"]

model = "embed-v4.0"
input_type = "search_query"

res = co.embed(
    texts=phrases,
    model=model,
    input_type=input_type,
    output_dimensions=1024,
    embedding_types=["float"],
)

(soup1, soup2, london) = res.embeddings.float


# compare them
def calculate_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))


calculate_similarity(soup1, soup2)  # 0.85 - very similar!
calculate_similarity(soup1, london)  # 0.16 - not similar!
```

## The `input_type` parameter

Cohere embeddings are optimized for different types of inputs.

- When using embeddings for [semantic search](/docs/semantic-search), the search query should be embedded by setting `input_type="search_query"`
- When using embeddings for semantic search, the text passages that are being searched over should be embedded with `input_type="search_document"`.
- When using embedding for `classification` and `clustering` tasks, you can set `input_type` to either 'classification' or 'clustering' to optimize the embeddings appropriately.
- When `input_type='image'`, the expected input to be embedded is an image instead of text.

## Multilingual Support

`embed-v4.0` is a best-in-class best-in-class multilingual model with support for over 100 languages, including Chinese, Spanish, and French.

```python PYTHON
import cohere

co = cohere.Client(api_key="<YOUR API KEY>")

texts = [
    "Hello from Cohere!",
    "مرحبًا من كوهير!",
    "Hallo von Cohere!",
    "Bonjour de Cohere!",
    "¡Hola desde Cohere!",
    "Olá do Cohere!",
    "Ciao da Cohere!",
    "您好，来自 Cohere！",
    "कोहेरे से नमस्ते!",
]

response = co.embed(
    model="embed-v4.0",
    texts=texts,
    input_type="classification",
    output_dimensions=1024,
    embedding_types=["float"],
)

embeddings = response.embeddings.float  # All text embeddings
print(embeddings[0][:5])  # Print embeddings for the first text
```

## Image Embeddings

The Cohere Embedding platform supports image embeddings for `embed-v4.0` and the `embed-v3.0` family. There are two ways to access this functionality: 

- Pass `image` to the `input_type` parameter. Here are the steps:
    - 1) Pass image to the input_type parameter 
    - 2) Pass your image URL to the images parameter
- Pass your image URL to the new `images` parameter. Here are the steps:
    - 1) pass in a input list of `dicts` with the key content 
    - 2) content contains a list of `dicts` with the keys `type` and `image`

When using the `images` parameter the following restrictions exist: 

- Pass `image` to the `input_type` parameter (as discussed above).
- Pass your image URL to the new `images` parameter.

Be aware that image embedding has the following restrictions:

- If `input_type='image'`, the `texts` field must be empty.
- The original image file type must be in a `png`, `jpeg`, `webp`, or `gif` format and can be up to 5 MB in size.
- The image must be base64 encoded and sent as a Data URL to the `images` parameter.
- Our API currently does not support batch image embeddings.

When using the `inputs` parameter the following restrictions exist (note these restrictions apply to `embed-v4.0`):

- The maximum size of payload is 20mb
- All images larger than 2,4578,624 pixels will be downsampled to 2,4578,624 pixels
- All images smaller than 200,604 pixels will be upsampled to 200,604 pixels
- `input_type` must be set to one of the following
    - `search_query`
    - `search_document`
    - `classification`
    - `clustering`

Here's a code sample using the `inputs` parameter:
```python PYTHON
import cohere
from PIL import Image
from io import BytesIO
import base64

co = cohere.Client(api_key="<YOUR API KEY>")

# The model accepts input in base64 as a Data URL


def image_to_base64_data_url(image_path):
    # Open the image file
    with Image.open(image_path) as img:
        # Create a BytesIO object to hold the image data in memory
        buffered = BytesIO()
        # Save the image as PNG to the BytesIO object
        img.save(buffered, format="PNG")
        # Encode the image data in base64
        img_base64 = base64.b64encode(buffered.getvalue()).decode(
            "utf-8"
        )

    # Create the Data URL and assumes the original image file type was png
    data_url = f"data:image/png;base64,{img_base64}"
    return data_url


processed_image = image_to_base64_data_url("<PATH_TO_IMAGE>")

input=[
	{"content":[{"type":"image":processed_image}]}
]

ret = co.embed(
    model="embed-v4.0",
    embedding_types=["float"],
    input_type='search_document',
    inputs=input,
    output_dimensions=1024
)

ret.embeddings.float
```

Here's a code sample using the `images` parameter:
```python PYTHON
import cohere
from PIL import Image
from io import BytesIO
import base64

co = cohere.Client(api_key="<YOUR API KEY>")

# The model accepts input in base64 as a Data URL


def image_to_base64_data_url(image_path):
    # Open the image file
    with Image.open(image_path) as img:
        # Create a BytesIO object to hold the image data in memory
        buffered = BytesIO()
        # Save the image as PNG to the BytesIO object
        img.save(buffered, format="PNG")
        # Encode the image data in base64
        img_base64 = base64.b64encode(buffered.getvalue()).decode(
            "utf-8"
        )

    # Create the Data URL and assumes the original image file type was png
    data_url = f"data:image/png;base64,{img_base64}"
    return data_url


processed_image = image_to_base64_data_url("<PATH_TO_IMAGE>")

ret = co.embed(
    images=[processed_image],
    model="embed-v4.0",
    embedding_types=["float"],
    input_type="image",
)

ret.embeddings.float
```

## Matryoshka Embeddings
Matryoshka learning creates embeddings with coarse-to-fine representation within a single vector; `embed-v4.0` supports multiple output dimensions in the following values: `[256,512,1024,1536]`. To access this, you specify the parameter `output_dimensions` when creating the embeddings. 

```python PYTHON
texts = ["hello"]

response = co.embed(
    model="embed-v4.0",
    texts=texts,
    output_dimensions=1024,
    input_type="classification",
    embedding_types=["float"],
).embeddings

# print out the embeddings
response.float  # returns a vector that is 1024 dimensions
```

## Support for Fused and Mixed Modalities
`embed-v4.0` supports text and content-rich images such as figures, slide decks, document screen shots (i.e. screenshots of PDF pages). This eliminates the need for complex text extraction or ETL pipelines. Unlike our previous `embed-v3.0` model family, `embed-v4.0` is capable of processing both images and texts together; the inputs can either be an image that contains both text and visual content, or text and images that youd like to compress into a single vector representation. 

A popular example of fused images and texts would be in e-Commerce, where you could have an asset represented as a JSON object with a corresponding image. 
```json JSON
{
    "product_title": "Nike Men's Low-Top Sneaker",
    "product_description": "Braided and synthetic fabric on the upper provides a lightweight fit and airy feel Foam midsole is soft and comfortable Elastic inner sleeve and booty-like structure create a custom fitRubber on the sole adds traction and durability",
    "brand_name": "Nike",
    "image_assets": [
        "some_url",
        "some_url",
        "some_url",
    ],
}
```

![Fused image and texts](../../assets/images/ecommerce_sneakers.png)

Here's a code sample illustrating how `embed-v4.0` could be used to work with fused images and texts like the above:

```python PYTHON
import cohere
from PIL import Image
from io import BytesIO
import base64

co = cohere.Client(api_key="<YOUR API KEY>")

# The model accepts input in base64 as a Data URL


def image_to_base64_data_url(image_path):
    # Open the image file
    with Image.open(image_path) as img:
        # Create a BytesIO object to hold the image data in memory
        buffered = BytesIO()
        # Save the image as PNG to the BytesIO object
        img.save(buffered, format="PNG")
        # Encode the image data in base64
        img_base64 = base64.b64encode(buffered.getvalue()).decode(
            "utf-8"
        )

    # Create the Data URL and assumes the original image file type was png
    data_url = f"data:image/png;base64,{img_base64}"
    return data_url


# Sample E-Commerce Object
sample_object = {
    "product_title": "Nike Men's Low-Top Sneaker",
    "product_description": "Braided and synthetic fabric on the upper provides a lightweight fit and airy feel Foam midsole is soft and comfortable Elastic inner sleeve and booty-like structure create a custom fitRubber on the sole adds traction and durability",
    "brand_name": "Nike",
    "image_assets": [
        "some_url",
        "some_url",
        "some_url",
    ],
}

# Process all the images into base64 representation
base_64_img_arr = []
for url in sample_object["image_assets"]:
    processed_image = image_to_base64_data_url(url)
    base_64_img_arr.append(processed_image)


embed_input = [
    {
        "content": [
            {"type": "text", "text": sample_object["product_title"]},
            {
                "type": "text",
                "text": sample_object["product_description"],
            },
            {"type": "text", "text": sample_object["brand_name"]},
        ]
        + [{"type": "image", "image": img} for img in base_64_img_arr]
    }
]


ret = co.embed(
    inputs=embed_input,
    model="embed-v4.0",
    embedding_types=["float"],
    input_type="search_document",
    output_dimensions=1024,
)

ret.embeddings.float
```

## Compression Levels

The Cohere embeddings platform supports compression. The Embed API features an `embeddings_types` parameter which allows the user to specify various ways of compressing the output.  

The following embedding types are supported: 

- `float`
- `int8`
- `unint8`
- `binary`
- `ubinary`

The parameter defaults to `float`, so if you pass in no argument you'll get back `float` embeddings:

```python PYTHON
ret = co.embed(texts=phrases, model=model, input_type=input_type)

ret.embeddings  # This contains the float embeddings
```

However we recommend being explicit about the `embedding type(s)`. To specify an embedding types, pass one of the types from the list above in as list containing a string:

```python PYTHON
ret = co.embed(
    texts=phrases,
    model=model,
    input_type=input_type,
    embedding_types=["int8"],
)

ret.embeddings.int8  # This contains your int8 embeddings
ret.embeddings.float  # This will be empty
ret.embeddings.uint8  # This will be empty
ret.embeddings.ubinary  # This will be empty
ret.embeddings.binary  # This will be empty
```

Finally, you can also pass several `embedding types` in as a list, in which case the endpoint will return a dictionary with both types available:

```python PYTHON
ret = co.embed(
    texts=phrases,
    model=model,
    input_type=input_type,
    embedding_types=["int8", "float"],
)

ret.embeddings.int8  # This contains your int8 embeddings
ret.embeddings.float  # This contains your float embeddings
ret.embeddings.uint8  # This will be empty
ret.embeddings.ubinary  # This will be empty
ret.embeddings.binary  # This will be empty
```

---
title: Elasticsearch and Cohere
slug: docs/elasticsearch-and-cohere
hidden: false
description: >-
  Learn how to create a semantic search pipeline with Elasticsearch and Cohere's
  generative AI capabilities.
image: ../../../assets/images/f1cc130-cohere_meta_image.jpg
keywords: 'Cohere integrations, Elasticsearch'
createdAt: 'Sun Apr 07 2024 20:15:08 GMT+0000 (Coordinated Universal Time)'
updatedAt: 'Thu May 30 2024 15:56:35 GMT+0000 (Coordinated Universal Time)'
---

<img src="../../../assets/images/17b17dc-elastic-search-logo.png" width="200px" height="auto" class="light-bg" />

[Elasticsearch](https://www.elastic.co/search-labs/blog/elasticsearch-cohere-embeddings-support) has all the tools developers need to build next generation search experiences with generative AI, and it supports native integration with [Cohere](https://www.elastic.co/search-labs/blog/elasticsearch-cohere-embeddings-support) through their [inference API](https://www.elastic.co/guide/en/elasticsearch/reference/master/semantic-search-inference.html).

Use Elastic if you‚Äôd like to build with:

- A vector database
- Deploy multiple ML models
- Perform text, vector and hybrid search
- Search with filters, facet, aggregations
- Apply document and field level security
- Run on-prem, cloud, or serverless (preview)

This guide uses a dataset of Wikipedia articles to set up a pipeline for semantic search. It will cover:

- Creating an Elastic inference processor using Cohere embeddings
- Creating an Elasticsearch index with embeddings
- Performing hybrid search on the Elasticsearch index and reranking results
- Performing basic RAG

To see the full code sample, refer to this [notebook](https://github.com/cohere-ai/notebooks/blob/main/notebooks/Cohere_Elastic_Guide.ipynb).

<a
  className="rounded-4xl group flex h-fit items-center justify-center whitespace-nowrap transition ease-in-out py-3 px-6 disabled:cursor-not-allowed bg-primary-neutral border border-primary-neutral hover:bg-primary-light hover:text-primary-dark hover:border-primary-light active:bg-primary-neutral active:text-white active:border-primary-neutral disabled:bg-gray-80 disabled:text-gray-30 disabled:border-gray-80 focus:outline-none focus:ring-offset-2 focus:ring focus:ring-black w-100-to-75-to-50 mt-6"
  href="https://www.elastic.co/search-labs/integrations/cohere"
  target="_self"
>
  <span className="text-sm lg:text-base">Learn More</span>
</a>

## Prerequisites

This tutorial assumes you have the following:

- An Elastic Cloud account through [Elastic Cloud](https://www.elastic.co/guide/en/cloud/current/ec-getting-started.html), available with a [free trial](https://cloud.elastic.co/registration?utm_source=github&utm_content=elasticsearch-labs-notebook)
- A Cohere production API Key. Get your API Key at this [link](https://dashboard.cohere.com/welcome/login?redirect_uri=%2Fapi-keys) if you don't have one
- Python 3.7 or higher

Note: While this tutorial integrates Cohere with an Elastic Cloud [serverless](https://docs.elastic.co/serverless/elasticsearch/get-started) project, you can also integrate with your self-managed Elasticsearch deployment or Elastic Cloud deployment by simply switching from the [serverless](https://docs.elastic.co/serverless/elasticsearch/clients) to the general [language client](https://www.elastic.co/guide/en/elasticsearch/client/index.html).

## Create an Elastic Serverless deployment

If you don't have an Elastic Cloud deployment, sign up [here](https://www.google.com/url?q=https%3A%2F%2Fcloud.elastic.co%2Fregistration%3Futm_source%3Dgithub%26utm_content%3Delasticsearch-labs-notebook) for a free trial and request access to Elastic Serverless

## Install the required packages

Install and import the required Python Packages:

- `elasticsearch_serverless`
- `cohere`: ensure you are on version 5.2.5 or later

To install the packages, use the following code

```python PYTHON
!pip install elasticsearch_serverless==0.2.0.20231031
!pip install cohere==5.2.5
```

After the instalation has finished, find your endpoint URL and create your API key in the Serverless dashboard.

## Import the required packages

Next, we need to import the modules we need. üîê NOTE: getpass enables us to securely prompt the user for credentials without echoing them to the terminal, or storing it in memory.

```python PYTHON
from elasticsearch_serverless import Elasticsearch, helpers
from getpass import getpass
import cohere
import json
import requests
```

## Create an Elasticsearch client

Now we can instantiate the Python Elasticsearch client.

First we prompt the user for their endpoint and encoded API key. Then we create a client object that instantiates an instance of the Elasticsearch class.

When creating your Elastic Serverless API key make sure to turn on Control security privileges, and edit cluster privileges to specify `"cluster": ["all"]`.

```python PYTHON
ELASTICSEARCH_ENDPOINT = getpass("Elastic Endpoint: ")
ELASTIC_API_KEY = getpass("Elastic encoded API key: ") # Use the encoded API key

client = Elasticsearch(
  ELASTICSEARCH_ENDPOINT,
  api_key=ELASTIC_API_KEY
)

# Confirm the client has connected
print(client.info())
```

# Build a Hybrid Search Index with Cohere and Elasticsearch

## Create an inference endpoint

One of the biggest pain points of building a vector search index is computing embeddings for a large corpus of data. Fortunately Elastic offers inference endpoints that can be used in ingest pipelines to automatically compute embeddings when bulk indexing operations are performed.

To set up an inference pipeline for ingestion we first must create an inference endpoint that uses Cohere embeddings. You'll need a Cohere API key for this that you can find in your Cohere account under the [API keys section](https://dashboard.cohere.com/api-keys).

We will create an inference endpoint that uses `embed-english-v3.0` and `int8` or `byte` compression to save on storage.

```python PYTHON
COHERE_API_KEY = getpass("Enter Cohere API key:  ")
# Delete the inference model if it already exists
client.options(ignore_status=[404]).inference.delete(inference_id="cohere_embeddings")

client.inference.put(
    task_type="text_embedding",
    inference_id="cohere_embeddings",
    body={
        "service": "cohere",
        "service_settings": {
            "api_key": COHERE_API_KEY,
            "model_id": "embed-english-v3.0",
            "embedding_type": "int8",
            "similarity": "cosine"
        },
        "task_settings": {},
    },
)
```

Here's what you might see:

```
Enter Cohere API key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑
ObjectApiResponse({'model_id': 'cohere_embeddings', 'inference_id': 'cohere_embeddings', 'task_type': 'text_embedding', 'service': 'cohere', 'service_settings': {'similarity': 'cosine', 'dimensions': 1024, 'model_id': 'embed-english-v3.0', 'rate_limit': {'requests_per_minute': 10000}, 'embedding_type': 'byte'}, 'task_settings': {}})
```

## Create the Index

The mapping of the destination index ‚Äì the index that contains the embeddings that the model will generate based on your input text ‚Äì must be created. The destination index must have a field with the [`semantic_text`](https://www.google.com/url?q=https%3A%2F%2Fwww.elastic.co%2Fguide%2Fen%2Felasticsearch%2Freference%2Fcurrent%2Fsemantic-text.html) field type to index the output of the Cohere model.

Let's create an index named cohere-wiki-embeddings with the mappings we need

```python PYTHON
client.indices.delete(index="cohere-wiki-embeddings", ignore_unavailable=True)
client.indices.create(
    index="cohere-wiki-embeddings",
    mappings={
        "properties": {
            "text_semantic": {
                "type": "semantic_text",
                "inference_id": "cohere_embeddings"
            },
            "text": {"type": "text", "copy_to": "text_semantic"},
            "wiki_id": {"type": "integer"},
            "url": {"type": "text"},
            "views": {"type": "float"},
            "langs": {"type": "integer"},
            "title": {"type": "text"},
            "paragraph_id": {"type": "integer"},
            "id": {"type": "integer"}
        }
    },
)
```

You might see something like this:

```
ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'cohere-wiki-embeddings'})
```

Let's note a few important parameters from that API call:

- `semantic_text`: A field type automatically generates embeddings for text content using an inference endpoint.
- `inference_id`: Specifies the ID of the inference endpoint to be used. In this example, the model ID is set to cohere_embeddings.
- `copy_to`: Specifies the output field which contains inference results

## Insert Documents

Let's insert our example wiki dataset. You need a production Cohere account to complete this step, otherwise the documentation ingest will time out due to the API request rate limits.

```python PYTHON
url = "https://raw.githubusercontent.com/cohere-ai/notebooks/main/notebooks/data/embed_jobs_sample_data.jsonl"
response = requests.get(url)

# Load the response data into a JSON object
jsonl_data = response.content.decode('utf-8').splitlines()

# Prepare the documents to be indexed
documents = []
for line in jsonl_data:
    data_dict = json.loads(line)
    documents.append({
        "_index": "cohere-wiki-embeddings",
        "_source": data_dict,
        }
      )

# Use the bulk endpoint to index
helpers.bulk(client, documents)

print("Done indexing documents into `cohere-wiki-embeddings` index!")
```

You should see this:

```
Done indexing documents into `cohere-wiki-embeddings` index!
```

## Semantic Search
After the dataset has been enriched with the embeddings, you can query the data using the semantic query provided by Elasticsearch. `semantic_text` in Elasticsearch simplifies the semantic search significantly. Learn more about how [semantic text](https://www.google.com/url?q=https%3A%2F%2Fwww.elastic.co%2Fsearch-labs%2Fblog%2Fsemantic-search-simplified-semantic-text) in Elasticsearch allows you to focus on your model and results instead of on the technical details.

```python PYTHON 
query = "When were the semi-finals of the 2022 FIFA world cup played?"

response = client.search(
    index="cohere-wiki-embeddings",
    size=100,
    query = {
        "semantic": {
                    "query": "When were the semi-finals of the 2022 FIFA world cup played?",
                     "field": "text_semantic"
        }
    }
)

raw_documents = response["hits"]["hits"]

# Display the first 10 results
for document in raw_documents[0:10]:
  print(f'Title: {document["_source"]["title"]}\nText: {document["_source"]["text"]}\n')

# Format the documents for ranking
documents = []
for hit in response["hits"]["hits"]:
    documents.append(hit["_source"]["text"])
```

Here's what that might look like:
```
Title: 2022 FIFA World Cup
Text: The 2022 FIFA World Cup was an international football tournament contested by the men's national teams of FIFA's member associations and 22nd edition of the FIFA World Cup. It took place in Qatar from 20 November to 18 December 2022, making it the first World Cup held in the Arab world and Muslim world, and the second held entirely in Asia after the 2002 tournament in South Korea and Japan. France were the defending champions, having defeated Croatia 4‚Äì2 in the 2018 final. At an estimated cost of over $220 billion, it is the most expensive World Cup ever held to date; this figure is disputed by Qatari officials, including organising CEO Nasser Al Khater, who said the true cost was $8 billion, and other figures related to overall infrastructure development since the World Cup was awarded to Qatar in 2010.

Title: 2022 FIFA World Cup
Text: The semi-finals were played on 13 and 14 December. Messi scored a penalty kick before Juli√°n √Ålvarez scored twice to give Argentina a 3‚Äì0 victory over Croatia. Th√©o Hernandez scored after five minutes as France led Morocco for most of the game and later Randal Kolo Muani scored on 78 minutes to complete a 2‚Äì0 victory for France over Morocco as they reached a second consecutive final.

Title: 2022 FIFA World Cup
Text: The quarter-finals were played on 9 and 10 December. Croatia and Brazil ended 0‚Äì0 after 90 minutes and went to extra time. Neymar scored for Brazil in the 15th minute of extra time. Croatia, however, equalised through Bruno Petkoviƒá in the second period of extra time. With the match tied, a penalty shootout decided the contest, with Croatia winning the shoot-out 4‚Äì2. In the second quarter-final match, Nahuel Molina and Messi scored for Argentina before Wout Weghorst equalised with two goals shortly before the end of the game. The match went to extra time and then penalties, where Argentina would go on to win 4‚Äì3. Morocco defeated Portugal 1‚Äì0, with Youssef En-Nesyri scoring at the end of the first half. Morocco became the first African and the first Arab nation to advance as far as the semi-finals of the competition. Despite Harry Kane scoring a penalty for England, it was not enough to beat France, who won 2‚Äì1 by virtue of goals from Aur√©lien Tchouam√©ni and Olivier Giroud, sending them to their second consecutive World Cup semi-final and becoming the first defending champions to reach this stage since Brazil in 1998.

Title: 2022 FIFA World Cup
Text: Unlike previous FIFA World Cups, which are typically played in June and July, because of Qatar's intense summer heat and often fairly high humidity, the 2022 World Cup was played in November and December. As a result, the World Cup was unusually staged in the middle of the seasons of domestic association football leagues, which started in late July or August, including all of the major European leagues, which had been obliged to incorporate extended breaks into their domestic schedules to accommodate the World Cup. Major European competitions had scheduled their respective competitions group matches to be played before the World Cup, to avoid playing group matches the following year.

Title: 2022 FIFA World Cup
Text: The match schedule was confirmed by FIFA in July 2020. The group stage was set to begin on 21 November, with four matches every day. Later, the schedule was tweaked by moving the Qatar vs Ecuador game to 20 November, after Qatar lobbied FIFA to allow their team to open the tournament. The final was played on 18 December 2022, National Day, at Lusail Stadium.

Title: 2022 FIFA World Cup
Text: Owing to the climate in Qatar, concerns were expressed over holding the World Cup in its traditional time frame of June and July. In October 2013, a task force was commissioned to consider alternative dates and report after the 2014 FIFA World Cup in Brazil. On 24 February 2015, the FIFA Task Force proposed that the tournament be played from late November to late December 2022, to avoid the summer heat between May and September and also avoid clashing with the 2022 Winter Olympics in February, the 2022 Winter Paralympics in March and Ramadan in April.

Title: 2022 FIFA World Cup
Text: Of the 32 nations qualified to play at the 2022 FIFA World Cup, 24 countries competed at the previous tournament in 2018. Qatar were the only team making their debut in the FIFA World Cup, becoming the first hosts to make their tournament debut since Italy in 1934. As a result, the 2022 tournament was the first World Cup in which none of the teams that earned a spot through qualification were making their debut. The Netherlands, Ecuador, Ghana, Cameroon, and the United States returned to the tournament after missing the 2018 tournament. Canada returned after 36 years, their only prior appearance being in 1986. Wales made their first appearance in 64 years ‚Äì the longest ever gap for any team, their only previous participation having been in 1958.

Title: 2022 FIFA World Cup
Text: After UEFA were guaranteed to host the 2018 event, members of UEFA were no longer in contention to host in 2022. There were five bids remaining for the 2022 FIFA World Cup: Australia, Japan, Qatar, South Korea, and the United States.

Title: Cristiano Ronaldo
Text: Ronaldo was named in Portugal's squad for the 2022 FIFA World Cup in Qatar, making it his fifth World Cup. On 24 November, in Portugal's opening match against Ghana, Ronaldo scored a penalty kick and became the first male player to score in five different World Cups. In the last group game against South Korea, Ronaldo received criticism from his own coach for his reaction at being substituted. He was dropped from the starting line-up for Portugal's last 16 match against Switzerland, marking the first time since Euro 2008 that he had not started a game for Portugal in a major international tournament, and the first time Portugal had started a knockout game without Ronaldo in the starting line-up at an international tournament since Euro 2000. He came off the bench late on as Portugal won 6‚Äì1, their highest tally in a World Cup knockout game since the 1966 World Cup, with Ronaldo's replacement Gon√ßalo Ramos scoring a hat-trick. Portugal employed the same strategy in the quarter-finals against Morocco, with Ronaldo once again coming off the bench; in the process, he equalled Bader Al-Mutawa's international appearance record, becoming the joint‚Äìmost capped male footballer of all time, with 196 caps. Portugal lost 1‚Äì0, however, with Morocco becoming the first CAF nation ever to reach the World Cup semi-finals.

Title: 2022 FIFA World Cup
Text: The final draw was held at the Doha Exhibition and Convention Center in Doha, Qatar, on 1 April 2022, 19:00 AST, prior to the completion of qualification. The two winners of the inter-confederation play-offs and the winner of the Path A of the UEFA play-offs were not known at the time of the draw. The draw was attended by 2,000 guests and was led by Carli Lloyd, Jermaine Jenas and sports broadcaster Samantha Johnson, assisted by the likes of Cafu (Brazil), Lothar Matth√§us (Germany), Adel Ahmed Malalla (Qatar), Ali Daei (Iran), Bora Milutinoviƒá (Serbia/Mexico), Jay-Jay Okocha (Nigeria), Rabah Madjer (Algeria), and Tim Cahill (Australia).
```

## Hybrid Search 
After the dataset has been enriched with the embeddings, you can query the data using hybrid search.

Pass a semantic query, and provide the query text and the model you have used to create the embeddings.

```python PYTHON 
query = "When were the semi-finals of the 2022 FIFA world cup played?"

response = client.search(
    index="cohere-wiki-embeddings",
    size=100,
    query={
        "bool": {
            "must": {
                "multi_match": {
                "query": "When were the semi-finals of the 2022 FIFA world cup played?",
                "fields": ["text", "title"]
        }
            },
            "should": {
                "semantic": {
                    "query": "When were the semi-finals of the 2022 FIFA world cup played?",
                     "field": "text_semantic"
                }
            },
        }
    }

)

raw_documents = response["hits"]["hits"]

# Display the first 10 results
for document in raw_documents[0:10]:
  print(f'Title: {document["_source"]["title"]}\nText: {document["_source"]["text"]}\n')

# Format the documents for ranking
documents = []
for hit in response["hits"]["hits"]:
    documents.append(hit["_source"]["text"])
```

## Ranking 

In order to effectively combine the results from our vector and BM25 retrieval, we can use Cohere's Rerank 3 model through the inference API to provide a final, more precise, semantic reranking of our results.

First, create an inference endpoint with your Cohere API key. Make sure to specify a name for your endpoint, and the model_id of one of the rerank models. In this example we will use Rerank 3.

```python PYTHON 
# Delete the inference model if it already exists
client.options(ignore_status=[404]).inference.delete(inference_id="cohere_rerank")

client.inference.put(
    task_type="rerank",
    inference_id="cohere_rerank",
    body={
        "service": "cohere",
        "service_settings":{
            "api_key": COHERE_API_KEY,
            "model_id": "rerank-english-v3.0"
           },
        "task_settings": {
            "top_n": 10,
        },
    }
)
```

You can now rerank your results using that inference endpoint. Here we will pass in the query we used for retrieval, along with the documents we just retrieved using hybrid search.

The inference service will respond with a list of documents in descending order of relevance. Each document has a corresponding index (reflecting to the order the documents were in when sent to the inference endpoint), and if the ‚Äúreturn_documents‚Äù task setting is True, then the document texts will be included as well.

In this case we will set the response to False and will reconstruct the input documents based on the index returned in the response.

```python PYTHON 
response = client.inference.inference(
    inference_id="cohere_rerank",
    body={
        "query": query,
        "input": documents,
        "task_settings": {
            "return_documents": False
            }
        }
)

# Reconstruct the input documents based on the index provided in the rereank response
ranked_documents = []
for document in response.body["rerank"]:
  ranked_documents.append({
      "title": raw_documents[int(document["index"])]["_source"]["title"],
      "text": raw_documents[int(document["index"])]["_source"]["text"]
  })

# Print the top 10 results
for document in ranked_documents[0:10]:
  print(f"Title: {document['title']}\nText: {document['text']}\n")
```

## Retrieval augemented generation

Now that we have ranked our results, we can easily turn this into a RAG system with Cohere's Chat API. Pass in the retrieved documents, along with the query and see the grounded response using Cohere's newest generative model Command R+.

First, we will create the Cohere client.

```python PYTHON 
co = cohere.Client(COHERE_API_KEY)
```

Next, we can easily get a grounded generation with citations from the Cohere Chat API. We simply pass in the user query and documents retrieved from Elastic to the API, and print out our grounded response.

```python PYTHON
response = co.chat(
    message=query,
    documents=ranked_documents,
    model='command-r-plus-08-2024'
)

source_documents = []
for citation in response.citations:
  for document_id in citation.document_ids:
    if document_id not in source_documents:
      source_documents.append(document_id)

print(f"Query: {query}")
print(f"Response: {response.text}")
print("Sources:")
for document in response.documents:
  if document['id'] in source_documents:
    print(f"{document['title']}: {document['text']}")
```

And there you have it! A quick and easy implementation of hybrid search and RAG with Cohere and Elastic.

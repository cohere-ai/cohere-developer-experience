---
title: Cohere Embed on LangChain (Integration Guide)
slug: "docs/embed-on-langchain"

hidden: false

description: "This page describes how to work with Cohere's embeddings models and LangChain."
image: "../../../assets/images/f1cc130-cohere_meta_image.jpg"  
keywords: "Cohere, vector embedding model"

createdAt: "Fri Mar 01 2024 16:19:22 GMT+0000 (Coordinated Universal Time)"
updatedAt: "Thu May 30 2024 15:58:05 GMT+0000 (Coordinated Universal Time)"
---
Cohere supports various integrations with LangChain, a large language model (LLM) framework which allows you to quickly create applications based on Cohere's models. This doc will guide you through how to leverage different Cohere embeddings with LangChain. 

### Prerequisites

Running Cohere embeddings with LangChain doesn't require many prerequisites, consult the [top-level document](/docs/cohere-and-langchain) for more information.

### Cohere Embeddings with LangChain

To use [Cohere's Embeddings](/docs/embeddings) with LangChain, create a [CohereEmbedding](https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/embeddings/cohere.py) object as follows (the available cohere embedding models [are listed here](/reference/embed)): 

```python PYTHON
from langchain_cohere import CohereEmbeddings

# Define the Cohere embedding model
embeddings = CohereEmbeddings(cohere_api_key="COHERE_API_KEY",
                              model="embed-english-v3.0")

# Embed a document
text = "This is a test document."
query_result = embeddings.embed_query(text)
print(query_result[:5], "...")
doc_result = embeddings.embed_documents([text])
print(doc_result[0][:5], "...")

```

To use these embeddings with Cohere's RAG functionality, you will need to use one of the vector DBs [from this list](https://python.langchain.com/docs/integrations/vectorstores). In this example we use chroma, so in order to run it you will need to install chroma using `pip install chromadb`.

```python PYTHON
from langchain_cohere import ChatCohere, CohereEmbeddings, CohereRerank, CohereRagRetriever
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import WebBaseLoader

user_query =  "what is Cohere Toolkit?"

llm = ChatCohere(cohere_api_key="COHERE_API_KEY",              
                 model="command-r-plus-08-2024",
                 temperature=0)

embeddings = CohereEmbeddings(cohere_api_key="COHERE_API_KEY",
                              model="embed-english-v3.0")

# Load text files and split into chunks, you can also use data gathered elsewhere in your application
raw_documents = WebBaseLoader("https://docs.cohere.com/docs/cohere-toolkit").load()

text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)
documents = text_splitter.split_documents(raw_documents)
# Create a vector store from the documents
db = Chroma.from_documents(documents, embeddings)
input_docs = db.as_retriever().invoke(user_query)

# Create the cohere rag retriever using the chat model 
rag = CohereRagRetriever(llm=llm)
docs = rag.invoke(
    user_query,
    documents=input_docs,
)
# Print the documents
print("Documents:")
for doc in docs[:-1]:
    print(doc.metadata)
    print("\n\n" + doc.page_content)
    print("\n\n" + "-" * 30 + "\n\n")
# Print the final generation 
answer = docs[-1].page_content
print("Answer:")
print(answer)
# Print the final citations 
citations = docs[-1].metadata['citations']
print("Citations:")
print(citations)
```

### Cohere with LangChain and Bedrock

#### Prerequisite

In addition to the prerequisites above, integrating Cohere with LangChain on Amazon Bedrock also requires: 

- The LangChain AWS package. To install it, run `pip install langchain-aws`.
- AWS Python SDK. To install it, run `pip install boto3`. You can find [more details here ](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html#install-boto3).
- Configured authentication credentials for AWS. For more details, [see this document](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html#configuration). 

#### Cohere Embeddings with LangChain and Amazon Bedrock

In this example, we create embeddings for a query using Bedrock and LangChain: 

```python PYTHON
from langchain_aws import BedrockEmbeddings

# Replace the profile name with the one created in the setup.
embeddings = BedrockEmbeddings(
    credentials_profile_name="{PROFILE-NAME}",
    region_name="us-east-1",
    model_id="cohere.embed-english-v3"
)

embeddings.embed_query("This is a content of the document")
```
### Using LangChain on Private Deployments

You can use LangChain with privately deployed Cohere models. To use it, specify your model deployment URL in the `base_url` parameter.

```python PYTHON
llm = CohereEmbeddings(base_url=<YOUR_DEPLOYMENT_URL>,
                 cohere_api_key="COHERE_API_KEY",              
                 model="MODEL_NAME")
```
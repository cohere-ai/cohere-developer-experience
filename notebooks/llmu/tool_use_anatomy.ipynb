{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Use Anatomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/cohere-ai/notebooks/blob/main/notebooks/llmu/tool_use_anatomy.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read the accompanying [article here](https://cohere.ai/blog/tool-use-anatomy/).*\n",
    "\n",
    "In this notebook, we’ll dissect the key components of a tool use system and what a tool use workflow looks like. And we’ll do that with a concrete code example.\n",
    "\n",
    "We’ll look at a use case of a RAG assistant that can query the sales database of an e-commerce company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let’s install the Cohere Python SDK and set up the Cohere client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install cohere -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client(\"COHERE_API_KEY\") # Get your API key: https://dashboard.cohere.com/api-keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool use setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-requisite, or Step 0, before we can run a tool use workflow, is to set up the tools. We can break this further into two steps:\n",
    "- Creating the tool\n",
    "- Defining the tool schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create a function to query a sales database called daily_sales_report and represent it as a tool. For simplicity, it contains a mock database containing just three data entries and the logic to return the data given a user query.\n",
    "\n",
    "In this example, we are defining a Python function as the tool. But more broadly, the tool can be any function or service that can receive and send data. It could be an email service, an SQL database, a vector database, a weather data service, a sports data service, a web search engine, or even another LLM, just to give a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_sales_report(day: str) -> dict:\n",
    "    \"\"\"\n",
    "    Function to retrieve the sales report for the given day\n",
    "    \"\"\"\n",
    "    # Mock database containing daily sales reports\n",
    "    sales_database = {\n",
    "    '2023-09-28': {'total_sales_amount': 5000,'total_units_sold': 100},\n",
    "    '2023-09-29': {'total_sales_amount': 10000,'total_units_sold': 250},\n",
    "    '2023-09-30': {'total_sales_amount': 8000,'total_units_sold': 200}\n",
    "    }\n",
    "    \n",
    "    report = sales_database.get(day, {})\n",
    "    \n",
    "    if report:\n",
    "        return {\n",
    "            'date': day,\n",
    "            'summary': f\"Total Sales Amount: {report['total_sales_amount']}, Total Units Sold: {report['total_units_sold']}\"\n",
    "        }\n",
    "    else:\n",
    "        return {'date': day, 'summary': 'No sales data available for this day.'}\n",
    "    \n",
    "\n",
    "functions_map = {\n",
    "    \"daily_sales_report\": daily_sales_report\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define tool schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the tool schema for the sales database tool. This schema is what will be passed to the Cohere API when running a tool use workflow.\n",
    "\n",
    "This schema informs the LLM about what the tool does, and the LLM decides whether to use a particular tool based on it. Therefore, the more descriptive and specific the schema, the more likely the LLM will make the right tool call decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"daily_sales_report\",\n",
    "        \"description\": \"Connects to a database to retrieve overall sales volumes and sales information for a given day.\",\n",
    "        \"parameter_definitions\": {\n",
    "            \"day\": {\n",
    "                \"description\": \"Retrieves sales data for this day, formatted as YYYY-MM-DD.\",\n",
    "                \"type\": \"str\",\n",
    "                \"required\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the preamble (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optional step is to add a custom preamble, which is the LLM’s system message.\n",
    "\n",
    "The recommended approach is to use two H2 Markdown headers: \"Task & Context\" and \"Style Guide\" in the exact order.\n",
    "\n",
    "It’s a completely optional step, though it’s likely needed if we want to create a robust and reliable application. Also note that the preamble is not related to the tool setup that we covered earlier, rather it’s part of the instruction to the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preamble = \"\"\"## Task & Context\n",
    "You help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.\n",
    "\n",
    "## Style Guide\n",
    "Unless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool use workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool is now ready to use. We can think of a tool use system as consisting of four components:\n",
    "- The user\n",
    "- The application\n",
    "- The LLM\n",
    "- The tools\n",
    "\n",
    "At its most basic, these four components interact in a workflow through four steps:\n",
    "- Step 1: Get user message. The LLM gets the user message (via the application).\n",
    "- Step 2: Generate tool calls. The LLM makes a decision on the tools to call (if any) and generates the tool calls.\n",
    "- Step 3: Get tool results. The tools are executed by the application and the results are sent to the LLM.\n",
    "- Step 4: Generate response and citations. The LLM generates the response and citations to back to the user.\n",
    "\n",
    "Let’s walk through these four steps using a code example. In this first example, we’ll use the simplest possible scenario where:\n",
    "- There is only one tool (the sales database)\n",
    "- Tool calling happens only once (and only one tool is called)\n",
    "- There is only one turn in the conversation (no conversation memory preserved)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get user message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM gets the user message (via the application)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Can you provide a sales summary for 29th September 2023?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate tool calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM makes a decision on the tools to call (if any) and generates the tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool calls:\n",
      "\n",
      "#1\n",
      "Tool: daily_sales_report\n",
      "Parameters: {'day': '2023-09-29'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = \"command-r-plus\"\n",
    "\n",
    "# Initial response to the user message\n",
    "response = co.chat(\n",
    "    message=message,\n",
    "    model=model,\n",
    "    preamble=preamble,\n",
    "    tools=tools,\n",
    "    force_single_step=True\n",
    ")\n",
    "\n",
    "tool_calls = response.tool_calls\n",
    "    \n",
    "print(\"Tool calls:\\n\")\n",
    "for i, t in enumerate(tool_calls):\n",
    "    print(f\"#{i+1}\\nTool: {t.name}\\nParameters: {t.parameters}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get tool results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tools are executed by the application and the results are sent to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool results:\n",
      "\n",
      "#1\n",
      "Tool call: {'name': 'daily_sales_report', 'parameters': {'day': '2023-09-29'}}\n",
      "Outputs: [{'date': '2023-09-29', 'summary': 'Total Sales Amount: 10000, Total Units Sold: 250'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tool_results = []\n",
    "for tc in tool_calls:\n",
    "    tool_output = functions_map[tc.name](**tc.parameters)\n",
    "    tool_call = {\"name\": tc.name, \"parameters\": tc.parameters}\n",
    "    tool_results.append({\"call\": tool_call, \"outputs\": [tool_output]})\n",
    "    \n",
    "print(\"Tool results:\\n\")\n",
    "for i, t in enumerate(tool_results):\n",
    "    print(f\"#{i+1}\\nTool call: {t['call']}\\nOutputs: {t['outputs']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate response and citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM generates the response and citations to back to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final response:\n",
      "On 29 September 2023, we sold 250 units, totalling 10,000 in sales.\n",
      "==================================================\n",
      "\n",
      "Citations:\n",
      "start=30 end=39 text='250 units' document_ids=['daily_sales_report:0:2:0']\n",
      "start=51 end=66 text='10,000 in sales' document_ids=['daily_sales_report:0:2:0']\n",
      "\n",
      "Cited Documents:\n",
      "{'date': '2023-09-29', 'id': 'daily_sales_report:0:2:0', 'summary': 'Total Sales Amount: 10000, Total Units Sold: 250', 'tool_name': 'daily_sales_report'}\n"
     ]
    }
   ],
   "source": [
    "# Generate response\n",
    "response = co.chat(\n",
    "    message=\"\",\n",
    "    model=model,\n",
    "    preamble=preamble,\n",
    "    tools=tools,\n",
    "    tool_results=tool_results,\n",
    "    chat_history=response.chat_history\n",
    ")\n",
    "    \n",
    "print(\"Final response:\")\n",
    "print(response.text)\n",
    "print(\"=\"*50)\n",
    "\n",
    "if response.citations:\n",
    "    print(\"\\nCitations:\")\n",
    "    for citation in response.citations:\n",
    "        print(citation)\n",
    "    print(\"\\nCited Documents:\")\n",
    "    for document in response.documents:\n",
    "        print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat history:\n",
      "\n",
      "message='Can you provide a sales summary for 29th September 2023?' tool_calls=None role='USER'\n",
      "\n",
      "message=None tool_calls=[ToolCall(name='daily_sales_report', parameters={'day': '2023-09-29'})] role='CHATBOT'\n",
      "\n",
      "tool_results=[ToolResult(call=ToolCall(name='daily_sales_report', parameters={'day': '2023-09-29'}), outputs=[{'date': '2023-09-29', 'summary': 'Total Sales Amount: 10000, Total Units Sold: 250'}])] role='TOOL'\n",
      "\n",
      "message='On 29 September 2023, we sold 250 units, totalling 10,000 in sales.' tool_calls=None role='CHATBOT'\n"
     ]
    }
   ],
   "source": [
    "# Print chat history\n",
    "for turn in response.chat_history:\n",
    "    print(turn,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can stream the response from the Chat endpoint for each generated token instead of having to wait for the full response. To enable streaming, we need to change the endpoint call from `co.chat` to `co.chat_stream`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final response:\n",
      "\n",
      "On 29 September 2023, total sales amounted to 10,000, with 250 units sold.\n",
      "\n",
      "Citations:\n",
      "start=22 end=52 text='total sales amounted to 10,000' document_ids=['daily_sales_report:0:2:0', 'daily_sales_report:0:4:0']\n",
      "start=59 end=73 text='250 units sold' document_ids=['daily_sales_report:0:2:0', 'daily_sales_report:0:4:0']\n",
      "\n",
      "Cited Documents\n",
      "{'date': '2023-09-29', 'id': 'daily_sales_report:0:2:0', 'summary': 'Total Sales Amount: 10000, Total Units Sold: 250', 'tool_name': 'daily_sales_report'}\n",
      "{'date': '2023-09-29', 'id': 'daily_sales_report:0:4:0', 'summary': 'Total Sales Amount: 10000, Total Units Sold: 250', 'tool_name': 'daily_sales_report'}\n"
     ]
    }
   ],
   "source": [
    "# Generate response\n",
    "response = co.chat_stream(\n",
    "    message=\"\",\n",
    "    model=model,\n",
    "    preamble=preamble,\n",
    "    tools=tools,\n",
    "    tool_results=tool_results,\n",
    "    chat_history=response.chat_history\n",
    ")\n",
    "    \n",
    "print(\"Final response:\\n\")\n",
    "chatbot_response = \"\"\n",
    "\n",
    "for event in response:\n",
    "    if event.event_type == \"text-generation\":\n",
    "        print(event.text, end=\"\")\n",
    "        chatbot_response += event.text\n",
    "    if event.event_type == \"stream-end\":\n",
    "        if event.response.citations:\n",
    "            print(\"\\n\\nCitations:\")\n",
    "            for citation in event.response.citations:\n",
    "                print(citation)\n",
    "        if event.response.documents:\n",
    "            print(\"\\nCited Documents\")\n",
    "            for document in event.response.documents:\n",
    "                print(document)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

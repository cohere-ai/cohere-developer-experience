{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Purpose Agentic Assistant with RAG, Evaluation, Human Input, Web Search, and Python Tool\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Tool use enhances the capabilities of LLMs by enabling them to offload tasks that are ill-suited for next-token-prediction language modeling. Tools allow models to (indirectly) perform mathematical or other deterministic operations, run code, and search a wide array of data sources. In this notebook, we demonstrate that Cohere's Command model can be used to extend this paradigm, to encompass diverse use cases that rely on information retrieval, programming, and human input.\n",
    "\n",
    "In an enterprise setting, information is often distributed across a wide range of knowledge bases - for instance: cloud-based document repositories such as Notion, Jira, Google Drive, or Microsoft SharePoint; chat logs from Slack, Microsoft Teams and others; or meeting transcripts and internal documents. By building out bespoke tools for each knowledge base, we allow the agent to access whatever sources of information are needed for a use case.\n",
    "\n",
    "Given these results, we can then allow the agent to determine if the information retrieved is sufficient to answer the query, or if a web search is needed. Here, this is done via a modified version of the [correctness](https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/evaluation/correctness.py) evaluator template from LlamaIndex. If the score is low, the agent asks the user for permission to do a web search to find the answer.\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook will showcase how an agent can equip LLM with multiple tools like RAG and web search to become a useful assistant.\n",
    "\n",
    "## Questions\n",
    "\n",
    "- \"How much do we get for a referral?\" -> HR question\n",
    "- \"How do I set up api key for cohere?\" -> IT Question\n",
    "- \"Is cohere available on aws\" -> web search question\n",
    "- \"How much do I get a year on learning and development, and can you calculate how much I can spend per week?\" --> HR question + Calculation\n",
    "\n",
    "## Data\n",
    "\n",
    "- Mock internal database of HR documents\n",
    "- Mock internal database of IT documents (such as API docs)\n",
    "\n",
    "## Tools\n",
    "\n",
    "- Python Interpreter\n",
    "- HR data retriever\n",
    "- IT data retriever\n",
    "- Web search tool with human permission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import cohere\n",
    "import pandas as pd\n",
    "\n",
    "from langchain.agents import Tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if you need to install the following packages\n",
    "# !pip install --quiet langchain langchain_experimental cohere --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohere version: 5.5.1\n",
      "langchain_core version: 0.2.0\n",
      "langchain_experimental version: 0.0.59\n"
     ]
    }
   ],
   "source": [
    "# versions\n",
    "import langchain\n",
    "import langchain_core\n",
    "import langchain_experimental\n",
    "print('cohere version:', cohere.__version__)\n",
    "print('langchain_core version:', langchain_core.__version__)\n",
    "print('langchain_experimental version:', langchain_experimental.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_API_KEY = os.environ.get(\"COHERE_API_KEY\")\n",
    "COHERE_MODEL = 'command-r-plus'\n",
    "co = cohere.Client(api_key=COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Here we define HR and IT related documents, which will be used as a mock database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated by LLM\n",
    "hr_documents = [\n",
    "    {\n",
    "        \"title\": \"Remote Work Policy\",\n",
    "        \"content\": \"We embrace a remote-friendly work environment, allowing employees to work remotely on a full-time or hybrid basis. However, employees should expect to come to the office once a quarter. Expectations for remote work include maintaining regular working hours, responding promptly to communications, and attending virtual meetings. We provide remote workers with the necessary equipment and reimburse expenses for setting up a home office. Virtual collaboration tools, such as video conferencing software and project management platforms, are utilized to ensure effective remote work experiences. In-person meetings and team-building activities are also organized periodically to foster connections.\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Global Mobility Program\",\n",
    "        \"content\": \"Employees have the opportunity to work in different countries through our Global Mobility Program. This policy outlines the process for international assignments, including permanent transfers, short-term projects, and rotational programs. We provide support with visa sponsorship, relocation assistance, and cultural integration. Compensation packages are adjusted to align with the host country's market rates, and employees are offered pre-assignment training and ongoing support during their time abroad. Reassignment back to their home country or another location is also facilitated as part of this program. \",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Paid Time Off and Sick Days\",\n",
    "        \"content\": \"We offer a competitive paid time off package, including vacation days, personal days, and sick leave. Employees are entitled to a set number of paid vacation days each year, which increases with tenure. Unlimited sick days are provided to ensure employees can take time off for their health and well-being. Additionally, we offer paid parental leave, bereavement leave, and volunteer time off. Our policy also outlines procedures for requesting and tracking time off, as well as guidelines for managing unused days, carry-over limits, and payout options.\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Learning and Development Reimbursement\",\n",
    "        \"content\": \"Employees are eligible up to $9000 per year for learning and development. Investing in our employees' growth, we offer a learning and development reimbursement policy. Employees can seek reimbursement for work-related courses, certifications, conferences, and training programs. This includes tuition fees, course materials, and travel expenses associated with attending educational events.\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Employee Referral Program\",\n",
    "        \"content\": \"We value employee referrals and have implemented a referral bonus program. Employees who refer successful hires are eligible for a monetary bonus upon the referred candidate's start date. Our policy outlines the bonus amounts, eligibility criteria, and the referral process. We also offer incentives for referring diverse talent and provide employees with resources and guidance on effective referral strategies, including access to networking events and referral training. We offer $5000 for every successful referral.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# from https://github.com/cohere-ai/cohere-python/blob/main/README.md\n",
    "it_documents = [\n",
    "    {\n",
    "        \"title\": \"Cohere SDK Streaming\",\n",
    "        \"content\": \"\"\"The SDK supports streaming endpoints. To take advantage of this feature for chat,\n",
    "        use `chat_stream`.\n",
    "\n",
    "        ```Python\n",
    "        import cohere\n",
    "\n",
    "        co = cohere.Client(\n",
    "            api_key=\"YOUR_API_KEY\",\n",
    "        )\n",
    "\n",
    "        stream = co.chat_stream(\n",
    "            message=\"Tell me a short story\"\n",
    "        )\n",
    "\n",
    "        for event in stream:\n",
    "            if event.event_type == \"text-generation\":\n",
    "                print(event.text, end='')\n",
    "        ```\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Cohere SDK environment variable\",\n",
    "        \"content\": \"\"\"> [!TIP]\n",
    "        > You can set a system environment variable `CO_API_KEY` to avoid writing your api key within your code, e.g. add `export CO_API_KEY=theapikeyforyouraccount`\n",
    "        > in your ~/.zshrc or ~/.bashrc, open a new terminal, then code calling `cohere.Client()` will read this key.\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function helps us to convert IT and HR documents as a pandas dataframe with embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbify(db):\n",
    "    \"\"\"\n",
    "    Convert a list of dictionaries to a pandas DataFrame and add embeddings to be used as a mock database\n",
    "    \"\"\"\n",
    "    db = pd.DataFrame(db)\n",
    "    # comebine title and body\n",
    "    db[\"combined\"] = \"Title: \" + db[\"title\"] + \"\\n\" + \"Body: \" + db[\"content\"]\n",
    "    # generate embedding\n",
    "    embeddings = co.embed(\n",
    "        texts=db.combined.tolist(),\n",
    "        model=\"embed-english-v3.0\",\n",
    "        input_type=\"search_document\",\n",
    "    )\n",
    "    db[\"embeddings\"] = embeddings.embeddings\n",
    "    return db\n",
    "\n",
    "\n",
    "db_it = dbify(it_documents)\n",
    "db_hr = dbify(hr_documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Define tools that are used by the agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever tools\n",
    "\n",
    "Define tools related to retrieval:\n",
    "\n",
    "- evaluator: evaluates the quality of the retrieved document.\n",
    "- web_search: performs web search given query.\n",
    "- retrieve_documents: retrieves top matching documents from a database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(query, retrieved_documents):\n",
    "    criteria = \"\"\"\n",
    "    You are an expert evaluation system for a question answering chatbot.\n",
    "\n",
    "    You are given the following information:\n",
    "    - a user query, and\n",
    "    - a generated answer\n",
    "\n",
    "    Your job is to judge the relevance and correctness of the generated answer.\n",
    "    Output a single score that represents a holistic evaluation.\n",
    "    You must return your response in a line with only the score.\n",
    "    Do not return answers in any other format.\n",
    "\n",
    "    Follow these guidelines for scoring:\n",
    "    - Your score has to be between 1 and 5, where 1 is the worst and 5 is the best.\n",
    "    - If the generated answer is not relevant to the user query, \\\n",
    "    you should give a score of 1.\n",
    "    - If the generated answer is relevant but does not fully answer the question, \\\n",
    "    you should give a score between 2 and 3.\n",
    "    - If the generated answer is relevant and fully correct, \\\n",
    "    you should give a score between 4 and 5.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    ## User Query\n",
    "    {query}\n",
    "\n",
    "    ## Retrieved Documents\n",
    "    {retrieved_documents}\n",
    "\n",
    "    ## Criteria\n",
    "    {criteria}\n",
    "\n",
    "    ## Output format\n",
    "    Ouput a single score that represents a holistic evaluation.\n",
    "    \"\"\"\n",
    "    return co.chat(message=prompt, model=COHERE_MODEL, preamble=None).text\n",
    "\n",
    "\n",
    "def web_search(query):\n",
    "    \"\"\"\n",
    "    Function to search the web for a given query.\n",
    "    \"\"\"\n",
    "    question = \"I could not find relevant information in the database. Do you want me to search the web? \\nPlease enter 'y' or 'n':\"\n",
    "\n",
    "    while True:\n",
    "        response = input(question)\n",
    "        if response == \"y\":\n",
    "            print(\"You entered 'y'.\")\n",
    "            response = co.chat(\n",
    "                message=query,\n",
    "                connectors=[{\"id\": \"web-search\"}],\n",
    "            )\n",
    "            return {\"web_result\": response.text}\n",
    "        elif response == \"n\":\n",
    "            print(\"You entered 'n'.\")\n",
    "            return {\n",
    "                \"result\": \"User declined to search the web. Complete the conversation.\"\n",
    "            }\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'y' or 'n'.\")\n",
    "\n",
    "\n",
    "def retrieve_documents(query: str, db, n):\n",
    "    \"\"\"\n",
    "    Function to retrieve most relevant documents a given query.\n",
    "    \"\"\"\n",
    "\n",
    "    query_emb = co.embed(\n",
    "        texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
    "    )\n",
    "\n",
    "    similarity_scores = cosine_similarity(\n",
    "        [query_emb.embeddings[0]], db.embeddings.tolist()\n",
    "    )\n",
    "    similarity_scores = similarity_scores[0]\n",
    "\n",
    "    top_indices = similarity_scores.argsort()[::-1][:n]\n",
    "    top_matches = db.iloc[top_indices]\n",
    "\n",
    "    evaluator_score = float(evaluator(query, top_matches.combined.tolist()))\n",
    "\n",
    "    if evaluator_score >= 4:\n",
    "        status_message = \"Success: Retrieved documents are relevant and correct. Please answer user's question.\"\n",
    "    else:\n",
    "        status_message = (\n",
    "            \"Warning: Retrieved documents are not relevant, please search the web.\"\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"top_matched_document\": top_matches.combined,\n",
    "        \"evaluator_score\": evaluator_score,\n",
    "        \"status_message\": status_message,\n",
    "    }\n",
    "\n",
    "\n",
    "def retrieve_it_documents(query: str, db=db_it, n=2) -> dict:\n",
    "    \"\"\"\n",
    "    Function to retrieve most relevant documents a given query.\n",
    "    It also returns other references mentioned in the top matched documents.\n",
    "    \"\"\"\n",
    "    return retrieve_documents(query, db, n)\n",
    "\n",
    "\n",
    "def retrieve_hr_documents(query: str, db=db_hr, n=2) -> dict:\n",
    "    \"\"\"\n",
    "    Function to retrieve most relevant documents a given query.\n",
    "    It also returns other references mentioned in the top matched documents.\n",
    "    \"\"\"\n",
    "    return retrieve_documents(query, db, n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_repl = PythonREPL()\n",
    "python_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"Executes python code and returns the result. The code runs in a static sandbox without interactive mode, so print output or save output to a file.\",\n",
    "    func=python_repl.run,\n",
    ")\n",
    "python_tool.name = \"python_interpreter\"\n",
    "\n",
    "\n",
    "class ToolInput(BaseModel):\n",
    "    code: str = Field(description=\"Python code to execute.\")\n",
    "\n",
    "\n",
    "python_tool.args_schema = ToolInput\n",
    "\n",
    "\n",
    "def run_python_code(code: str) -> dict:\n",
    "    \"\"\"\n",
    "    Function to run given python code\n",
    "    \"\"\"\n",
    "    input_code = ToolInput(code=code)\n",
    "    return {\"python_answer\": python_tool.func(input_code.code)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions map\n",
    "\n",
    "Define mapping of functions and function definitions for the agent to refer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "functions_map = {\n",
    "    \"retrieve_it_documents\": retrieve_it_documents,\n",
    "    \"retrieve_hr_documents\": retrieve_hr_documents,\n",
    "    \"web_search\": web_search,\n",
    "        \"run_python_code\": run_python_code,\n",
    "\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"name\": \"retrieve_it_documents\",\n",
    "        \"description\": \"given a query, retrieve documents from a database to answer user's question related to IT\",\n",
    "        \"parameter_definitions\": {\n",
    "            \"query\": {\n",
    "                \"description\": \"user's question or query\",\n",
    "                \"type\": \"str\",\n",
    "                \"required\": True,\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"retrieve_hr_documents\",\n",
    "        \"description\": \"given a query, retrieve documents from a database to answer user's question related to HR.\",\n",
    "        \"parameter_definitions\": {\n",
    "            \"query\": {\n",
    "                \"description\": \"user's question or query\",\n",
    "                \"type\": \"str\",\n",
    "                \"required\": True,\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"web_search\",\n",
    "        \"description\": \"Search web to answer user's queston\",\n",
    "        \"parameter_definitions\": {\n",
    "            \"query\": {\n",
    "                \"description\": \"user's question or query\",\n",
    "                \"type\": \"str\",\n",
    "                \"required\": True,\n",
    "            }\n",
    "        },\n",
    "    },\n",
    " {\n",
    "        \"name\": \"run_python_code\",\n",
    "        \"description\": \"given a python code, runs it\",\n",
    "        \"parameter_definitions\": {\n",
    "            \"code\": {\n",
    "                \"description\": \"executable python code\",\n",
    "                \"type\": \"str\",\n",
    "                \"required\": True\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohere Agent\n",
    "\n",
    "Wrapper of Cohere API to handle multi step tool use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohere_agent(\n",
    "    message: str,\n",
    "    preamble: str,\n",
    "    tools: list[dict],\n",
    "    force_single_step=False,\n",
    "    verbose: bool = False,\n",
    "    temperature: float = 0.3,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Function to handle multi-step tool use api.\n",
    "\n",
    "    Args:\n",
    "        message (str): The message to send to the Cohere AI model.\n",
    "        preamble (str): The preamble or context for the conversation.\n",
    "        tools (list of dict): List of tools to use in the conversation.\n",
    "        verbose (bool, optional): Whether to print verbose output. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        str: The final response from the call.\n",
    "    \"\"\"\n",
    "\n",
    "    counter = 1\n",
    "\n",
    "    response = co.chat(\n",
    "        model=COHERE_MODEL,\n",
    "        message=message,\n",
    "        preamble=preamble,\n",
    "        tools=tools,\n",
    "        force_single_step=force_single_step,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nrunning step 0.\")\n",
    "        print(response.text)\n",
    "\n",
    "    while response.tool_calls:\n",
    "        tool_results = []\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nrunning step {counter}.\")\n",
    "\n",
    "        for tool_call in response.tool_calls:\n",
    "            if tool_call.parameters:\n",
    "                output = functions_map[tool_call.name](**tool_call.parameters)\n",
    "            else:\n",
    "                output = functions_map[tool_call.name]()\n",
    "\n",
    "            outputs = [output]\n",
    "            tool_results.append({\"call\": tool_call, \"outputs\": outputs})\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"= running tool {tool_call.name}, with parameters: \\n{tool_call.parameters}\"\n",
    "                )\n",
    "                print(f\"== tool results:\")\n",
    "                pprint(output)\n",
    "\n",
    "        response = co.chat(\n",
    "            model=COHERE_MODEL,\n",
    "            message=\"\",\n",
    "            chat_history=response.chat_history,\n",
    "            preamble=preamble,\n",
    "            tools=tools,\n",
    "            force_single_step=force_single_step,\n",
    "            tool_results=tool_results,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(response.text)\n",
    "            counter += 1\n",
    "\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "\n",
    "Preamble is a system level instruction that the agent follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preamble = \"\"\"\n",
    "You are helpful assitant for employees that has access to multiple databases such as HR and IT.\n",
    "Search relevant databases first. If you cannot find relevant information, search the web.\n",
    "You may need to use python to run some code or make calculations.\n",
    "\n",
    "Walk me through each step on what you are considering and going to do.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "List of questions to ask the agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions = [\n",
    "    \"how much do we get for a referral?\",\n",
    "    \"how do I set up api key for cohere?\",\n",
    "    \"Is cohere available on aws\",\n",
    "    \"how much do I get a year on learning and development. and can you calculate how much I can spend per week?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - \"how much do we get for a referral?\"\n",
    "\n",
    "This is an HR related question, so the agent decides to search the HR database for an answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running step 0.\n",
      "I will search the HR database for information about referral bonuses.\n",
      "\n",
      "running step 1.\n",
      "= running tool retrieve_hr_documents, with parameters: \n",
      "{'query': 'referral bonus'}\n",
      "== tool results:\n",
      "{'evaluator_score': 5.0,\n",
      " 'status_message': 'Success: Retrieved documents are relevant and correct. '\n",
      "                   \"Please answer user's question.\",\n",
      " 'top_matched_document': 4    Title: Employee Referral Program\\nBody: We val...\n",
      "3    Title: Learning and Development Reimbursement\\...\n",
      "Name: combined, dtype: object}\n",
      "Employees who refer successful hires are eligible for a $5000 bonus upon the referred candidate's start date.\n"
     ]
    }
   ],
   "source": [
    "output = cohere_agent(questions[0], preamble, tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 - \"how do I set up api key for cohere?\"\n",
    "\n",
    "This is an IR related question. So the agent decides to search the IR database to answer the question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running step 0.\n",
      "I will search the IT database for information on how to set up an API key for Cohere.\n",
      "\n",
      "running step 1.\n",
      "= running tool retrieve_it_documents, with parameters: \n",
      "{'query': 'how to set up api key for cohere'}\n",
      "== tool results:\n",
      "{'evaluator_score': 5.0,\n",
      " 'status_message': 'Success: Retrieved documents are relevant and correct. '\n",
      "                   \"Please answer user's question.\",\n",
      " 'top_matched_document': 1    Title: Cohere SDK environment variable\\nBody: ...\n",
      "0    Title: Cohere SDK Streaming\\nBody: The SDK sup...\n",
      "Name: combined, dtype: object}\n",
      "To set up an API key for Cohere, you can use the following code:\n",
      "```Python\n",
      "import cohere\n",
      "\n",
      "co = cohere.Client(\n",
      " api_key=\"YOUR_API_KEY\",\n",
      ")```\n"
     ]
    }
   ],
   "source": [
    "output = cohere_agent(questions[1], preamble, tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 - \"Is cohere available on aws\"\n",
    "\n",
    "This is an IT related question, but our database does not contain the correct information. Therefore, you see that evaluator_score is very low as the retrieved documents do not contain the information to answer user question. Thus, it tries to perform web search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running step 0.\n",
      "I will search the HR and IT databases for information on whether Cohere is available on AWS.\n",
      "\n",
      "running step 1.\n",
      "= running tool retrieve_it_documents, with parameters: \n",
      "{'query': 'Is cohere available on aws?'}\n",
      "== tool results:\n",
      "{'evaluator_score': 1.0,\n",
      " 'status_message': 'Warning: Retrieved documents are not relevant, please '\n",
      "                   'search the web.',\n",
      " 'top_matched_document': 0    Title: Cohere SDK Streaming\\nBody: The SDK sup...\n",
      "1    Title: Cohere SDK environment variable\\nBody: ...\n",
      "Name: combined, dtype: object}\n",
      "= running tool retrieve_hr_documents, with parameters: \n",
      "{'query': 'Is cohere available on aws?'}\n",
      "== tool results:\n",
      "{'evaluator_score': 1.0,\n",
      " 'status_message': 'Warning: Retrieved documents are not relevant, please '\n",
      "                   'search the web.',\n",
      " 'top_matched_document': 0    Title: Remote Work Policy\\nBody: We embrace a ...\n",
      "3    Title: Learning and Development Reimbursement\\...\n",
      "Name: combined, dtype: object}\n",
      "I could not find any relevant information in the HR and IT databases. I will now search the web to find out if Cohere is available on AWS.\n",
      "\n",
      "running step 2.\n",
      "You entered 'y'.\n",
      "= running tool web_search, with parameters: \n",
      "{'query': 'Is cohere available on aws?'}\n",
      "== tool results:\n",
      "{'web_result': 'Yes, Cohere is available on AWS. Developers can access a range '\n",
      "               'of Cohere language models in a private environment via '\n",
      "               \"Amazon's AWS Cloud platform. Cohere's models are supported on \"\n",
      "               'two Amazon services: Amazon SageMaker and Amazon Bedrock.'}\n",
      "Yes, Cohere is available on AWS. Developers can access a range of Cohere language models in a private environment via Amazon's AWS Cloud platform. Cohere's models are supported on two Amazon services: Amazon SageMaker and Amazon Bedrock.\n"
     ]
    }
   ],
   "source": [
    "# gives permission to search the web\n",
    "output = cohere_agent(questions[2], preamble, tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running step 0.\n",
      "I will search the databases to see if Cohere is available on AWS.\n",
      "\n",
      "running step 1.\n",
      "= running tool retrieve_it_documents, with parameters: \n",
      "{'query': 'Is cohere available on aws?'}\n",
      "== tool results:\n",
      "{'evaluator_score': 1.0,\n",
      " 'status_message': 'Warning: Retrieved documents are not relevant, please '\n",
      "                   'search the web.',\n",
      " 'top_matched_document': 0    Title: Cohere SDK Streaming\\nBody: The SDK sup...\n",
      "1    Title: Cohere SDK environment variable\\nBody: ...\n",
      "Name: combined, dtype: object}\n",
      "I couldn't find any relevant information in the databases. I will now search the web to see if Cohere is available on AWS.\n",
      "\n",
      "running step 2.\n",
      "You entered 'n'.\n",
      "= running tool web_search, with parameters: \n",
      "{'query': 'Is cohere available on aws?'}\n",
      "== tool results:\n",
      "{'result': 'User declined to search the web. Complete the conversation.'}\n",
      "I'm sorry, I can't answer this question.\n"
     ]
    }
   ],
   "source": [
    "# does not give permission to search the web\n",
    "output = cohere_agent(questions[2], preamble, tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 - \"how much do I get a year on learning and development. and can you calculate how much I can spend per week?\"\n",
    "\n",
    "This is an HR related question that requires a basic calculation to answer. The agent uses the Python tool to carry out the math.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running step 0.\n",
      "I will first search the HR database for information on how much the user gets a year on learning and development. Then, I will calculate how much they can spend per week.\n",
      "\n",
      "running step 1.\n",
      "= running tool retrieve_hr_documents, with parameters: \n",
      "{'query': 'how much do I get a year on learning and development'}\n",
      "== tool results:\n",
      "{'evaluator_score': 5.0,\n",
      " 'status_message': 'Success: Retrieved documents are relevant and correct. '\n",
      "                   \"Please answer user's question.\",\n",
      " 'top_matched_document': 3    Title: Learning and Development Reimbursement\\...\n",
      "4    Title: Employee Referral Program\\nBody: We val...\n",
      "Name: combined, dtype: object}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found that employees are eligible for up to $9000 per year for learning and development. Now, I will calculate how much they can spend per week.\n",
      "\n",
      "running step 2.\n",
      "= running tool run_python_code, with parameters: \n",
      "{'code': \"import math\\n\\n# Total amount per year\\ntotal_amount = 9000\\n\\n# Calculate weekly amount\\nweekly_amount = total_amount / 52\\n\\nprint(f'You can spend up to ${weekly_amount:.2f} per week on learning and development.')\"}\n",
      "== tool results:\n",
      "{'python_answer': 'You can spend up to $173.08 per week on learning and '\n",
      "                  'development.\\n'}\n",
      "You are eligible for up to $9000 per year for learning and development. This means you can spend up to $173.08 per week.\n"
     ]
    }
   ],
   "source": [
    "output = cohere_agent(questions[3], preamble, tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a demonstration of an agent working with a diverse set of tools. It combines search across multiple databases and the internet, with Python code execution to provide useful and accurate information to the user.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

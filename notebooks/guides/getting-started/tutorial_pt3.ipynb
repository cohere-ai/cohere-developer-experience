{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/cohere-ai/notebooks/blob/main/notebooks/guides/getting-started/tutorial_pt3.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As its name implies, the Chat endpoint enables developers to build chatbots that can handle conversations. At the core of a conversation is a multi-turn dialog between the user and the chatbot. This requires the chatbot to have the state (or “memory”) of all the previous turns to maintain the state of the conversation.\n",
    "\n",
    "In this tutorial, you'll learn about:\n",
    "- Creating a custom preamble\n",
    "- Creating a single-turn conversation\n",
    "- Building the conversation memory\n",
    "- Running a multi-turn conversation\n",
    "- Viewing the chat history\n",
    "\n",
    "You'll learn these by building an onboarding assistant for new hires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To get started, first we need to install the `cohere` library and create a Cohere client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cohere\n",
    "\n",
    "import cohere\n",
    "\n",
    "co = cohere.Client(\"COHERE_API_KEY\") # Get your API key: https://dashboard.cohere.com/api-keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a custom preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A conversation starts with a system message, or a preamble, to help steer a chatbot’s response toward certain characteristics.\n",
    "\n",
    "For example, if we want the chatbot to adopt a formal style, the preamble can be used to encourage the generation of more business-like and professional responses.\n",
    "\n",
    "The recommended approach is to use two H2 Markdown headers: \"Task and Context\" and \"Style Guide\" in the exact order.\n",
    "\n",
    "In the example below, the preamble provides context for the assistant's task (task and context) and encourages the generation of rhymes as much as possible (style guide)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a rhyme to break the ice,\n",
      "A polite and friendly tone should suffice: \n",
      "\n",
      "Hello team, it's a pleasure to meet,\n",
      "My name's [Your Name], and my role is quite sweet. \n",
      "\n",
      "I'm thrilled to join Co1t, a startup so bright,\n",
      "Where innovation and talent ignite. \n",
      "\n",
      "My role here is [Your Role], a position brand new,\n",
      "Where I'll contribute and learn from you. \n",
      "\n",
      "I look forward to working together in harmony,\n",
      "Exchanging ideas and creating synergy. \n",
      "\n",
      "Feel free to connect, and let's start anew,\n",
      "I'm excited to be part of this team, me and you! \n",
      "\n",
      "Cheers to a great first week,\n",
      "And many successes, unique and sleek! \n",
      "\n",
      "Let's collaborate and soar,\n",
      "Co1t's future is bright, that's for sure! \n",
      "\n",
      "Regards, \n",
      "[Your Name] \n",
      "\n",
      "(P.S. I'm a poet and didn't know it!)\n"
     ]
    }
   ],
   "source": [
    "# Add the user message\n",
    "message = \"I'm joining a new startup called Co1t today. Could you help me write a short introduction message to my teammates.\"\n",
    "\n",
    "# Create a custom preamble\n",
    "preamble=\"\"\"## Task and Context\n",
    "You are an assistant who assist new employees of Co1t with their first week.\n",
    "\n",
    "## Style Guide\n",
    "Try to speak in rhymes as much as possible. Be professional.\"\"\"\n",
    "\n",
    "# Generate the response\n",
    "response = co.chat(message=message,\n",
    "                   preamble=preamble)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further reading:\n",
    "- [Documentation on preambles](https://docs.cohere.com/docs/preambles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a single-turn conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a single-turn conversation, which doesn't require the chatbot to maintain any conversation state. \n",
    "\n",
    "Here, we are also adding a custom preamble for generating concise response, just to keep the outputs brief for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hi, I'm thrilled to join the Co1t team today and look forward to contributing to the company's success and working collaboratively with all of you!\"\n"
     ]
    }
   ],
   "source": [
    "# Add the user message\n",
    "message = \"I'm joining a new startup called Co1t today. Could you help me write a short introduction message to my teammates.\"\n",
    "\n",
    "# Create a custom preamble\n",
    "preamble=\"\"\"## Task & Context\n",
    "Generate concise responses, with maximum one-sentence.\"\"\"\n",
    "\n",
    "# Generate the response\n",
    "response = co.chat(message=message,\n",
    "                   preamble=preamble)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the conversation memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want the model to refine the earlier response. This requires the next generation to have access to the state, or memory, of the conversation.\n",
    "\n",
    "To do this, we add the `chat_history` argument, which takes the current chat history as the value.\n",
    "\n",
    "You can get the current chat history by taking the the `response.chat_history` object from the previous response.\n",
    "\n",
    "Looking at the response, we see that the model is able to get the context from the chat history. The model is able to capture that \"it\" in the user message refers to the introduction message it had generated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hey, I'm stoked to be a part of the Co1t crew! Can't wait to dive in and work together to make our startup vision a reality!\"\n"
     ]
    }
   ],
   "source": [
    "# Add the user message\n",
    "message = \"Make it more upbeat and conversational.\"\n",
    "\n",
    "# Generate the response with the current chat history as the context\n",
    "response = co.chat(message=message,\n",
    "                   preamble=preamble,\n",
    "                   chat_history=response.chat_history)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further reading:\n",
    "- [Documentation on using the Chat endpoint](https://docs.cohere.com/docs/chat-api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a multi-turn conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can continue doing this for any number of turns by passing the most recent `response.chat_history` value, which contains the conversation history from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Super excited to be a part of the Co1t family! Looking forward to learning from your expertise and guidance and contributing my best to the team's success under your management.\"\n"
     ]
    }
   ],
   "source": [
    "# Add the user message\n",
    "message = \"Thanks. Could you create another one for my DM to my manager.\"\n",
    "\n",
    "# Generate the response with the current chat history as the context\n",
    "response = co.chat(message=message,\n",
    "                   preamble=preamble,\n",
    "                   chat_history=response.chat_history)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the chat history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at the current chat history, you can print the `response.chat_history` object, which contains a list of `USER` and `CHATBOT` turns in the same sequence as they were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: USER\n",
      "Message: I'm joining a new startup called Co1t today. Could you help me write a short introduction message to my teammates. \n",
      "\n",
      "Role: CHATBOT\n",
      "Message: \"Hi, I'm thrilled to join the Co1t team today and look forward to contributing to the company's success and working collaboratively with all of you!\" \n",
      "\n",
      "Role: USER\n",
      "Message: Make it more upbeat and conversational. \n",
      "\n",
      "Role: CHATBOT\n",
      "Message: \"Hey, I'm stoked to be a part of the Co1t crew! Can't wait to dive in and work together to make our startup vision a reality!\" \n",
      "\n",
      "Role: USER\n",
      "Message: Thanks. Could you create another one for my DM to my manager. \n",
      "\n",
      "Role: CHATBOT\n",
      "Message: \"Super excited to be a part of the Co1t family! Looking forward to learning from your expertise and guidance and contributing my best to the team's success under your management.\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the chat history\n",
    "for turn in response.chat_history:\n",
    "    print(\"Role:\",turn.role)\n",
    "    print(\"Message:\",turn.message,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you learned about:\n",
    "- How to create a custom preamble\n",
    "- How to create a single-turn conversation\n",
    "- How to build the conversation memory\n",
    "- How to run a multi-turn conversation\n",
    "- How to view the chat history\n",
    "\n",
    "You will use the same method for running a multi-turn conversation when you learn about other use cases such as RAG (Part 6) and tool use (Part 7).\n",
    "\n",
    "But to fully leverage these other capabilities, you will need another type of language model that generates text representations, or embeddings.\n",
    "\n",
    "In Part 4, you will learn how text embeddings can power an important use case for RAG, which is semantic search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

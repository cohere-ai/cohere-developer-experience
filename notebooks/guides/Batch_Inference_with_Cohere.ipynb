{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0QnztNFOd4V"
      },
      "source": [
        "# Cohere Batch API Cookbook: Embeddings\n",
        "\n",
        "This notebook demonstrates how to use the Cohere Batch API to process large volumes of embedding requests efficiently.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "1. How to prepare input data in the correct format for batch embedding\n",
        "2. How to upload datasets and create batch jobs\n",
        "3. How to monitor job progress\n",
        "4. How to download and process results\n",
        "5. How to manage and monitor your datasets and batch jobs\n",
        "\n",
        "## Use Cases\n",
        "\n",
        "- Embedding large document collections for semantic search\n",
        "- Creating embeddings for machine learning training data\n",
        "- Batch processing of text data for clustering or classification\n",
        "- Building vector databases with thousands or millions of entries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr_mOwd_Od4W"
      },
      "source": [
        "## Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UbQAuOaiOd4W"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%%capture\n",
        "!pip install fastavro requests cohere==5.19.0 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gUXFei5WOd4X"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import fastavro\n",
        "import os\n",
        "from typing import List, Dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwTZt1pTOd4X",
        "outputId": "36e627c8-0939-43c6-86a2-3368b0bf8e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Cohere client initialized\n"
          ]
        }
      ],
      "source": [
        "# Initialize Cohere client\n",
        "# Replace with your actual API key from https://dashboard.cohere.com/api-keys\n",
        "API_KEY = \"your-api-key\"\n",
        "\n",
        "# V1 client for datasets\n",
        "co = cohere.Client(api_key=API_KEY)\n",
        "\n",
        "print(\"✓ Cohere client initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP409d4oOd4X"
      },
      "source": [
        "## Step 1: Prepare Your Input Data\n",
        "\n",
        "The Batch API requires input data in JSONL format, where each line is a JSON object containing:\n",
        "- `custom_id`: A **unique** identifier for tracking the request\n",
        "- `body`: The embedding request parameters with the following structure:\n",
        "  - `input_type`: Type of input (search_document, search_query, classification, clustering)\n",
        "  - `embedding_types`: Array of embedding formats to return\n",
        "  - `inputs`: Array of input objects, each with a `content` array containing text objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNDB45dhOd4X",
        "outputId": "930e7614-3942-4d6a-eed9-a14938eaddd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample dataset contains 10 items\n",
            "First item: High-performance laptop with 16GB RAM and 512GB SSD\n"
          ]
        }
      ],
      "source": [
        "# Example: Sample dataset of product descriptions\n",
        "sample_texts = [\n",
        "    \"High-performance laptop with 16GB RAM and 512GB SSD\",\n",
        "    \"Wireless noise-cancelling headphones with 30-hour battery life\",\n",
        "    \"Ergonomic office chair with lumbar support and adjustable height\",\n",
        "    \"4K smart TV with HDR and built-in streaming apps\",\n",
        "    \"Professional camera with 24MP sensor and 4K video recording\",\n",
        "    \"Fitness tracker with heart rate monitor and GPS\",\n",
        "    \"Portable Bluetooth speaker with waterproof design\",\n",
        "    \"Gaming mouse with programmable buttons and RGB lighting\",\n",
        "    \"Standing desk converter with dual monitor support\",\n",
        "    \"Mechanical keyboard with tactile switches and backlighting\"\n",
        "]\n",
        "\n",
        "print(f\"Sample dataset contains {len(sample_texts)} items\")\n",
        "print(f\"First item: {sample_texts[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF_14AyFOd4Y",
        "outputId": "e1a54fa7-6da1-4df1-c55f-6b17d438ab41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 10 batch requests\n",
            "\n",
            "Example request:\n",
            "{\n",
            "  \"custom_id\": \"1\",\n",
            "  \"body\": {\n",
            "    \"input_type\": \"search_document\",\n",
            "    \"embedding_types\": [\n",
            "      \"float\"\n",
            "    ],\n",
            "    \"inputs\": [\n",
            "      {\n",
            "        \"content\": [\n",
            "          {\n",
            "            \"type\": \"text\",\n",
            "            \"text\": \"High-performance laptop with 16GB RAM and 512GB SSD\"\n",
            "          }\n",
            "        ]\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "def create_batch_input(texts: List[str], input_type: str = \"search_document\") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Create batch input in the required JSONL format for Cohere Embed v2.\n",
        "\n",
        "    Args:\n",
        "        texts: List of texts to embed\n",
        "        input_type: One of 'search_document', 'search_query', 'classification', 'clustering'\n",
        "\n",
        "    Returns:\n",
        "        List of dictionaries ready to be saved as JSONL\n",
        "    \"\"\"\n",
        "    batch_input = []\n",
        "\n",
        "    for idx, text in enumerate(texts):\n",
        "        # custom_id must be unique - using string index\n",
        "        batch_input.append({\n",
        "            \"custom_id\": str(idx + 1),  # Ensure unique IDs starting from \"1\"\n",
        "            \"body\": {\n",
        "                \"input_type\": input_type,\n",
        "                \"embedding_types\": [\"float\"],\n",
        "                \"inputs\": [\n",
        "                    {\n",
        "                        \"content\": [\n",
        "                            {\n",
        "                                \"type\": \"text\",\n",
        "                                \"text\": text\n",
        "                            }\n",
        "                        ]\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        })\n",
        "\n",
        "    return batch_input\n",
        "\n",
        "# Create batch input\n",
        "batch_input = create_batch_input(sample_texts, input_type=\"search_document\")\n",
        "\n",
        "print(f\"Created {len(batch_input)} batch requests\")\n",
        "print(\"\\nExample request:\")\n",
        "print(json.dumps(batch_input[0], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUHsLQIiOd4Y",
        "outputId": "214da4ba-30d4-41ad-cbf0-d4c3f236cd6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Saved 10 records to batch_embed_input.jsonl\n"
          ]
        }
      ],
      "source": [
        "def save_jsonl(data: List[Dict], filename: str):\n",
        "    \"\"\"Save data as JSONL file (one JSON object per line).\"\"\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        for item in data:\n",
        "            f.write(json.dumps(item) + \"\\n\")\n",
        "    print(f\"✓ Saved {len(data)} records to {filename}\")\n",
        "\n",
        "# Save to file\n",
        "input_filename = \"batch_embed_input.jsonl\"\n",
        "save_jsonl(batch_input, input_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-aMlvXYOd4Y"
      },
      "source": [
        "## Step 2: Upload Dataset to Cohere\n",
        "\n",
        "Upload your JSONL file to Cohere's dataset service. The dataset will be validated asynchronously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X4IR0avOd4Y",
        "outputId": "dbbe1cba-99db-4519-a4c3-13bdedf7f24b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading dataset...\n",
            "Dataset created with ID: product-embeddings-batch-gszxbq\n",
            "Waiting for dataset validation to complete...\n",
            "...\n",
            "...\n",
            "...\n",
            "✓ Dataset validated successfully! ID: product-embeddings-batch-gszxbq\n"
          ]
        }
      ],
      "source": [
        "# Upload dataset and wait for validation\n",
        "print(\"Uploading dataset...\")\n",
        "\n",
        "dataset = co.datasets.create(\n",
        "    name=\"product-embeddings-batch\",\n",
        "    data=open(input_filename, \"rb\"),\n",
        "    type=\"batch-embed-v2-input\"\n",
        ")\n",
        "\n",
        "print(f\"Dataset created with ID: {dataset.id}\")\n",
        "print(\"Waiting for dataset validation to complete...\")\n",
        "\n",
        "try:\n",
        "    dataset_response = co.wait(dataset)\n",
        "    dataset = dataset_response.dataset\n",
        "    print(f\"✓ Dataset validated successfully! ID: {dataset.id}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Dataset validation failed: {e}\")\n",
        "    raise Exception(f\"Dataset validation failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vlDC9pyOd4Y"
      },
      "source": [
        "## Step 3: Create Batch Job\n",
        "\n",
        "Create a batch embedding job using your validated dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FOHDcQdOd4Y",
        "outputId": "fab25ddd-4879-475b-8bf0-66701b57bd5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating batch job...\n",
            "✓ Batch job created with ID: 879296b8-8c2d-45ac-8cec-02436e859611\n",
            "  Name: product-embeddings-job\n",
            "  Model: batch-embed-v4\n",
            "  Status: BATCH_STATUS_QUEUED\n",
            "  Number of records: 10\n",
            "  Created at: 2025-10-16 17:36:15.297709+00:00\n",
            "\n",
            "Save this ID to check status later: 879296b8-8c2d-45ac-8cec-02436e859611\n"
          ]
        }
      ],
      "source": [
        "# Create batch job\n",
        "print(\"Creating batch job...\")\n",
        "batch_job = co.batches.create(\n",
        "    request={\n",
        "        \"name\": \"product-embeddings-job\",\n",
        "        \"input_dataset_id\": dataset.id,\n",
        "        \"model\": \"batch-embed-v4\"  # Options: batch-embed-v4, batch-embed-v4-a100\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"✓ Batch job created with ID: {batch_job.batch.id}\")\n",
        "print(f\"  Name: {batch_job.batch.name}\")\n",
        "print(f\"  Model: {batch_job.batch.model}\")\n",
        "print(f\"  Status: {batch_job.batch.status}\")\n",
        "print(f\"  Number of records: {batch_job.batch.num_records}\")\n",
        "print(f\"  Created at: {batch_job.batch.created_at}\")\n",
        "print(f\"\\nSave this ID to check status later: {batch_job.batch.id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TwvBE12Od4Y"
      },
      "source": [
        "## Step 4: Monitor Job Progress\n",
        "\n",
        "Poll the batch job status until it completes. This may take anywhere from a few minutes to several hours depending on the size of the batch job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vFKRbXbpOd4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c76649a7-8cb2-4593-f77f-05f20feeacbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monitoring batch job progress...\n",
            "(This may take a while for large batches)\n",
            "\n",
            "Status: BATCH_STATUS_QUEUED\n",
            "Progress: 0/10 completed\n",
            "Checking again in 60 seconds...\n",
            "\n",
            "Status: BATCH_STATUS_QUEUED\n",
            "Progress: 0/10 completed\n",
            "Checking again in 60 seconds...\n",
            "\n",
            "Status: BATCH_STATUS_QUEUED\n",
            "Progress: 0/10 completed\n",
            "Checking again in 60 seconds...\n",
            "\n",
            "Status: BATCH_STATUS_QUEUED\n",
            "Progress: 0/10 completed\n",
            "Checking again in 60 seconds...\n",
            "\n",
            "Status: BATCH_STATUS_QUEUED\n",
            "Progress: 0/10 completed\n",
            "Checking again in 60 seconds...\n",
            "\n",
            "Status: BATCH_STATUS_QUEUED\n",
            "Progress: 0/10 completed\n",
            "Checking again in 60 seconds...\n",
            "\n",
            "Status: BATCH_STATUS_QUEUED\n",
            "Progress: 0/10 completed\n",
            "Checking again in 60 seconds...\n",
            "\n",
            "Status: BATCH_STATUS_COMPLETED\n",
            "Progress: 10/10 completed\n",
            "\n",
            "✓ Job BATCH_STATUS_COMPLETED\n"
          ]
        }
      ],
      "source": [
        "def monitor_batch_job(co, batch_id: str, poll_interval: int = 30):\n",
        "    \"\"\"\n",
        "    Monitor batch job until completion.\n",
        "    Args:\n",
        "        co: Cohere client\n",
        "        batch_id: Batch job ID\n",
        "        poll_interval: Seconds between status checks\n",
        "    Returns:\n",
        "        Final batch job status\n",
        "    \"\"\"\n",
        "    print(\"Monitoring batch job progress...\")\n",
        "    print(\"(This may take a while for large batches or if there are in-progress jobs)\\n\")\n",
        "\n",
        "    while True:\n",
        "        response = co.batches.retrieve(batch_id)\n",
        "        status = response.batch\n",
        "\n",
        "        # Display progress\n",
        "        print(f\"Status: {status.status}\")\n",
        "        print(f\"Progress: {status.num_successful_records}/{status.num_records} completed\")\n",
        "\n",
        "        if status.num_failed_records > 0:\n",
        "            print(f\"Failed: {status.num_failed_records}\")\n",
        "\n",
        "        # Check if job is complete\n",
        "        if status.status in [\"BATCH_STATUS_COMPLETED\", \"BATCH_STATUS_FAILED\", \"BATCH_STATUS_CANCELLED\"]:\n",
        "            print(f\"\\n✓ Job {status.status}\")\n",
        "            return status\n",
        "\n",
        "        print(f\"Checking again in {poll_interval} seconds...\\n\")\n",
        "        time.sleep(poll_interval)\n",
        "\n",
        "# Monitor the job\n",
        "final_status = monitor_batch_job(co, batch_job.batch.id, poll_interval=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z3ITSC8XOd4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c45777-01a2-42b0-d698-edd551fba6f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "BATCH JOB SUMMARY\n",
            "==================================================\n",
            "Job ID: 879296b8-8c2d-45ac-8cec-02436e859611\n",
            "Status: BATCH_STATUS_COMPLETED\n",
            "Total requests: 10\n",
            "Completed: 10\n",
            "Failed: 0\n",
            "Output dataset ID: product-embeddings-job-output-xse5ev\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Display final results summary\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"BATCH JOB SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Job ID: {final_status.id}\")\n",
        "print(f\"Status: {final_status.status}\")\n",
        "print(f\"Total requests: {final_status.num_records}\")\n",
        "print(f\"Completed: {final_status.num_successful_records}\")\n",
        "print(f\"Failed: {final_status.num_failed_records}\")\n",
        "print(f\"Output dataset ID: {final_status.output_dataset_id}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAwLVCHbOd4Z"
      },
      "source": [
        "## Step 5: Download and Process Results\n",
        "\n",
        "Download the output dataset and save it in your preferred format using Cohere's built-in utility.\n",
        "The `co.utils.save_dataset()` function supports multiple formats:\n",
        "\n",
        "* `jsonl` - JSON Lines format (recommended for preserving data structure)\n",
        "* `csv` - Comma-separated values (easy to view in Excel/Sheets)\n",
        "* `avro` - Apache Avro format (efficient binary format)\n",
        "\n",
        "Simply change the format parameter to your desired output format. The function handles all the downloading and conversion automatically."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_save_dataset(dataset_id, output_dir, co, format=\"jsonl\"):\n",
        "    \"\"\"\n",
        "    Download dataset from Cohere and save to file.\n",
        "\n",
        "    Args:\n",
        "        dataset_id: Output dataset ID from batch job\n",
        "        output_dir: Directory to save output files\n",
        "        co: Cohere client\n",
        "        format: Output format - 'jsonl', 'csv', or 'avro' (default: 'jsonl')\n",
        "\n",
        "    Returns:\n",
        "        List of result dictionaries\n",
        "    \"\"\"\n",
        "    print(f\"Downloading dataset {dataset_id}...\")\n",
        "\n",
        "    # Get the dataset object\n",
        "    output_dataset = co.datasets.get(id=dataset_id).dataset\n",
        "\n",
        "    # Collect all records\n",
        "    dataset = []\n",
        "    for record in output_dataset:\n",
        "        dataset.append(record)\n",
        "\n",
        "    print(f\"✓ Downloaded {len(dataset)} records\")\n",
        "\n",
        "    # Save using Cohere's utility\n",
        "    output_path = os.path.join(output_dir, f\"{dataset_id}.{format}\")\n",
        "    co.utils.save_dataset(\n",
        "        dataset=output_dataset,\n",
        "        filepath=output_path,\n",
        "        format=format,\n",
        "    )\n",
        "\n",
        "    print(f\"✓ Saved {len(dataset)} records to {output_path}\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"./batch_output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Download and save results\n",
        "results = download_and_save_dataset(\n",
        "    final_status.output_dataset_id,\n",
        "    output_dir,\n",
        "    co,\n",
        "    format=\"jsonl\"  # Options: 'jsonl', 'csv', or 'avro'\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Results saved to {output_dir}/{final_status.output_dataset_id}.jsonl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNXCfGBOIaki",
        "outputId": "8a00d082-7b61-48b3-8e4d-7026086bf2f3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset product-embeddings-job-output-xse5ev...\n",
            "✓ Downloaded 12 records\n",
            "✓ Saved 12 records to ./batch_output/product-embeddings-job-output-xse5ev.jsonl\n",
            "\n",
            "✓ Results saved to ./batch_output/product-embeddings-job-output-xse5ev.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "45yN39tHOd4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1449b407-526b-4497-ebe1-65ff8a55aeb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example result structure:\n",
            "{\n",
            "  \"custom_id\": \"4\",\n",
            "  \"body\": {\n",
            "    \"id\": \"5f10573b-c3dc-40e8-bd6c-9e106889de04\",\n",
            "    \"embeddings\": {\n",
            "      \"float\": [\n",
            "        [\n",
            "          -0.09744025,\n",
            "          -0.02665485,\n",
            "          -0.02577224,\n",
            "          -0.0074580624,\n",
            "          0.025948763,\n",
            "          0.017210914,\n",
            "          -0.024713106,\n",
            "          0.0061341464,\n",
            "          -0.034774873,\n",
            "          -0.0060458854,\n",
            "          -0.0014121776,\n",
            "          0.124271624,\n",
            "          -0.049426213,\n",
            "          -0.0044571855,\n",
            "          -0.004744034,\n",
            "          0...\n"
          ]
        }
      ],
      "source": [
        "# Inspect first result\n",
        "print(\"Example result structure:\")\n",
        "print(json.dumps(results[0], indent=2, default=str)[:500] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d79Y2wQOd4Z"
      },
      "source": [
        "## Cleanup (Optional)\n",
        "\n",
        "Clean up temporary files created during this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV1x0zbZOd4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2631cc-3d77-49de-aa5f-7d8ea2968f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed batch_embed_input.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Remove temporary files\n",
        "files_to_remove = [\"batch_embed_input.jsonl\"]\n",
        "\n",
        "for file in files_to_remove:\n",
        "    if os.path.exists(file):\n",
        "        os.remove(file)\n",
        "        print(f\"Removed {file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Managing Your Datasets and Batch Jobs\n",
        "\n",
        "Now that you've completed a full batch job workflow, let's explore how to manage your datasets and batch jobs. These utilities are helpful for monitoring multiple jobs, debugging issues, or cleaning up resources.\n",
        "\n",
        "### Listing All Datasets\n",
        "\n",
        "You can view all datasets in your account to track what data you've uploaded.\n"
      ],
      "metadata": {
        "id": "ZRSlFjoykC8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all datasets\n",
        "print(\"Fetching your datasets...\\n\")\n",
        "\n",
        "# You can filter to only show validated datasets\n",
        "only_validated = True  # Set to False to see all datasets\n",
        "\n",
        "datasets_response = co.datasets.list(\n",
        "    validation_status=\"validated\" if only_validated else None\n",
        ")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"YOUR DATASETS {'(Validated Only)' if only_validated else '(All)'}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if not datasets_response.datasets:\n",
        "    print(\"\\nNo datasets found.\")\n",
        "else:\n",
        "    for i, ds in enumerate(datasets_response.datasets[:10], 1):  # Show first 10\n",
        "        print(f\"\\n#{i}\")\n",
        "        print(f\"  ID: {ds.id}\")\n",
        "        print(f\"  Name: {ds.name}\")\n",
        "        print(f\"  Type: {ds.dataset_type}\")\n",
        "        print(f\"  Validation Status: {ds.validation_status}\")\n",
        "        print(f\"  Created: {ds.created_at}\")\n",
        "        if hasattr(ds, 'validation_error') and ds.validation_error:\n",
        "            print(f\"  Validation Error: {ds.validation_error}\")\n",
        "\n",
        "    total = len(datasets_response.datasets)\n",
        "    print(f\"\\n(Showing {min(10, total)} of {total} datasets)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV4uWlzNkLj0",
        "outputId": "ac141956-6b66-4978-cd08-df399eeadcc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching your datasets...\n",
            "\n",
            "================================================================================\n",
            "YOUR DATASETS (Validated Only)\n",
            "================================================================================\n",
            "\n",
            "#1\n",
            "  ID: product-embeddings-job-output-5d4qyd\n",
            "  Name: product-embeddings-job-output\n",
            "  Type: batch-embed-v2-output\n",
            "  Validation Status: validated\n",
            "  Created: 2025-10-16 00:54:03.625755+00:00\n",
            "\n",
            "#2\n",
            "  ID: product-embeddings-job-output-ay6j8w\n",
            "  Name: product-embeddings-job-output\n",
            "  Type: batch-embed-v2-output\n",
            "  Validation Status: validated\n",
            "  Created: 2025-10-16 00:53:43.777087+00:00\n",
            "\n",
            "#3\n",
            "  ID: product-embeddings-job-output-qajjgg\n",
            "  Name: product-embeddings-job-output\n",
            "  Type: batch-embed-v2-output\n",
            "  Validation Status: validated\n",
            "  Created: 2025-10-16 00:53:18.973449+00:00\n",
            "\n",
            "#4\n",
            "  ID: product-embeddings-batch-sv80yd\n",
            "  Name: product-embeddings-batch\n",
            "  Type: batch-embed-v2-input\n",
            "  Validation Status: validated\n",
            "  Created: 2025-10-16 00:48:32.344911+00:00\n",
            "\n",
            "#5\n",
            "  ID: product-embeddings-batch-qvtetd\n",
            "  Name: product-embeddings-batch\n",
            "  Type: batch-embed-v2-input\n",
            "  Validation Status: validated\n",
            "  Created: 2025-10-16 00:44:15.853256+00:00\n",
            "\n",
            "#6\n",
            "  ID: product-embeddings-batch-vmpaqr\n",
            "  Name: product-embeddings-batch\n",
            "  Type: batch-embed-v2-input\n",
            "  Validation Status: validated\n",
            "  Created: 2025-10-15 23:51:42.875200+00:00\n",
            "\n",
            "#7\n",
            "  ID: product-embeddings-job-output-269e8p\n",
            "  Name: product-embeddings-job-output\n",
            "  Type: batch-embed-v2-output\n",
            "  Validation Status: validated\n",
            "  Created: 2025-10-10 16:04:48.886820+00:00\n",
            "\n",
            "#8\n",
            "  ID: product-embeddings-batch-dd1y5w\n",
            "  Name: product-embeddings-batch\n",
            "  Type: batch-embed-v2-input\n",
            "  Validation Status: validated\n",
            "  Created: 2025-10-10 16:02:16.237691+00:00\n",
            "\n",
            "#9\n",
            "  ID: product-embeddings-job-output-sxd6hr\n",
            "  Name: product-embeddings-job-output\n",
            "  Type: batch-embed-v2-output\n",
            "  Validation Status: validated\n",
            "  Created: 2025-10-10 01:48:33.101736+00:00\n",
            "\n",
            "#10\n",
            "  ID: product-embeddings-batch-rksdee\n",
            "  Name: product-embeddings-batch\n",
            "  Type: batch-embed-v2-input\n",
            "  Validation Status: validated\n",
            "  Created: 2025-10-10 01:48:22.584556+00:00\n",
            "\n",
            "(Showing 10 of 22 datasets)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing All Batch Jobs\n",
        "\n",
        "View all batch jobs to monitor their progress and status."
      ],
      "metadata": {
        "id": "R2dkf-c7kqpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all batch jobs\n",
        "print(\"\\nFetching your batch jobs...\\n\")\n",
        "\n",
        "batches_response = co.batches.list()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"YOUR BATCH JOBS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if not batches_response.batches:\n",
        "    print(\"\\nNo batch jobs found.\")\n",
        "else:\n",
        "    for i, batch in enumerate(batches_response.batches[:10], 1):  # Show first 10\n",
        "        print(f\"\\n#{i}\")\n",
        "        print(f\"  ID: {batch.id}\")\n",
        "        print(f\"  Name: {batch.name}\")\n",
        "        print(f\"  Model: {batch.model}\")\n",
        "        print(f\"  Status: {batch.status}\")\n",
        "        print(f\"  Progress: {batch.num_successful_records}/{batch.num_records} completed\")\n",
        "\n",
        "        if batch.num_failed_records > 0:\n",
        "            print(f\"  Failed: {batch.num_failed_records}\")\n",
        "\n",
        "        print(f\"  Input Dataset: {batch.input_dataset_id}\")\n",
        "        if batch.output_dataset_id:\n",
        "            print(f\"  Output Dataset: {batch.output_dataset_id}\")\n",
        "\n",
        "        print(f\"  Created: {batch.created_at}\")\n",
        "        print(f\"  Updated: {batch.updated_at}\")\n",
        "\n",
        "    total = len(batches_response.batches)\n",
        "    print(f\"\\n(Showing {min(10, total)} of {total} batch jobs)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erheEoX5kwyM",
        "outputId": "dfe542da-27f5-4d79-9085-84d03384fee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fetching your batch jobs...\n",
            "\n",
            "================================================================================\n",
            "YOUR BATCH JOBS\n",
            "================================================================================\n",
            "\n",
            "#1\n",
            "  ID: a17e1e5f-e80e-471b-ada1-2750b47b432c\n",
            "  Name: rit-embed-job-mixed-30k\n",
            "  Model: batch-embed-v4\n",
            "  Status: BATCH_STATUS_COMPLETED\n",
            "  Progress: 29248/30000 completed\n",
            "  Input Dataset: \n",
            "  Created: 2025-08-15 01:18:30.237654+00:00\n",
            "  Updated: 2025-08-15 02:47:23.386329+00:00\n",
            "\n",
            "#2\n",
            "  ID: 7cc1a188-73a1-4709-84c0-66f6274482f7\n",
            "  Name: product-embeddings-job\n",
            "  Model: batch-embed-v4\n",
            "  Status: BATCH_STATUS_COMPLETED\n",
            "  Progress: 10/10 completed\n",
            "  Input Dataset: product-embeddings-batch-fk0pfx\n",
            "  Output Dataset: product-embeddings-job-output-ezn4ke\n",
            "  Created: 2025-10-10 01:43:48.240205+00:00\n",
            "  Updated: 2025-10-10 01:43:53.196834+00:00\n",
            "\n",
            "#3\n",
            "  ID: 9c922fd7-ccda-4dcb-b6f8-bdf9a9d4be86\n",
            "  Name: product-embeddings-job\n",
            "  Model: batch-embed-v4\n",
            "  Status: BATCH_STATUS_COMPLETED\n",
            "  Progress: 10/10 completed\n",
            "  Input Dataset: product-embeddings-batch-fk0pfx\n",
            "  Output Dataset: product-embeddings-job-output-bkxwq4\n",
            "  Created: 2025-10-10 01:44:21.044806+00:00\n",
            "  Updated: 2025-10-10 01:44:23.588546+00:00\n",
            "\n",
            "#4\n",
            "  ID: 8e232dd3-363f-4e22-96fd-19b145922c44\n",
            "  Name: product-embeddings-job\n",
            "  Model: batch-embed-v4\n",
            "  Status: BATCH_STATUS_COMPLETED\n",
            "  Progress: 10/10 completed\n",
            "  Input Dataset: product-embeddings-batch-fk0pfx\n",
            "  Output Dataset: product-embeddings-job-output-ryztrr\n",
            "  Created: 2025-10-10 01:44:45.533557+00:00\n",
            "  Updated: 2025-10-10 01:44:48.403233+00:00\n",
            "\n",
            "#5\n",
            "  ID: 985dee9d-a047-4065-8d18-a03ce3f3345c\n",
            "  Name: product-embeddings-job\n",
            "  Model: batch-embed-v4\n",
            "  Status: BATCH_STATUS_COMPLETED\n",
            "  Progress: 10/10 completed\n",
            "  Input Dataset: product-embeddings-batch-rksdee\n",
            "  Output Dataset: product-embeddings-job-output-sxd6hr\n",
            "  Created: 2025-10-10 01:48:32.959078+00:00\n",
            "  Updated: 2025-10-10 01:48:34.296953+00:00\n",
            "\n",
            "#6\n",
            "  ID: 82eff8a4-47d5-44a1-a7ce-d82c2bf741a5\n",
            "  Name: product-embeddings-job\n",
            "  Model: batch-embed-v4\n",
            "  Status: BATCH_STATUS_COMPLETED\n",
            "  Progress: 10/10 completed\n",
            "  Input Dataset: product-embeddings-batch-dd1y5w\n",
            "  Output Dataset: product-embeddings-job-output-269e8p\n",
            "  Created: 2025-10-10 16:04:48.504370+00:00\n",
            "  Updated: 2025-10-10 16:04:51.063483+00:00\n",
            "\n",
            "#7\n",
            "  ID: 1d15cfc6-b6c2-4ff3-b042-ae9535c2552e\n",
            "  Name: product-embeddings-job\n",
            "  Model: batch-embed-v4\n",
            "  Status: BATCH_STATUS_COMPLETED\n",
            "  Progress: 10/10 completed\n",
            "  Input Dataset: product-embeddings-batch-sv80yd\n",
            "  Output Dataset: product-embeddings-job-output-qajjgg\n",
            "  Created: 2025-10-16 00:53:18.561426+00:00\n",
            "  Updated: 2025-10-16 00:53:23.163311+00:00\n",
            "\n",
            "#8\n",
            "  ID: 0035f589-08e1-4af8-8e1a-6aa06d9a014b\n",
            "  Name: product-embeddings-job\n",
            "  Model: batch-embed-v4\n",
            "  Status: BATCH_STATUS_COMPLETED\n",
            "  Progress: 10/10 completed\n",
            "  Input Dataset: product-embeddings-batch-sv80yd\n",
            "  Output Dataset: product-embeddings-job-output-ay6j8w\n",
            "  Created: 2025-10-16 00:53:43.474016+00:00\n",
            "  Updated: 2025-10-16 00:53:45.946398+00:00\n",
            "\n",
            "#9\n",
            "  ID: 8b58636e-7638-4710-940b-541fc85a2cf0\n",
            "  Name: product-embeddings-job\n",
            "  Model: batch-embed-v4\n",
            "  Status: BATCH_STATUS_COMPLETED\n",
            "  Progress: 10/10 completed\n",
            "  Input Dataset: product-embeddings-batch-sv80yd\n",
            "  Output Dataset: product-embeddings-job-output-5d4qyd\n",
            "  Created: 2025-10-16 00:54:03.428883+00:00\n",
            "  Updated: 2025-10-16 00:54:06.294725+00:00\n",
            "\n",
            "(Showing 9 of 9 batch jobs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cancelling a Batch Job\n",
        "\n",
        "If you need to stop a running or queued batch job, you can cancel it. This is useful if you've submitted a job with incorrect parameters or if you no longer need the results.\n",
        "\n",
        "**Important Notes:**\n",
        "- You can only cancel jobs with status `BATCH_STATUS_QUEUED` or `BATCH_STATUS_IN_PROGRESS`\n",
        "- Completed, failed, or already cancelled jobs cannot be cancelled\n",
        "- Cancellation is immediate and cannot be undone"
      ],
      "metadata": {
        "id": "JGSu70EhlDDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example: Checking if a batch job can be cancelled\n",
        "print(\"Checking if batch job can be cancelled...\\n\")\n",
        "\n",
        "# Get current status\n",
        "response = co.batches.retrieve(batch_job.batch.id)\n",
        "current_status = response.batch.status\n",
        "\n",
        "print(f\"Batch ID: {batch_job.batch.id}\")\n",
        "print(f\"Batch Name: {response.batch.name}\")\n",
        "print(f\"Current Status: {current_status}\")\n",
        "print(f\"Progress: {response.batch.num_successful_records}/{response.batch.num_records}\")\n",
        "\n",
        "# Define cancellable statuses\n",
        "cancellable_statuses = [\"BATCH_STATUS_QUEUED\", \"BATCH_STATUS_IN_PROGRESS\"]\n",
        "non_cancellable_statuses = [\n",
        "    \"BATCH_STATUS_COMPLETED\",\n",
        "    \"BATCH_STATUS_FAILED\",\n",
        "    \"BATCH_STATUS_CANCELLED\",\n",
        "    \"BATCH_STATUS_CANCELING\"\n",
        "]\n",
        "\n",
        "# Check if cancellation is possible\n",
        "if current_status in cancellable_statuses:\n",
        "    print(f\"\\n✓ This job can be cancelled (status: {current_status})\")\n",
        "    print(\"\\nTo cancel this job, uncomment and run:\")\n",
        "    print(f\"# co.batches.cancel('{batch_job.batch.id}')\")\n",
        "    print(f\"# print('✓ Batch job cancelled')\")\n",
        "elif current_status in non_cancellable_statuses:\n",
        "    print(f\"\\n⚠️ Cannot cancel - job status is: {current_status}\")\n",
        "    if current_status == \"BATCH_STATUS_CANCELING\":\n",
        "        print(\"This job is already being cancelled.\")\n",
        "    elif current_status == \"BATCH_STATUS_CANCELLED\":\n",
        "        print(\"This job has already been cancelled.\")\n",
        "    else:\n",
        "        print(f\"Only jobs with status in {cancellable_statuses} can be cancelled.\")\n",
        "else:\n",
        "    print(f\"\\n⚠️ Unknown status: {current_status}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bdffos_lGaQ",
        "outputId": "8dd2a33f-d705-4258-ede7-cb34c8477a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking if batch job can be cancelled...\n",
            "\n",
            "Batch ID: 8b58636e-7638-4710-940b-541fc85a2cf0\n",
            "Batch Name: product-embeddings-job\n",
            "Current Status: BATCH_STATUS_COMPLETED\n",
            "Progress: 10/10\n",
            "\n",
            "⚠️ Cannot cancel - job status is: BATCH_STATUS_COMPLETED\n",
            "Only jobs with status in ['BATCH_STATUS_QUEUED', 'BATCH_STATUS_IN_PROGRESS'] can be cancelled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-uFNRpxOd4Z"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this cookbook, you learned how to:\n",
        "\n",
        "1. ✅ Prepare input data in the correct JSONL format with unique `custom_id`s\n",
        "2. ✅ Upload datasets to Cohere and wait for validation\n",
        "3. ✅ Create and monitor batch embedding jobs\n",
        "4. ✅ Download and convert results from AVRO to JSONL format\n",
        "5. ✅ List and inspect your datasets and batch jobs\n",
        "6. ✅ Cancel batch jobs when needed\n",
        "\n",
        "## Resources\n",
        "\n",
        "- [Batch API reference](https://docs.cohere.com/reference/create-batch)\n",
        "- [Dataset API Reference](https://docs.cohere.com/docs/datasets)\n",
        "- [Embed v2 API Reference](https://docs.cohere.com/reference/embed)\n",
        "- [Get API Key](https://dashboard.cohere.com/api-keys)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}